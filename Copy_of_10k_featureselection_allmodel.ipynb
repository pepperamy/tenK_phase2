{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 10k_featureselection_cnnlstm.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "TE2BHZAjEPfc",
        "3tpLiMqNK9qj"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pepperamy/tenK_phase2/blob/main/Copy_of_10k_featureselection_allmodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gFdXv30e4Zx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67749457-1552-4089-f4d4-cc7139de9aa8"
      },
      "source": [
        "import pandas as pd\r\n",
        "import pickle\r\n",
        "import re\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\r\n",
        "from sklearn.metrics.pairwise import cosine_similarity\r\n",
        "\r\n",
        "from scipy.optimize import linear_sum_assignment\r\n",
        "import time\r\n",
        "\r\n",
        "from IPython.core.interactiveshell import InteractiveShell\r\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\r\n",
        "\r\n",
        "import statsmodels.api as sm\r\n",
        "import statsmodels.formula.api as smf\r\n",
        "\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')\r\n",
        "\r\n",
        "from scipy.stats import mstats\r\n",
        "import math\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPbGENVjzMx6"
      },
      "source": [
        "from sklearn.model_selection import KFold,StratifiedKFold"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovlMafoEj7fh"
      },
      "source": [
        "from keras import regularizers"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edodAjPPLihc"
      },
      "source": [
        "from keras import backend as K"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEyVpJiqfWh7"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, precision_recall_curve, classification_report,accuracy_score, auc, roc_curve, roc_auc_score, average_precision_score"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQoE_A26fcCN"
      },
      "source": [
        "from keras.models import Sequential\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "from keras.layers import Embedding, Dense, Conv2D, MaxPooling2D, Reshape, Conv1D, MaxPooling1D,\\\r\n",
        "Dropout, Activation, Input, Flatten, Concatenate, BatchNormalization, Lambda, LSTM, GRU, Bidirectional,\\\r\n",
        "ZeroPadding2D\r\n",
        "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\r\n",
        "from keras import regularizers\r\n",
        "from keras.models import Model\r\n",
        "from keras import optimizers\r\n",
        "from keras import metrics\r\n",
        "from keras import models\r\n",
        "from keras import layers"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOhMLRyIB5rG"
      },
      "source": [
        "from sklearn.utils import class_weight"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hU6Xry_KF88_"
      },
      "source": [
        "from sklearn import utils"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LTmS2gbJsCI"
      },
      "source": [
        "import random"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QGsL2oSKI0I"
      },
      "source": [
        "from sklearn.svm import LinearSVC,SVC\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\r\n",
        "#from sklearn import metrics\r\n",
        "from sklearn.model_selection import cross_validate\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dP4mF35eC3Gv"
      },
      "source": [
        "# data prepare"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGDo0BX3fdqF"
      },
      "source": [
        "df = pd.read_csv('data_performance_words_win1_comb_20210301.csv')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXrMxcpfdcof",
        "outputId": "cf0ba892-e118-4c59-e3b4-adb88dc975a4"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(53635, 212)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTHf-QumI8Cd",
        "outputId": "86ea5289-61b4-43b5-e090-e01a51732cb5"
      },
      "source": [
        "sum(df.label)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "487.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "7uYp5m-amwON",
        "outputId": "78be607b-37e8-4ae9-a081-726dc973fc79"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cik</th>\n",
              "      <th>y1</th>\n",
              "      <th>y2</th>\n",
              "      <th>s1</th>\n",
              "      <th>window</th>\n",
              "      <th>label</th>\n",
              "      <th>sic_class_x</th>\n",
              "      <th>rsst_acc</th>\n",
              "      <th>ch_rec</th>\n",
              "      <th>ch_inv</th>\n",
              "      <th>soft_asset</th>\n",
              "      <th>ch_cs</th>\n",
              "      <th>ch_roa</th>\n",
              "      <th>issue</th>\n",
              "      <th>aqi</th>\n",
              "      <th>asset_turnover</th>\n",
              "      <th>cfed</th>\n",
              "      <th>depi</th>\n",
              "      <th>gmi</th>\n",
              "      <th>ig</th>\n",
              "      <th>opm</th>\n",
              "      <th>rg</th>\n",
              "      <th>sg</th>\n",
              "      <th>sgee</th>\n",
              "      <th>pastavg5</th>\n",
              "      <th>pastavg3</th>\n",
              "      <th>pastavg1</th>\n",
              "      <th>cr5</th>\n",
              "      <th>cr3</th>\n",
              "      <th>cr1</th>\n",
              "      <th>WeakModal_3_avg</th>\n",
              "      <th>WeakModal_3_dis</th>\n",
              "      <th>WeakModal_3_n</th>\n",
              "      <th>WeakModal_3_new</th>\n",
              "      <th>WeakModal_3_p</th>\n",
              "      <th>WeakModal_3_u</th>\n",
              "      <th>Litigious_3_avg</th>\n",
              "      <th>Litigious_3_dis</th>\n",
              "      <th>Litigious_3_n</th>\n",
              "      <th>Litigious_3_new</th>\n",
              "      <th>...</th>\n",
              "      <th>Achieve_3_p</th>\n",
              "      <th>Achieve_3_u</th>\n",
              "      <th>Power_3_avg</th>\n",
              "      <th>Power_3_dis</th>\n",
              "      <th>Power_3_n</th>\n",
              "      <th>Power_3_new</th>\n",
              "      <th>Power_3_p</th>\n",
              "      <th>Power_3_u</th>\n",
              "      <th>Reward_3_avg</th>\n",
              "      <th>Reward_3_dis</th>\n",
              "      <th>Reward_3_n</th>\n",
              "      <th>Reward_3_new</th>\n",
              "      <th>Reward_3_p</th>\n",
              "      <th>Reward_3_u</th>\n",
              "      <th>Risk_3_avg</th>\n",
              "      <th>Risk_3_dis</th>\n",
              "      <th>Risk_3_n</th>\n",
              "      <th>Risk_3_new</th>\n",
              "      <th>Risk_3_p</th>\n",
              "      <th>Risk_3_u</th>\n",
              "      <th>WeakModal_up</th>\n",
              "      <th>WeakModal_down</th>\n",
              "      <th>Litigious_up</th>\n",
              "      <th>Litigious_down</th>\n",
              "      <th>StrongModal_up</th>\n",
              "      <th>StrongModal_down</th>\n",
              "      <th>Negative_up</th>\n",
              "      <th>Negative_down</th>\n",
              "      <th>Positive_up</th>\n",
              "      <th>Positive_down</th>\n",
              "      <th>Uncertainty_up</th>\n",
              "      <th>Uncertainty_down</th>\n",
              "      <th>Compare_up</th>\n",
              "      <th>Compare_down</th>\n",
              "      <th>Achieve_up</th>\n",
              "      <th>Achieve_down</th>\n",
              "      <th>Discrep_up</th>\n",
              "      <th>Discrep_down</th>\n",
              "      <th>Reward_up</th>\n",
              "      <th>Reward_down</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20.0</td>\n",
              "      <td>1995.0</td>\n",
              "      <td>1996.0</td>\n",
              "      <td>0.633505</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.063117</td>\n",
              "      <td>-0.072425</td>\n",
              "      <td>-0.067847</td>\n",
              "      <td>0.661974</td>\n",
              "      <td>-0.147079</td>\n",
              "      <td>0.198730</td>\n",
              "      <td>1</td>\n",
              "      <td>0.974056</td>\n",
              "      <td>1.624273</td>\n",
              "      <td>0.206066</td>\n",
              "      <td>1.226305</td>\n",
              "      <td>0.914198</td>\n",
              "      <td>0.715334</td>\n",
              "      <td>0.044798</td>\n",
              "      <td>0.783539</td>\n",
              "      <td>0.814093</td>\n",
              "      <td>1.013528</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.000071</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>0.004950</td>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>-0.002775</td>\n",
              "      <td>0.002801</td>\n",
              "      <td>0.190476</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>-0.004527</td>\n",
              "      <td>0.016180</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.029638</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.190476</td>\n",
              "      <td>-0.000009</td>\n",
              "      <td>0.002644</td>\n",
              "      <td>0.190476</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.190476</td>\n",
              "      <td>0.523810</td>\n",
              "      <td>-0.002433</td>\n",
              "      <td>0.002488</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.019737</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.052570</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.193277</td>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.058512</td>\n",
              "      <td>0.353070</td>\n",
              "      <td>0.338308</td>\n",
              "      <td>0.238095</td>\n",
              "      <td>0.292404</td>\n",
              "      <td>0.100189</td>\n",
              "      <td>0.145658</td>\n",
              "      <td>0.395804</td>\n",
              "      <td>0.355975</td>\n",
              "      <td>0.060777</td>\n",
              "      <td>0.303224</td>\n",
              "      <td>0.190476</td>\n",
              "      <td>0.248916</td>\n",
              "      <td>0.190476</td>\n",
              "      <td>0.193121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.0</td>\n",
              "      <td>1996.0</td>\n",
              "      <td>1997.0</td>\n",
              "      <td>0.803827</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.066126</td>\n",
              "      <td>-0.018252</td>\n",
              "      <td>-0.059281</td>\n",
              "      <td>0.620435</td>\n",
              "      <td>-0.066028</td>\n",
              "      <td>0.034753</td>\n",
              "      <td>1</td>\n",
              "      <td>1.248039</td>\n",
              "      <td>1.606518</td>\n",
              "      <td>0.025826</td>\n",
              "      <td>1.088859</td>\n",
              "      <td>0.978102</td>\n",
              "      <td>0.755016</td>\n",
              "      <td>0.062466</td>\n",
              "      <td>0.938786</td>\n",
              "      <td>0.969746</td>\n",
              "      <td>1.012432</td>\n",
              "      <td>0.633505</td>\n",
              "      <td>0.633505</td>\n",
              "      <td>0.633505</td>\n",
              "      <td>1.268856</td>\n",
              "      <td>1.268856</td>\n",
              "      <td>1.268856</td>\n",
              "      <td>-0.000034</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.028571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.866667</td>\n",
              "      <td>0.003234</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>-0.003780</td>\n",
              "      <td>0.018289</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.000668</td>\n",
              "      <td>0.007947</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>-0.001054</td>\n",
              "      <td>0.013954</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.028571</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.161905</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.161905</td>\n",
              "      <td>0.357243</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.219242</td>\n",
              "      <td>0.123810</td>\n",
              "      <td>0.134598</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.144428</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.075494</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.070482</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.207947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20.0</td>\n",
              "      <td>1997.0</td>\n",
              "      <td>1998.0</td>\n",
              "      <td>0.462705</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.095900</td>\n",
              "      <td>0.066711</td>\n",
              "      <td>0.013223</td>\n",
              "      <td>0.656729</td>\n",
              "      <td>-0.030720</td>\n",
              "      <td>0.019574</td>\n",
              "      <td>1</td>\n",
              "      <td>0.840540</td>\n",
              "      <td>1.574474</td>\n",
              "      <td>0.020191</td>\n",
              "      <td>0.991780</td>\n",
              "      <td>0.991078</td>\n",
              "      <td>1.073227</td>\n",
              "      <td>0.073961</td>\n",
              "      <td>1.241132</td>\n",
              "      <td>1.022834</td>\n",
              "      <td>0.983269</td>\n",
              "      <td>0.718666</td>\n",
              "      <td>0.718666</td>\n",
              "      <td>0.803827</td>\n",
              "      <td>0.643838</td>\n",
              "      <td>0.643838</td>\n",
              "      <td>0.575627</td>\n",
              "      <td>0.002823</td>\n",
              "      <td>0.005714</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.007841</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>-0.001499</td>\n",
              "      <td>0.004000</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.004315</td>\n",
              "      <td>...</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000062</td>\n",
              "      <td>0.028035</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.021889</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>-0.003310</td>\n",
              "      <td>0.001504</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.002960</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>-0.000069</td>\n",
              "      <td>0.011111</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.004688</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.141174</td>\n",
              "      <td>0.072381</td>\n",
              "      <td>0.137649</td>\n",
              "      <td>0.137333</td>\n",
              "      <td>0.074024</td>\n",
              "      <td>0.139048</td>\n",
              "      <td>0.149893</td>\n",
              "      <td>0.299598</td>\n",
              "      <td>0.070786</td>\n",
              "      <td>0.271178</td>\n",
              "      <td>0.154181</td>\n",
              "      <td>0.144762</td>\n",
              "      <td>0.484144</td>\n",
              "      <td>0.236060</td>\n",
              "      <td>0.074921</td>\n",
              "      <td>0.277778</td>\n",
              "      <td>0.076624</td>\n",
              "      <td>0.202532</td>\n",
              "      <td>0.002960</td>\n",
              "      <td>0.268170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20.0</td>\n",
              "      <td>1998.0</td>\n",
              "      <td>1999.0</td>\n",
              "      <td>0.701689</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.054997</td>\n",
              "      <td>0.026323</td>\n",
              "      <td>-0.009875</td>\n",
              "      <td>0.676757</td>\n",
              "      <td>0.011434</td>\n",
              "      <td>0.002424</td>\n",
              "      <td>1</td>\n",
              "      <td>0.837833</td>\n",
              "      <td>1.604656</td>\n",
              "      <td>0.003715</td>\n",
              "      <td>1.025961</td>\n",
              "      <td>1.024634</td>\n",
              "      <td>0.948804</td>\n",
              "      <td>0.076906</td>\n",
              "      <td>1.077020</td>\n",
              "      <td>0.985921</td>\n",
              "      <td>0.983057</td>\n",
              "      <td>0.633346</td>\n",
              "      <td>0.633346</td>\n",
              "      <td>0.462705</td>\n",
              "      <td>1.107909</td>\n",
              "      <td>1.107909</td>\n",
              "      <td>1.516495</td>\n",
              "      <td>0.000590</td>\n",
              "      <td>0.006755</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>-0.000112</td>\n",
              "      <td>0.005460</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.590909</td>\n",
              "      <td>0.001965</td>\n",
              "      <td>0.034894</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.019415</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000347</td>\n",
              "      <td>0.003575</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008179</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.681818</td>\n",
              "      <td>-0.000126</td>\n",
              "      <td>0.003620</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>0.052210</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.096370</td>\n",
              "      <td>0.048976</td>\n",
              "      <td>0.140434</td>\n",
              "      <td>0.093257</td>\n",
              "      <td>0.110468</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.050488</td>\n",
              "      <td>0.187374</td>\n",
              "      <td>0.063963</td>\n",
              "      <td>0.195518</td>\n",
              "      <td>0.159758</td>\n",
              "      <td>0.101197</td>\n",
              "      <td>0.055574</td>\n",
              "      <td>0.103194</td>\n",
              "      <td>0.144520</td>\n",
              "      <td>0.053633</td>\n",
              "      <td>0.003575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.0</td>\n",
              "      <td>1999.0</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>0.823023</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.024892</td>\n",
              "      <td>-0.024929</td>\n",
              "      <td>0.041267</td>\n",
              "      <td>0.705573</td>\n",
              "      <td>-0.001713</td>\n",
              "      <td>-0.014429</td>\n",
              "      <td>1</td>\n",
              "      <td>1.093648</td>\n",
              "      <td>1.560280</td>\n",
              "      <td>-0.015406</td>\n",
              "      <td>0.942174</td>\n",
              "      <td>0.995699</td>\n",
              "      <td>1.221034</td>\n",
              "      <td>0.068754</td>\n",
              "      <td>0.933610</td>\n",
              "      <td>0.966150</td>\n",
              "      <td>1.000184</td>\n",
              "      <td>0.650432</td>\n",
              "      <td>0.656074</td>\n",
              "      <td>0.701689</td>\n",
              "      <td>1.265350</td>\n",
              "      <td>1.254468</td>\n",
              "      <td>1.172917</td>\n",
              "      <td>-0.000791</td>\n",
              "      <td>0.002083</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.764706</td>\n",
              "      <td>-0.000278</td>\n",
              "      <td>0.003717</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>-0.001826</td>\n",
              "      <td>0.011784</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>0.054348</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.764706</td>\n",
              "      <td>0.001092</td>\n",
              "      <td>0.007639</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.764706</td>\n",
              "      <td>-0.000721</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.010870</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.764706</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.178554</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.121364</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.068988</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.004167</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.184109</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>0.312405</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.129003</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.253588</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.007639</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 212 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    cik      y1      y2  ...  Discrep_down  Reward_up  Reward_down\n",
              "0  20.0  1995.0  1996.0  ...      0.248916   0.190476     0.193121\n",
              "1  20.0  1996.0  1997.0  ...      0.070482   0.200000     0.207947\n",
              "2  20.0  1997.0  1998.0  ...      0.202532   0.002960     0.268170\n",
              "3  20.0  1998.0  1999.0  ...      0.144520   0.053633     0.003575\n",
              "4  20.0  1999.0  2000.0  ...      0.253588   0.176471     0.007639\n",
              "\n",
              "[5 rows x 212 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFPQxWfzmxA5"
      },
      "source": [
        "df_fl = df[(df.y2 <= 2012) & (df.y2 >= 1995 ) ]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHk9KoNgdKnU",
        "outputId": "b921ebe1-7c80-4dc3-e71c-d2996a1aeeea"
      },
      "source": [
        "df_fl.label.value_counts()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    53148\n",
              "1.0      487\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htklHIW9JDXK",
        "outputId": "bcd2d78a-e710-4fa6-cdfd-727d3a74662d"
      },
      "source": [
        "df_fl.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(53635, 212)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czKM_c73sGzE"
      },
      "source": [
        "selected_new = ['WeakModal','Negative', 'Compare', 'Discrep','Positive',\\\r\n",
        "         'Achieve',  'Reward', 'StrongModal','Uncertainty', 'Litigious'][::-1]\r\n",
        "\r\n",
        "v_perf = ['aqi',\r\n",
        " 'asset_turnover',\r\n",
        " 'depi',\r\n",
        " 'gmi',\r\n",
        " #'ig',\r\n",
        " 'opm',\r\n",
        " 'rg',\r\n",
        " 'sg',\r\n",
        " 'sgee',\r\n",
        " 'ch_rec',\r\n",
        " 'ch_inv',\r\n",
        " 'soft_asset',\r\n",
        " 'ch_cs',\r\n",
        " 'ch_roa',\r\n",
        " 'issue']\r\n",
        "\r\n",
        "v_1 = ['s1']\r\n",
        "v_2 = ['pastavg3','cr3']"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqB8Sa2NDeFF"
      },
      "source": [
        "# selected_comb = []\r\n",
        "# for s in selected_new:\r\n",
        "#   selected_comb.append(s+'_up')\r\n",
        "#   selected_comb.append(s+'_down')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u09YX6QTsRjF"
      },
      "source": [
        "selected_new_all = []\r\n",
        "temp = []\r\n",
        "for s in selected_new:\r\n",
        "    wrd = s.split('_')[0]\r\n",
        "    if wrd not in temp:\r\n",
        "        #print(s,'\\n',temp)\r\n",
        "        #selected_new_all.append(wrd+'_3_avg')\r\n",
        "        selected_new_all.append(wrd+'_3_p')\r\n",
        "        selected_new_all.append(wrd+'_3_n')\r\n",
        "        #selected_new_all.append(wrd+'_3_u')\r\n",
        "        selected_new_all.append(wrd+'_3_new')\r\n",
        "        selected_new_all.append(wrd+'_3_dis')\r\n",
        "        temp.append(wrd)\r\n",
        "    else: \r\n",
        "        pass"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08oZ_gShupro"
      },
      "source": [
        "selected_new_all"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLPx7-Q37_ft"
      },
      "source": [
        "selected_new_all_sorted = []\r\n",
        "selected_new_all_p = []\r\n",
        "selected_new_all_n = []\r\n",
        "selected_new_all_new = []\r\n",
        "selected_new_all_dis = []\r\n",
        "for s in selected_new_all:\r\n",
        "  if 'new' in s.split('_'):\r\n",
        "    selected_new_all_new.append(s)\r\n",
        "  elif 'p' in s.split('_'):\r\n",
        "    selected_new_all_p.append(s)\r\n",
        "  elif 'n' in s.split('_'):\r\n",
        "    selected_new_all_n.append(s)\r\n",
        "  elif 'dis' in s.split('_'):\r\n",
        "    selected_new_all_dis.append(s)\r\n",
        "\r\n",
        "for i, w in enumerate(selected_new_all_p):\r\n",
        "  selected_new_all_sorted.append(selected_new_all_p[i])\r\n",
        "  selected_new_all_sorted.append(selected_new_all_new[i])\r\n",
        "  selected_new_all_sorted.append(selected_new_all_n[i])\r\n",
        "  \r\n",
        "  selected_new_all_sorted.append(selected_new_all_dis[i])  \r\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uuAH4EArW1P"
      },
      "source": [
        "selected_new_all_sorted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_jHGUWwCi3M"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TE2BHZAjEPfc"
      },
      "source": [
        "# SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWbZ3_n5Ci5x"
      },
      "source": [
        "def svm( data, vs, label = 'label'):\r\n",
        "    \r\n",
        "    columns_fl = vs[1] #+ [ 'sic_class_x']\r\n",
        "    \r\n",
        "    data_target = data.loc[:,columns_fl + [label]]\r\n",
        "    \r\n",
        "    tprs = []\r\n",
        "    auc_list = []\r\n",
        "    mean_fpr = np.linspace(0,1,100)\r\n",
        "    \r\n",
        "    class_report = []\r\n",
        "    sum_pred_list = []\r\n",
        "\r\n",
        "    kf = StratifiedKFold(n_splits = 4, shuffle = True)\r\n",
        "    c = 0\r\n",
        "    data_target = data[columns_fl + [label]]\r\n",
        "    data_target = data_target.dropna()\r\n",
        "    data_target = data_target.reset_index(drop = True)\r\n",
        "    print('dataset: ', data_target.shape, '/n', sum(data_target.label))\r\n",
        "     \r\n",
        "    for train_index, test_index in kf.split(data_target[columns_fl],data_target[label]):\r\n",
        "        \r\n",
        "        c += 1\r\n",
        "\r\n",
        "        train_x = data_target.loc[train_index,columns_fl]\r\n",
        "        train_y = data_target.loc[train_index,label]\r\n",
        "        test_x = data_target.loc[test_index,columns_fl]\r\n",
        "        test_y = data_target.loc[test_index,label] \r\n",
        "\r\n",
        "        print('iterate_num: ', c, '\\n','sum of test_y:', sum(test_y))\r\n",
        "    \r\n",
        "        svm = LinearSVC(class_weight = \"balanced\")\r\n",
        "        svm.fit(train_x, train_y )\r\n",
        "        pickle.dump(svm, open('svm_'+str(vs[0])+ '_'+str(c), 'wb'))\r\n",
        "        \r\n",
        "\r\n",
        "        pred = svm.predict(test_x)\r\n",
        "        sum_pred_list.append(pred)\r\n",
        "        print('sum of pred: ', sum(pred), '\\n')\r\n",
        "        # c_r = metrics.classification_report(test_y, pred, labels=[0,1], output_dict = True)\r\n",
        "        # class_report.append(c_r)\r\n",
        "        #print(metrics.classification_report(test_y, pred, labels=[0,1]))\r\n",
        "        \r\n",
        "        decision_values = svm.decision_function(test_x)\r\n",
        "        auc_score = roc_auc_score(test_y, decision_values)\r\n",
        "        print(auc_score)\r\n",
        "        auc_list.append(auc_score)\r\n",
        "        \r\n",
        "        fpr, tpr, thresholds = roc_curve(test_y, decision_values)\r\n",
        "        tprs.append(np.interp(mean_fpr, fpr, tpr))\r\n",
        "        \r\n",
        "#         mean_tpr = np.mean(tprs, axis=0)\r\n",
        "#         mean_auc = auc(mean_fpr, mean_tpr)\r\n",
        "        \r\n",
        "        \r\n",
        "    mean_tpr = np.mean(tprs, axis=0)\r\n",
        "    print('avg_AUC : ', np.mean(auc_list))\r\n",
        "    print('avg_AUC_2 : ', auc(mean_fpr, mean_tpr))\r\n",
        "    frauds_prec = []\r\n",
        "    fradus_recall = []\r\n",
        "    for d in class_report:\r\n",
        "        frauds_prec.append(d['1']['precision'])\r\n",
        "        fradus_recall.append(d['1']['recall'])\r\n",
        "    \r\n",
        "#     coef_s = 0\r\n",
        "#     for i in coef:\r\n",
        "#         coef_s += abs(i)\r\n",
        "#     coef_avg = coef_s / len(coef)\r\n",
        "#     coef_top = pd.DataFrame(coef_avg, index = columns_fl,columns = ['importance'])\r\n",
        "#     coef_top = coef_top.sort_values('importance',ascending=False)\r\n",
        "#     print(coef_top.iloc[0:10,:])\r\n",
        "        \r\n",
        "    print('frauds_prec : ', np.mean(frauds_prec))\r\n",
        "    print('fradus_recall : ', np.mean(fradus_recall))\r\n",
        "    print('\\n')\r\n",
        "    return np.mean(auc_list),mean_tpr"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSJwNQBg9ouv",
        "outputId": "26921b35-f487-41ba-90aa-48f0f4607091"
      },
      "source": [
        "v_2"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pastavg3', 'cr3']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrLJFpcI9rJR",
        "outputId": "24c09202-6afb-4aa6-aea2-0fa592631ddd"
      },
      "source": [
        "vs_fl = {'perf':v_perf, 'perf+spc': v_perf +v_1, 'wrd+spc': selected_new_all +v_1,'perf+spc+wrd': v_perf +v_1 +selected_new_all}\r\n",
        "mean_tpr_dict_svm = dict()\r\n",
        "for fl in vs_fl.items():\r\n",
        "#    print(fl)\r\n",
        "    svm_model = svm( df_fl, fl,label = 'label')\r\n",
        "    print(fl)\r\n",
        "    print(svm_model[0])\r\n",
        "    mean_tpr_dict_svm[fl[0]] = svm_model[1]\r\n",
        "    print('============================')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataset:  (53635, 15) /n 487.0\n",
            "iterate_num:  1 \n",
            " sum of test_y: 122.0\n",
            "sum of pred:  2913.0 \n",
            "\n",
            "0.6566809416821817\n",
            "iterate_num:  2 \n",
            " sum of test_y: 122.0\n",
            "sum of pred:  2826.0 \n",
            "\n",
            "0.6702662654363256\n",
            "iterate_num:  3 \n",
            " sum of test_y: 122.0\n",
            "sum of pred:  3059.0 \n",
            "\n",
            "0.6883438391031786\n",
            "iterate_num:  4 \n",
            " sum of test_y: 121.0\n",
            "sum of pred:  3140.0 \n",
            "\n",
            "0.706292797222414\n",
            "avg_AUC :  0.680395960861025\n",
            "avg_AUC_2 :  0.6803150390232086\n",
            "frauds_prec :  nan\n",
            "fradus_recall :  nan\n",
            "\n",
            "\n",
            "('perf', ['aqi', 'asset_turnover', 'depi', 'gmi', 'opm', 'rg', 'sg', 'sgee', 'ch_rec', 'ch_inv', 'soft_asset', 'ch_cs', 'ch_roa', 'issue'])\n",
            "0.680395960861025\n",
            "============================\n",
            "dataset:  (53635, 16) /n 487.0\n",
            "iterate_num:  1 \n",
            " sum of test_y: 122.0\n",
            "sum of pred:  3031.0 \n",
            "\n",
            "0.6804672877593901\n",
            "iterate_num:  2 \n",
            " sum of test_y: 122.0\n",
            "sum of pred:  2782.0 \n",
            "\n",
            "0.690804027602476\n",
            "iterate_num:  3 \n",
            " sum of test_y: 122.0\n",
            "sum of pred:  2779.0 \n",
            "\n",
            "0.6875813533997855\n",
            "iterate_num:  4 \n",
            " sum of test_y: 121.0\n",
            "sum of pred:  2392.0 \n",
            "\n",
            "0.6583822999800338\n",
            "avg_AUC :  0.6793087421854214\n",
            "avg_AUC_2 :  0.6790580578854526\n",
            "frauds_prec :  nan\n",
            "fradus_recall :  nan\n",
            "\n",
            "\n",
            "('perf+spc', ['aqi', 'asset_turnover', 'depi', 'gmi', 'opm', 'rg', 'sg', 'sgee', 'ch_rec', 'ch_inv', 'soft_asset', 'ch_cs', 'ch_roa', 'issue', 's1'])\n",
            "0.6793087421854214\n",
            "============================\n",
            "dataset:  (53635, 42) /n 487.0\n",
            "iterate_num:  1 \n",
            " sum of test_y: 122.0\n",
            "sum of pred:  4993.0 \n",
            "\n",
            "0.6014315730770987\n",
            "iterate_num:  2 \n",
            " sum of test_y: 122.0\n",
            "sum of pred:  4827.0 \n",
            "\n",
            "0.6101884376075716\n",
            "iterate_num:  3 \n",
            " sum of test_y: 122.0\n",
            "sum of pred:  5102.0 \n",
            "\n",
            "0.6498487983447397\n",
            "iterate_num:  4 \n",
            " sum of test_y: 121.0\n",
            "sum of pred:  4950.0 \n",
            "\n",
            "0.5985045968625269\n",
            "avg_AUC :  0.6149933514729842\n",
            "avg_AUC_2 :  0.6152674625950605\n",
            "frauds_prec :  nan\n",
            "fradus_recall :  nan\n",
            "\n",
            "\n",
            "('wrd+spc', ['Litigious_3_p', 'Litigious_3_n', 'Litigious_3_new', 'Litigious_3_dis', 'Uncertainty_3_p', 'Uncertainty_3_n', 'Uncertainty_3_new', 'Uncertainty_3_dis', 'StrongModal_3_p', 'StrongModal_3_n', 'StrongModal_3_new', 'StrongModal_3_dis', 'Reward_3_p', 'Reward_3_n', 'Reward_3_new', 'Reward_3_dis', 'Achieve_3_p', 'Achieve_3_n', 'Achieve_3_new', 'Achieve_3_dis', 'Positive_3_p', 'Positive_3_n', 'Positive_3_new', 'Positive_3_dis', 'Discrep_3_p', 'Discrep_3_n', 'Discrep_3_new', 'Discrep_3_dis', 'Compare_3_p', 'Compare_3_n', 'Compare_3_new', 'Compare_3_dis', 'Negative_3_p', 'Negative_3_n', 'Negative_3_new', 'Negative_3_dis', 'WeakModal_3_p', 'WeakModal_3_n', 'WeakModal_3_new', 'WeakModal_3_dis', 's1'])\n",
            "0.6149933514729842\n",
            "============================\n",
            "dataset:  (53635, 56) /n 487.0\n",
            "iterate_num:  1 \n",
            " sum of test_y: 122.0\n",
            "sum of pred:  2738.0 \n",
            "\n",
            "0.7117403057592347\n",
            "iterate_num:  2 \n",
            " sum of test_y: 122.0\n",
            "sum of pred:  2836.0 \n",
            "\n",
            "0.7102665368713655\n",
            "iterate_num:  3 \n",
            " sum of test_y: 122.0\n",
            "sum of pred:  2862.0 \n",
            "\n",
            "0.6927892047816984\n",
            "iterate_num:  4 \n",
            " sum of test_y: 121.0\n",
            "sum of pred:  2822.0 \n",
            "\n",
            "0.7055538657993553\n",
            "avg_AUC :  0.7050874783029135\n",
            "avg_AUC_2 :  0.7049356524190556\n",
            "frauds_prec :  nan\n",
            "fradus_recall :  nan\n",
            "\n",
            "\n",
            "('perf+spc+wrd', ['aqi', 'asset_turnover', 'depi', 'gmi', 'opm', 'rg', 'sg', 'sgee', 'ch_rec', 'ch_inv', 'soft_asset', 'ch_cs', 'ch_roa', 'issue', 's1', 'Litigious_3_p', 'Litigious_3_n', 'Litigious_3_new', 'Litigious_3_dis', 'Uncertainty_3_p', 'Uncertainty_3_n', 'Uncertainty_3_new', 'Uncertainty_3_dis', 'StrongModal_3_p', 'StrongModal_3_n', 'StrongModal_3_new', 'StrongModal_3_dis', 'Reward_3_p', 'Reward_3_n', 'Reward_3_new', 'Reward_3_dis', 'Achieve_3_p', 'Achieve_3_n', 'Achieve_3_new', 'Achieve_3_dis', 'Positive_3_p', 'Positive_3_n', 'Positive_3_new', 'Positive_3_dis', 'Discrep_3_p', 'Discrep_3_n', 'Discrep_3_new', 'Discrep_3_dis', 'Compare_3_p', 'Compare_3_n', 'Compare_3_new', 'Compare_3_dis', 'Negative_3_p', 'Negative_3_n', 'Negative_3_new', 'Negative_3_dis', 'WeakModal_3_p', 'WeakModal_3_n', 'WeakModal_3_new', 'WeakModal_3_dis'])\n",
            "0.7050874783029135\n",
            "============================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uEhB2d89uY0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PX-G6Zx9uXM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BH3ezRUs9txF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnOcEwwp9tvc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAx--SZdCi8A",
        "outputId": "c07dfd56-b4fb-4b28-ed84-e1c93333d4f7"
      },
      "source": [
        "vs_fl = {'perf':v_perf, 'perf+spc': v_perf +v_1+v_2, 'wrd+spc': selected_new_all +v_1 +v_2,'perf+spc+wrd': v_perf +v_1 +v_2 +selected_new_all}\r\n",
        "mean_tpr_dict_svm = dict()\r\n",
        "for fl in vs_fl.items():\r\n",
        "#    print(fl)\r\n",
        "    svm_model = svm( df_fl, fl,label = 'label')\r\n",
        "    print(fl)\r\n",
        "    print(svm_model[0])\r\n",
        "    mean_tpr_dict_svm[fl[0]] = svm_model[1]\r\n",
        "    print('============================')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataset:  (53635, 15) /n 487.0\n",
            "iterate_num:  1 \n",
            " sum of test_y: 122.0\n",
            "sum of pred:  3275.0 \n",
            "\n",
            "0.6520116420956266\n",
            "iterate_num:  2 \n",
            " sum of test_y: 122.0\n",
            "sum of pred:  2752.0 \n",
            "\n",
            "0.6764994009922185\n",
            "iterate_num:  3 \n",
            " sum of test_y: 122.0\n",
            "sum of pred:  3315.0 \n",
            "\n",
            "0.6905615867598922\n",
            "iterate_num:  4 \n",
            " sum of test_y: 121.0\n",
            "sum of pred:  3018.0 \n",
            "\n",
            "0.7086626025438398\n",
            "avg_AUC :  0.6819338080978943\n",
            "avg_AUC_2 :  0.681893450149784\n",
            "frauds_prec :  nan\n",
            "fradus_recall :  nan\n",
            "\n",
            "\n",
            "('perf', ['aqi', 'asset_turnover', 'depi', 'gmi', 'opm', 'rg', 'sg', 'sgee', 'ch_rec', 'ch_inv', 'soft_asset', 'ch_cs', 'ch_roa', 'issue'])\n",
            "0.6819338080978943\n",
            "============================\n",
            "dataset:  (45611, 18) /n 407.0\n",
            "iterate_num:  1 \n",
            " sum of test_y: 102.0\n",
            "sum of pred:  2099.0 \n",
            "\n",
            "0.7207977430420005\n",
            "iterate_num:  2 \n",
            " sum of test_y: 102.0\n",
            "sum of pred:  1812.0 \n",
            "\n",
            "0.6266571932728494\n",
            "iterate_num:  3 \n",
            " sum of test_y: 102.0\n",
            "sum of pred:  2005.0 \n",
            "\n",
            "0.6721971506946289\n",
            "iterate_num:  4 \n",
            " sum of test_y: 101.0\n",
            "sum of pred:  1925.0 \n",
            "\n",
            "0.6944465617254584\n",
            "avg_AUC :  0.6785246621837343\n",
            "avg_AUC_2 :  0.6786443350217375\n",
            "frauds_prec :  nan\n",
            "fradus_recall :  nan\n",
            "\n",
            "\n",
            "('perf+spc', ['aqi', 'asset_turnover', 'depi', 'gmi', 'opm', 'rg', 'sg', 'sgee', 'ch_rec', 'ch_inv', 'soft_asset', 'ch_cs', 'ch_roa', 'issue', 's1', 'pastavg3', 'cr3'])\n",
            "0.6785246621837343\n",
            "============================\n",
            "dataset:  (45611, 44) /n 407.0\n",
            "iterate_num:  1 \n",
            " sum of test_y: 102.0\n",
            "sum of pred:  4071.0 \n",
            "\n",
            "0.6435132410631716\n",
            "iterate_num:  2 \n",
            " sum of test_y: 102.0\n",
            "sum of pred:  4066.0 \n",
            "\n",
            "0.593233116625112\n",
            "iterate_num:  3 \n",
            " sum of test_y: 102.0\n",
            "sum of pred:  4011.0 \n",
            "\n",
            "0.6021695112873925\n",
            "iterate_num:  4 \n",
            " sum of test_y: 101.0\n",
            "sum of pred:  3933.0 \n",
            "\n",
            "0.6194291051085463\n",
            "avg_AUC :  0.6145862435210556\n",
            "avg_AUC_2 :  0.6143251580059966\n",
            "frauds_prec :  nan\n",
            "fradus_recall :  nan\n",
            "\n",
            "\n",
            "('wrd+spc', ['Litigious_3_p', 'Litigious_3_n', 'Litigious_3_new', 'Litigious_3_dis', 'Uncertainty_3_p', 'Uncertainty_3_n', 'Uncertainty_3_new', 'Uncertainty_3_dis', 'StrongModal_3_p', 'StrongModal_3_n', 'StrongModal_3_new', 'StrongModal_3_dis', 'Reward_3_p', 'Reward_3_n', 'Reward_3_new', 'Reward_3_dis', 'Achieve_3_p', 'Achieve_3_n', 'Achieve_3_new', 'Achieve_3_dis', 'Positive_3_p', 'Positive_3_n', 'Positive_3_new', 'Positive_3_dis', 'Discrep_3_p', 'Discrep_3_n', 'Discrep_3_new', 'Discrep_3_dis', 'Compare_3_p', 'Compare_3_n', 'Compare_3_new', 'Compare_3_dis', 'Negative_3_p', 'Negative_3_n', 'Negative_3_new', 'Negative_3_dis', 'WeakModal_3_p', 'WeakModal_3_n', 'WeakModal_3_new', 'WeakModal_3_dis', 's1', 'pastavg3', 'cr3'])\n",
            "0.6145862435210556\n",
            "============================\n",
            "dataset:  (45611, 58) /n 407.0\n",
            "iterate_num:  1 \n",
            " sum of test_y: 102.0\n",
            "sum of pred:  2103.0 \n",
            "\n",
            "0.6985014340219761\n",
            "iterate_num:  2 \n",
            " sum of test_y: 102.0\n",
            "sum of pred:  2036.0 \n",
            "\n",
            "0.7448056826482473\n",
            "iterate_num:  3 \n",
            " sum of test_y: 102.0\n",
            "sum of pred:  2241.0 \n",
            "\n",
            "0.689605813124294\n",
            "iterate_num:  4 \n",
            " sum of test_y: 101.0\n",
            "sum of pred:  1967.0 \n",
            "\n",
            "0.7058264361079059\n",
            "avg_AUC :  0.7096848414756058\n",
            "avg_AUC_2 :  0.7097414398302575\n",
            "frauds_prec :  nan\n",
            "fradus_recall :  nan\n",
            "\n",
            "\n",
            "('perf+spc+wrd', ['aqi', 'asset_turnover', 'depi', 'gmi', 'opm', 'rg', 'sg', 'sgee', 'ch_rec', 'ch_inv', 'soft_asset', 'ch_cs', 'ch_roa', 'issue', 's1', 'pastavg3', 'cr3', 'Litigious_3_p', 'Litigious_3_n', 'Litigious_3_new', 'Litigious_3_dis', 'Uncertainty_3_p', 'Uncertainty_3_n', 'Uncertainty_3_new', 'Uncertainty_3_dis', 'StrongModal_3_p', 'StrongModal_3_n', 'StrongModal_3_new', 'StrongModal_3_dis', 'Reward_3_p', 'Reward_3_n', 'Reward_3_new', 'Reward_3_dis', 'Achieve_3_p', 'Achieve_3_n', 'Achieve_3_new', 'Achieve_3_dis', 'Positive_3_p', 'Positive_3_n', 'Positive_3_new', 'Positive_3_dis', 'Discrep_3_p', 'Discrep_3_n', 'Discrep_3_new', 'Discrep_3_dis', 'Compare_3_p', 'Compare_3_n', 'Compare_3_new', 'Compare_3_dis', 'Negative_3_p', 'Negative_3_n', 'Negative_3_new', 'Negative_3_dis', 'WeakModal_3_p', 'WeakModal_3_n', 'WeakModal_3_new', 'WeakModal_3_dis'])\n",
            "0.7096848414756058\n",
            "============================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zESDM53TKweY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHiIenY9K8Lf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tpLiMqNK9qj"
      },
      "source": [
        "# LR\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q86DE7q6K8OH"
      },
      "source": [
        "def lg( data,vs, label = 'label'):\r\n",
        "    \r\n",
        "    \r\n",
        "    columns_fl = vs[1]# + [ 'sic_class_x']\r\n",
        "    data_target = data.loc[:,columns_fl + [label]]\r\n",
        "    \r\n",
        "        \r\n",
        "#     train_x, test_x, train_y, test_y = train_test_split(data_x, data_y,test_size=0.2, random_state=19, \r\n",
        "#                                                                         stratify = data_y) \r\n",
        "\r\n",
        "    tprs = []\r\n",
        "    auc_list = []\r\n",
        "    mean_fpr = np.linspace(0,1,100)\r\n",
        "    \r\n",
        "    class_report = []\r\n",
        "    sum_pred_list = []\r\n",
        "    kf = StratifiedKFold(n_splits = 4, shuffle = True)\r\n",
        "    c = 0\r\n",
        "    data_target = data[columns_fl + [label]]\r\n",
        "    data_target = data_target.dropna()\r\n",
        "    data_target = data_target.reset_index(drop = True)\r\n",
        "    for train_index, test_index in kf.split(data_target[columns_fl],data_target[label]):\r\n",
        "        \r\n",
        "        c += 1\r\n",
        "\r\n",
        "        train_x = data_target.loc[train_index,columns_fl]\r\n",
        "        train_y = data_target.loc[train_index,label]\r\n",
        "        test_x = data_target.loc[test_index,columns_fl]\r\n",
        "        test_y = data_target.loc[test_index,label] \r\n",
        "\r\n",
        "        print('iterate_num: ', c, '\\n','sum of test_y:', sum(test_y))\r\n",
        "    \r\n",
        "        lg = LogisticRegression(class_weight = 'balanced')\r\n",
        "        lg.fit(train_x, train_y )\r\n",
        "        #pickle.dump(lg, open('lg_'+str(vs[0])+ '_'+str(c), 'wb'))\r\n",
        "\r\n",
        "        pred = lg.predict(test_x)\r\n",
        "        sum_pred_list.append(pred)\r\n",
        "        print('sum of pred: ', sum(pred), '\\n')\r\n",
        "        c_r = metrics.classification_report(test_y, pred, labels=[0,1], output_dict = True)\r\n",
        "        class_report.append(c_r)\r\n",
        "        #print(metrics.classification_report(test_y, pred, labels=[0,1]))\r\n",
        "        \r\n",
        "        decision_values = lg.predict_proba(test_x)\r\n",
        "        auc_score = roc_auc_score(test_y, decision_values[:,1])\r\n",
        "        print(auc_score)\r\n",
        "        auc_list.append(auc_score)\r\n",
        "        fpr, tpr, thresholds = roc_curve(test_y, decision_values[:,1])\r\n",
        "        tprs.append(np.interp(mean_fpr, fpr, tpr))\r\n",
        "        \r\n",
        "        #print('AUC',auc_score)\r\n",
        "        \r\n",
        "    mean_tpr = np.mean(tprs, axis=0)\r\n",
        "    print('avg_AUC : ', np.mean(auc_list))\r\n",
        "    print('avg_AUC_2 : ', auc(mean_fpr, mean_tpr))\r\n",
        "    frauds_prec = []\r\n",
        "    fradus_recall = []\r\n",
        "    for d in class_report:\r\n",
        "        frauds_prec.append(d['1']['precision'])\r\n",
        "        fradus_recall.append(d['1']['recall'])\r\n",
        "        \r\n",
        "    print('frauds_prec : ', np.mean(frauds_prec))\r\n",
        "    print('fradus_recall : ', np.mean(fradus_recall))\r\n",
        "    print('\\n')\r\n",
        "    return np.mean(auc_list),mean_tpr"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgQ54FUiLAJt",
        "outputId": "ec339d5f-81eb-4151-d901-bdee00fc0bec"
      },
      "source": [
        "vs_fl = {'perf':v_perf, 'perf+spc': v_perf +v_1+v_2, 'wrd+spc': selected_new_all +v_1 +v_2,'perf+spc+wrd': v_perf+v_1+v_2+selected_new_all}\r\n",
        "mean_tpr_dict_lg = dict()\r\n",
        "for fl in vs_fl.items():\r\n",
        "    lg_model = lg( df_fl, fl,label = 'label')\r\n",
        "    print(fl)\r\n",
        "    print(lg_model[0])\r\n",
        "    mean_tpr_dict_lg[fl[0]] = lg_model[1]\r\n",
        "    print('============================')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iterate_num:  1 \n",
            " sum of test_y: 122.0\n",
            "sum of pred:  5340.0 \n",
            "\n",
            "0.6703390593788826\n",
            "iterate_num:  2 \n",
            " sum of test_y: 122.0\n",
            "sum of pred:  5158.0 \n",
            "\n",
            "0.6768781762526418\n",
            "iterate_num:  3 \n",
            " sum of test_y: 122.0\n",
            "sum of pred:  5217.0 \n",
            "\n",
            "0.6674303861656963\n",
            "iterate_num:  4 \n",
            " sum of test_y: 121.0\n",
            "sum of pred:  5297.0 \n",
            "\n",
            "0.6779882405408381\n",
            "avg_AUC :  0.6731589655845147\n",
            "avg_AUC_2 :  0.6733243216612679\n",
            "frauds_prec :  0.014709944743580906\n",
            "fradus_recall :  0.6345007451564829\n",
            "\n",
            "\n",
            "('perf', ['aqi', 'asset_turnover', 'depi', 'gmi', 'opm', 'rg', 'sg', 'sgee', 'ch_rec', 'ch_inv', 'soft_asset', 'ch_cs', 'ch_roa', 'issue'])\n",
            "0.6731589655845147\n",
            "============================\n",
            "iterate_num:  1 \n",
            " sum of test_y: 102.0\n",
            "sum of pred:  4623.0 \n",
            "\n",
            "0.7197523731198523\n",
            "iterate_num:  2 \n",
            " sum of test_y: 102.0\n",
            "sum of pred:  4405.0 \n",
            "\n",
            "0.6156925207035296\n",
            "iterate_num:  3 \n",
            " sum of test_y: 102.0\n",
            "sum of pred:  4181.0 \n",
            "\n",
            "0.6563994857300499\n",
            "iterate_num:  4 \n",
            " sum of test_y: 101.0\n",
            "sum of pred:  4509.0 \n",
            "\n",
            "0.7042152582659381\n",
            "avg_AUC :  0.6740149094548424\n",
            "avg_AUC_2 :  0.6741240300500638\n",
            "frauds_prec :  0.014593700058840902\n",
            "fradus_recall :  0.636526887982916\n",
            "\n",
            "\n",
            "('perf+spc', ['aqi', 'asset_turnover', 'depi', 'gmi', 'opm', 'rg', 'sg', 'sgee', 'ch_rec', 'ch_inv', 'soft_asset', 'ch_cs', 'ch_roa', 'issue', 's1', 'pastavg3', 'cr3'])\n",
            "0.6740149094548424\n",
            "============================\n",
            "iterate_num:  1 \n",
            " sum of test_y: 102.0\n",
            "sum of pred:  4323.0 \n",
            "\n",
            "0.6420575309143213\n",
            "iterate_num:  2 \n",
            " sum of test_y: 102.0\n",
            "sum of pred:  4064.0 \n",
            "\n",
            "0.6224653032613807\n",
            "iterate_num:  3 \n",
            " sum of test_y: 102.0\n",
            "sum of pred:  4236.0 \n",
            "\n",
            "0.6205307182602268\n",
            "iterate_num:  4 \n",
            " sum of test_y: 101.0\n",
            "sum of pred:  4285.0 \n",
            "\n",
            "0.6186712645249128\n",
            "avg_AUC :  0.6259312042402103\n",
            "avg_AUC_2 :  0.6257348774093096\n",
            "frauds_prec :  0.0131310195650905\n",
            "fradus_recall :  0.545403805086391\n",
            "\n",
            "\n",
            "('wrd+spc', ['Litigious_3_p', 'Litigious_3_n', 'Litigious_3_new', 'Litigious_3_dis', 'Uncertainty_3_p', 'Uncertainty_3_n', 'Uncertainty_3_new', 'Uncertainty_3_dis', 'StrongModal_3_p', 'StrongModal_3_n', 'StrongModal_3_new', 'StrongModal_3_dis', 'Reward_3_p', 'Reward_3_n', 'Reward_3_new', 'Reward_3_dis', 'Achieve_3_p', 'Achieve_3_n', 'Achieve_3_new', 'Achieve_3_dis', 'Positive_3_p', 'Positive_3_n', 'Positive_3_new', 'Positive_3_dis', 'Discrep_3_p', 'Discrep_3_n', 'Discrep_3_new', 'Discrep_3_dis', 'Compare_3_p', 'Compare_3_n', 'Compare_3_new', 'Compare_3_dis', 'Negative_3_p', 'Negative_3_n', 'Negative_3_new', 'Negative_3_dis', 'WeakModal_3_p', 'WeakModal_3_n', 'WeakModal_3_new', 'WeakModal_3_dis', 's1', 'pastavg3', 'cr3'])\n",
            "0.6259312042402103\n",
            "============================\n",
            "iterate_num:  1 \n",
            " sum of test_y: 102.0\n",
            "sum of pred:  3858.0 \n",
            "\n",
            "0.6660264318097826\n",
            "iterate_num:  2 \n",
            " sum of test_y: 102.0\n",
            "sum of pred:  3979.0 \n",
            "\n",
            "0.6799840722059994\n",
            "iterate_num:  3 \n",
            " sum of test_y: 102.0\n",
            "sum of pred:  4044.0 \n",
            "\n",
            "0.7472616513201157\n",
            "iterate_num:  4 \n",
            " sum of test_y: 101.0\n",
            "sum of pred:  3906.0 \n",
            "\n",
            "0.7097426758869144\n",
            "avg_AUC :  0.700753707805703\n",
            "avg_AUC_2 :  0.7006533986732005\n",
            "frauds_prec :  0.016707706683578297\n",
            "fradus_recall :  0.648611920015531\n",
            "\n",
            "\n",
            "('perf+spc+wrd', ['aqi', 'asset_turnover', 'depi', 'gmi', 'opm', 'rg', 'sg', 'sgee', 'ch_rec', 'ch_inv', 'soft_asset', 'ch_cs', 'ch_roa', 'issue', 's1', 'pastavg3', 'cr3', 'Litigious_3_p', 'Litigious_3_n', 'Litigious_3_new', 'Litigious_3_dis', 'Uncertainty_3_p', 'Uncertainty_3_n', 'Uncertainty_3_new', 'Uncertainty_3_dis', 'StrongModal_3_p', 'StrongModal_3_n', 'StrongModal_3_new', 'StrongModal_3_dis', 'Reward_3_p', 'Reward_3_n', 'Reward_3_new', 'Reward_3_dis', 'Achieve_3_p', 'Achieve_3_n', 'Achieve_3_new', 'Achieve_3_dis', 'Positive_3_p', 'Positive_3_n', 'Positive_3_new', 'Positive_3_dis', 'Discrep_3_p', 'Discrep_3_n', 'Discrep_3_new', 'Discrep_3_dis', 'Compare_3_p', 'Compare_3_n', 'Compare_3_new', 'Compare_3_dis', 'Negative_3_p', 'Negative_3_n', 'Negative_3_new', 'Negative_3_dis', 'WeakModal_3_p', 'WeakModal_3_n', 'WeakModal_3_new', 'WeakModal_3_dis'])\n",
            "0.700753707805703\n",
            "============================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdVMNLDaLAMR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_R7MWNdnMexr"
      },
      "source": [
        "# NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZ9W1cJrNOuu"
      },
      "source": [
        "def model_M1(n1,n2):\r\n",
        "    model_m1 = Sequential(name = 'M1')\r\n",
        "    model_m1.add(BatchNormalization())\r\n",
        "    model_m1.add(layers.Dense(n1,name = 'layer_1',activation='relu'))\r\n",
        "    model_m1.add(layers.Dropout(0.3))\r\n",
        "    #model_m1.add(layers.Dense(64,name = 'layer_2'))\r\n",
        "    model_m1.add(layers.Dense(n2,name = 'layer_2',activation='relu'))\r\n",
        "    model_m1.add(layers.Dense(1,activation='sigmoid'))\r\n",
        "    #model_m1.summary()\r\n",
        "    return model_m1"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mapP-xQTNTMv"
      },
      "source": [
        "def performance_measure(pred_yp, y):\r\n",
        "    '''\r\n",
        "    Given lists of predicted y probability and x, y, return a dataframe of AR, AUC, Brier, Decile Table\r\n",
        "    '''\r\n",
        "    \r\n",
        "    tenc_dat = pd.DataFrame({'y_true':y,'probability':pred_yp.flatten()})\r\n",
        "    tenc_dat.sort_values('probability',axis = 0,ascending=False, inplace = True)\r\n",
        "    tenc_dat.index = range(0,len(tenc_dat))\r\n",
        "    y = tenc_dat['y_true']\r\n",
        "    point = float(len(tenc_dat))/10\r\n",
        "    point = int(round(point))\r\n",
        "    tenc = []\r\n",
        "    for i in range(0,10):\r\n",
        "        tenc.append(y[(i*point):((i+1)*point)])\r\n",
        "    tenc[9]=tenc[9].append(y[10*point:])\r\n",
        "    total = sum(y)\r\n",
        "    num_of_bkr = []\r\n",
        "    for j in range(0,10):\r\n",
        "        num_of_bkr.append(sum(tenc[j]))\r\n",
        "    tencile_bkr = np.array(num_of_bkr)\r\n",
        "    rate = tencile_bkr.astype(float)/total\r\n",
        "\r\n",
        "    return rate"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGDx2QzbNZcD"
      },
      "source": [
        "class AUCEvaluation(Callback):\r\n",
        "    \"\"\" Show AUC after interval number of epoches \"\"\"\r\n",
        "    def __init__(self, validation_data=(), interval=1):\r\n",
        "        super(Callback, self).__init__()\r\n",
        "        self.interval = interval\r\n",
        "        self.X_val, self.y_val = validation_data\r\n",
        "\r\n",
        "    def on_epoch_end(self, epoch, logs={}):\r\n",
        "        if epoch % self.interval == 0:\r\n",
        "            y_pred = self.model.predict(self.X_val, verbose=0)\r\n",
        "            score = roc_auc_score(self.y_val, y_pred)\r\n",
        "            logs['auc'] = score\r\n",
        "            tencile=performance_measure(y_pred, self.y_val)\r\n",
        "            logs['tencile'] = tencile\r\n",
        "            print(\" epoch:{:d} auc: {:.4f}\".format(epoch, score))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XNsDIM5NdG0"
      },
      "source": [
        "def fit_model( model,x_train, y_train, x_val, y_val, x_test, y_test, model_name, verbose = 0):\r\n",
        "    \r\n",
        "    history = None\r\n",
        "    result = None\r\n",
        "    \r\n",
        "    model_df = model\r\n",
        "    \r\n",
        "    #class weight for test \r\n",
        "    class_weights = class_weight.compute_class_weight('balanced',\r\n",
        "                              np.unique(y_train),\r\n",
        "                              y_train)\r\n",
        "    class_weights = {l:c for l,c in zip(np.unique(y_train), class_weights)}\r\n",
        "    # class weight for val\r\n",
        "    val_class_weights = class_weight.compute_class_weight('balanced',\r\n",
        "                                np.unique(y_val),\r\n",
        "                                y_val)\r\n",
        "    val_class_weights = {l:c for l,c in zip(np.unique(y_val), val_class_weights)}\r\n",
        "    val_sample_weights = []\r\n",
        "    for y in y_val:\r\n",
        "        if y == 1:\r\n",
        "          val_sample_weights.append(val_class_weights[1])\r\n",
        "        else: val_sample_weights.append(val_class_weights[0])\r\n",
        "    val_sample_weights = np.asarray(val_sample_weights)\r\n",
        "    \r\n",
        "    \r\n",
        "    auc_eval = AUCEvaluation(validation_data=(x_val, y_val), interval=1)\r\n",
        "    earlyStopping = EarlyStopping(monitor='val_my_auc',patience = 3, \r\n",
        "                      verbose =verbose, mode ='max')\r\n",
        "    checkpoint = ModelCheckpoint(model_name,monitor='val_my_auc',verbose=verbose,\r\n",
        "              save_best_only=True, save_weights_only=True, mode ='max')\r\n",
        "\r\n",
        "    opt = optimizers.RMSprop(lr=0.0005)\r\n",
        "    model_df.compile(optimizer= opt,\r\n",
        "              loss='binary_crossentropy',\r\n",
        "              metrics=['accuracy', metrics.AUC(name='my_auc')])\r\n",
        "    \r\n",
        "    history = model_df.fit(x_train,\r\n",
        "                y_train,\r\n",
        "                epochs=30,\r\n",
        "                batch_size=512,\r\n",
        "                callbacks=[auc_eval, earlyStopping,checkpoint], #checkpoint\r\n",
        "                class_weight = class_weights, \\\r\n",
        "                validation_data=(x_val,y_val,val_sample_weights)) \r\n",
        "    model_df.load_weights(model_name)\r\n",
        "    y_pred = model_df.predict(x_test)\r\n",
        "    y_pred_1=np.reshape(y_pred, -1)\r\n",
        "    auc_score = roc_auc_score(y_test, y_pred_1)\r\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_1)\r\n",
        "    print(\"AUC: \" ,round(auc_score,4))\r\n",
        "        \r\n",
        "    return history, auc_score, fpr, tpr, thresholds, [y_test, y_pred_1]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjXb2Su8OHwC"
      },
      "source": [
        "def cross_val(n1, n2, data,label,columns_fl,model_name):\r\n",
        "    tprs = []\r\n",
        "    auc_list = []\r\n",
        "    mean_fpr = np.linspace(0,1,100)\r\n",
        "    \r\n",
        "    kf = StratifiedKFold(n_splits = 4, shuffle = True)\r\n",
        "    c = 0\r\n",
        "    data_1 = data[columns_fl + [label]]\r\n",
        "    data_1 = data_1.dropna()\r\n",
        "    data_target = data_1.reset_index(drop = True)\r\n",
        "    \r\n",
        "    predicted_res =[]\r\n",
        "    print('dataset: ', data_target.shape, '/n', sum(data_target.label))\r\n",
        "    \r\n",
        "    \r\n",
        "    for train_index, test_index in kf.split(data_target[columns_fl],data_target[label]):\r\n",
        "        \r\n",
        "        c += 1\r\n",
        "\r\n",
        "        train_data = data_target.loc[train_index,columns_fl]\r\n",
        "        train_label = data_target.loc[train_index,label]\r\n",
        "        test_x = data_target.loc[test_index,columns_fl].to_numpy()\r\n",
        "        test_y = data_target.loc[test_index,label] \r\n",
        "\r\n",
        "        print('iterate_num: ', c, '\\n','sum of test_y:', sum(test_y))\r\n",
        "        train_x, val_x, train_y, val_y = train_test_split(train_data.to_numpy(), train_label.to_numpy(),test_size=0.2, \\\r\n",
        "                                                            random_state=42, stratify = train_label)\r\n",
        "        print('train_x_shape',train_x.shape)\r\n",
        "        model = model_M1(n1,n2)\r\n",
        "        mod_res = fit_model(model, train_x, train_y, val_x, val_y, test_x, test_y, model_name+'_'+str(c)+'_NN_model')\r\n",
        "        auc_list.append(mod_res[1])\r\n",
        "        tprs.append(np.interp(mean_fpr, mod_res[2], mod_res[3]))\r\n",
        "#         print(type(mod_res[-1]))\r\n",
        "#         print(len(mod_res[-1]))\r\n",
        "#         print(mod_res[-1])\r\n",
        "        temp_pred_res = [mod_res[-1],test_index]\r\n",
        "        #print(temp_pred_res)\r\n",
        "        predicted_res.append(temp_pred_res)\r\n",
        "        \r\n",
        "    mean_tpr = np.mean(tprs, axis=0)\r\n",
        "    print('avg_AUC : ', np.mean(auc_list))\r\n",
        "    print('avg_AUC_2 : ', auc(mean_fpr, mean_tpr))\r\n",
        "    \r\n",
        "    return np.mean(auc_list),mean_tpr, predicted_res"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dC6UwbsmOMOO",
        "outputId": "98e1e583-df8f-4168-d970-29c4e0660f42"
      },
      "source": [
        "label = 'label'\r\n",
        "vs_fl = {'perf':v_perf, 'perf+spc': v_perf +v_1+v_2, 'wrd+spc': selected_new_all +v_1 +v_2,'perf+spc+wrd': v_perf +v_1 +v_2 +selected_new_all}\r\n",
        "#\r\n",
        "mean_tpr_dict_nn = dict()\r\n",
        "pred_res_nn = dict()\r\n",
        "for fl in vs_fl.items():\r\n",
        "    print(fl[1])\r\n",
        "    n1 = len(fl[1])*2\r\n",
        "    n2 = len(fl[1])\r\n",
        "    #M1 = model_M1(n1,n2)\r\n",
        "    NN = cross_val(n1, n2, df_fl, label, fl[1], fl[0])\r\n",
        "    print(fl)\r\n",
        "    print(NN[0])\r\n",
        "    mean_tpr_dict_nn[fl[0]] = NN[1]\r\n",
        "    pred_res_nn[fl[0]] = NN[2]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['aqi', 'asset_turnover', 'depi', 'gmi', 'opm', 'rg', 'sg', 'sgee', 'ch_rec', 'ch_inv', 'soft_asset', 'ch_cs', 'ch_roa', 'issue']\n",
            "iterate_num:  1 \n",
            " sum of test_y: 122.0\n",
            "train_x_shape (32180, 14)\n",
            "Epoch 1/30\n",
            "63/63 [==============================] - 3s 24ms/step - loss: 0.7030 - accuracy: 0.5836 - my_auc: 0.5588 - val_loss: 0.6930 - val_accuracy: 0.4172 - val_my_auc: 0.5044\n",
            " epoch:0 auc: 0.5028\n",
            "Epoch 2/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6649 - accuracy: 0.5973 - my_auc: 0.6450 - val_loss: 0.6821 - val_accuracy: 0.4778 - val_my_auc: 0.5864\n",
            " epoch:1 auc: 0.5858\n",
            "Epoch 3/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6703 - accuracy: 0.6026 - my_auc: 0.6424 - val_loss: 0.6709 - val_accuracy: 0.5717 - val_my_auc: 0.6321\n",
            " epoch:2 auc: 0.6329\n",
            "Epoch 4/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6916 - accuracy: 0.6024 - my_auc: 0.6239 - val_loss: 0.6621 - val_accuracy: 0.6181 - val_my_auc: 0.6494\n",
            " epoch:3 auc: 0.6509\n",
            "Epoch 5/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6777 - accuracy: 0.6263 - my_auc: 0.6345 - val_loss: 0.6555 - val_accuracy: 0.6326 - val_my_auc: 0.6628\n",
            " epoch:4 auc: 0.6635\n",
            "Epoch 6/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6314 - accuracy: 0.6283 - my_auc: 0.6774 - val_loss: 0.6525 - val_accuracy: 0.6578 - val_my_auc: 0.6675\n",
            " epoch:5 auc: 0.6671\n",
            "Epoch 7/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6216 - accuracy: 0.6379 - my_auc: 0.6739 - val_loss: 0.6475 - val_accuracy: 0.6520 - val_my_auc: 0.6773\n",
            " epoch:6 auc: 0.6769\n",
            "Epoch 8/30\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.6355 - accuracy: 0.6378 - my_auc: 0.6560 - val_loss: 0.6452 - val_accuracy: 0.6540 - val_my_auc: 0.6809\n",
            " epoch:7 auc: 0.6806\n",
            "Epoch 9/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6478 - accuracy: 0.6377 - my_auc: 0.6743 - val_loss: 0.6427 - val_accuracy: 0.6683 - val_my_auc: 0.6838\n",
            " epoch:8 auc: 0.6843\n",
            "Epoch 10/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6591 - accuracy: 0.6376 - my_auc: 0.6793 - val_loss: 0.6421 - val_accuracy: 0.6736 - val_my_auc: 0.6847\n",
            " epoch:9 auc: 0.6842\n",
            "Epoch 11/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6098 - accuracy: 0.6496 - my_auc: 0.6887 - val_loss: 0.6402 - val_accuracy: 0.6619 - val_my_auc: 0.6874\n",
            " epoch:10 auc: 0.6872\n",
            "Epoch 12/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6104 - accuracy: 0.6493 - my_auc: 0.7064 - val_loss: 0.6382 - val_accuracy: 0.6572 - val_my_auc: 0.6901\n",
            " epoch:11 auc: 0.6902\n",
            "Epoch 13/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6490 - accuracy: 0.6330 - my_auc: 0.6950 - val_loss: 0.6395 - val_accuracy: 0.6755 - val_my_auc: 0.6889\n",
            " epoch:12 auc: 0.6887\n",
            "Epoch 14/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6535 - accuracy: 0.6382 - my_auc: 0.6549 - val_loss: 0.6394 - val_accuracy: 0.6701 - val_my_auc: 0.6889\n",
            " epoch:13 auc: 0.6883\n",
            "Epoch 15/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6669 - accuracy: 0.6328 - my_auc: 0.6636 - val_loss: 0.6381 - val_accuracy: 0.6559 - val_my_auc: 0.6907\n",
            " epoch:14 auc: 0.6906\n",
            "Epoch 16/30\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.6578 - accuracy: 0.6235 - my_auc: 0.6835 - val_loss: 0.6366 - val_accuracy: 0.6626 - val_my_auc: 0.6940\n",
            " epoch:15 auc: 0.6942\n",
            "Epoch 17/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6287 - accuracy: 0.6392 - my_auc: 0.6844 - val_loss: 0.6367 - val_accuracy: 0.6591 - val_my_auc: 0.6938\n",
            " epoch:16 auc: 0.6934\n",
            "Epoch 18/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6118 - accuracy: 0.6459 - my_auc: 0.6868 - val_loss: 0.6356 - val_accuracy: 0.6520 - val_my_auc: 0.6948\n",
            " epoch:17 auc: 0.6948\n",
            "Epoch 19/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6451 - accuracy: 0.6246 - my_auc: 0.6935 - val_loss: 0.6358 - val_accuracy: 0.6602 - val_my_auc: 0.6953\n",
            " epoch:18 auc: 0.6952\n",
            "Epoch 20/30\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.6029 - accuracy: 0.6393 - my_auc: 0.7003 - val_loss: 0.6345 - val_accuracy: 0.6433 - val_my_auc: 0.6953\n",
            " epoch:19 auc: 0.6957\n",
            "Epoch 21/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6065 - accuracy: 0.6294 - my_auc: 0.6941 - val_loss: 0.6340 - val_accuracy: 0.6428 - val_my_auc: 0.6968\n",
            " epoch:20 auc: 0.6967\n",
            "Epoch 22/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6380 - accuracy: 0.6149 - my_auc: 0.7047 - val_loss: 0.6336 - val_accuracy: 0.6516 - val_my_auc: 0.6978\n",
            " epoch:21 auc: 0.6977\n",
            "Epoch 23/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6009 - accuracy: 0.6332 - my_auc: 0.7126 - val_loss: 0.6328 - val_accuracy: 0.6475 - val_my_auc: 0.6993\n",
            " epoch:22 auc: 0.6990\n",
            "Epoch 24/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6139 - accuracy: 0.6317 - my_auc: 0.7195 - val_loss: 0.6328 - val_accuracy: 0.6514 - val_my_auc: 0.6989\n",
            " epoch:23 auc: 0.6991\n",
            "Epoch 25/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6069 - accuracy: 0.6335 - my_auc: 0.7064 - val_loss: 0.6317 - val_accuracy: 0.6409 - val_my_auc: 0.7003\n",
            " epoch:24 auc: 0.7008\n",
            "Epoch 26/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.5944 - accuracy: 0.6209 - my_auc: 0.7031 - val_loss: 0.6312 - val_accuracy: 0.6445 - val_my_auc: 0.7020\n",
            " epoch:25 auc: 0.7021\n",
            "Epoch 27/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6184 - accuracy: 0.6252 - my_auc: 0.6942 - val_loss: 0.6309 - val_accuracy: 0.6393 - val_my_auc: 0.7025\n",
            " epoch:26 auc: 0.7027\n",
            "Epoch 28/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.5850 - accuracy: 0.6229 - my_auc: 0.7046 - val_loss: 0.6307 - val_accuracy: 0.6290 - val_my_auc: 0.7014\n",
            " epoch:27 auc: 0.7020\n",
            "Epoch 29/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6350 - accuracy: 0.6088 - my_auc: 0.7049 - val_loss: 0.6310 - val_accuracy: 0.6417 - val_my_auc: 0.7028\n",
            " epoch:28 auc: 0.7026\n",
            "Epoch 30/30\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.6056 - accuracy: 0.6237 - my_auc: 0.6744 - val_loss: 0.6307 - val_accuracy: 0.6306 - val_my_auc: 0.7028\n",
            " epoch:29 auc: 0.7030\n",
            "AUC:  0.6613\n",
            "iterate_num:  2 \n",
            " sum of test_y: 122.0\n",
            "train_x_shape (32180, 14)\n",
            "Epoch 1/30\n",
            "63/63 [==============================] - 3s 25ms/step - loss: 0.6915 - accuracy: 0.2894 - my_auc: 0.5100 - val_loss: 0.6923 - val_accuracy: 0.1689 - val_my_auc: 0.5436\n",
            " epoch:0 auc: 0.5425\n",
            "Epoch 2/30\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.6974 - accuracy: 0.4558 - my_auc: 0.5612 - val_loss: 0.6863 - val_accuracy: 0.2719 - val_my_auc: 0.5806\n",
            " epoch:1 auc: 0.5806\n",
            "Epoch 3/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6733 - accuracy: 0.5685 - my_auc: 0.6059 - val_loss: 0.6809 - val_accuracy: 0.4497 - val_my_auc: 0.6099\n",
            " epoch:2 auc: 0.6114\n",
            "Epoch 4/30\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.6699 - accuracy: 0.6290 - my_auc: 0.5974 - val_loss: 0.6784 - val_accuracy: 0.5306 - val_my_auc: 0.6192\n",
            " epoch:3 auc: 0.6191\n",
            "Epoch 5/30\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.6948 - accuracy: 0.6176 - my_auc: 0.6212 - val_loss: 0.6771 - val_accuracy: 0.6120 - val_my_auc: 0.6176\n",
            " epoch:4 auc: 0.6173\n",
            "Epoch 6/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6716 - accuracy: 0.6717 - my_auc: 0.6480 - val_loss: 0.6783 - val_accuracy: 0.6266 - val_my_auc: 0.6185\n",
            " epoch:5 auc: 0.6179\n",
            "Epoch 7/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6688 - accuracy: 0.6516 - my_auc: 0.6648 - val_loss: 0.6786 - val_accuracy: 0.6443 - val_my_auc: 0.6225\n",
            " epoch:6 auc: 0.6229\n",
            "Epoch 8/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6359 - accuracy: 0.6699 - my_auc: 0.6331 - val_loss: 0.6803 - val_accuracy: 0.6399 - val_my_auc: 0.6237\n",
            " epoch:7 auc: 0.6234\n",
            "Epoch 9/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6703 - accuracy: 0.6500 - my_auc: 0.6341 - val_loss: 0.6821 - val_accuracy: 0.6353 - val_my_auc: 0.6228\n",
            " epoch:8 auc: 0.6235\n",
            "Epoch 10/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6431 - accuracy: 0.6514 - my_auc: 0.6823 - val_loss: 0.6834 - val_accuracy: 0.6376 - val_my_auc: 0.6252\n",
            " epoch:9 auc: 0.6250\n",
            "Epoch 11/30\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.6432 - accuracy: 0.6498 - my_auc: 0.6774 - val_loss: 0.6839 - val_accuracy: 0.6299 - val_my_auc: 0.6262\n",
            " epoch:10 auc: 0.6268\n",
            "Epoch 12/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6530 - accuracy: 0.6381 - my_auc: 0.6760 - val_loss: 0.6856 - val_accuracy: 0.6352 - val_my_auc: 0.6270\n",
            " epoch:11 auc: 0.6267\n",
            "Epoch 13/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6943 - accuracy: 0.6415 - my_auc: 0.6525 - val_loss: 0.6861 - val_accuracy: 0.6396 - val_my_auc: 0.6273\n",
            " epoch:12 auc: 0.6269\n",
            "Epoch 14/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6507 - accuracy: 0.6570 - my_auc: 0.6716 - val_loss: 0.6868 - val_accuracy: 0.6352 - val_my_auc: 0.6259\n",
            " epoch:13 auc: 0.6261\n",
            "Epoch 15/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6378 - accuracy: 0.6542 - my_auc: 0.6940 - val_loss: 0.6892 - val_accuracy: 0.6334 - val_my_auc: 0.6229\n",
            " epoch:14 auc: 0.6234\n",
            "Epoch 16/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6984 - accuracy: 0.6322 - my_auc: 0.6847 - val_loss: 0.6909 - val_accuracy: 0.6566 - val_my_auc: 0.6253\n",
            " epoch:15 auc: 0.6251\n",
            "AUC:  0.6749\n",
            "iterate_num:  3 \n",
            " sum of test_y: 122.0\n",
            "train_x_shape (32180, 14)\n",
            "Epoch 1/30\n",
            "63/63 [==============================] - 3s 24ms/step - loss: 0.8430 - accuracy: 0.9502 - my_auc: 0.5522 - val_loss: 0.7213 - val_accuracy: 0.8945 - val_my_auc: 0.5166\n",
            " epoch:0 auc: 0.5168\n",
            "Epoch 2/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.7125 - accuracy: 0.8418 - my_auc: 0.5977 - val_loss: 0.6927 - val_accuracy: 0.6265 - val_my_auc: 0.5422\n",
            " epoch:1 auc: 0.5405\n",
            "Epoch 3/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.7025 - accuracy: 0.7290 - my_auc: 0.6349 - val_loss: 0.6824 - val_accuracy: 0.4887 - val_my_auc: 0.5661\n",
            " epoch:2 auc: 0.5642\n",
            "Epoch 4/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6998 - accuracy: 0.6607 - my_auc: 0.6138 - val_loss: 0.6767 - val_accuracy: 0.4444 - val_my_auc: 0.5833\n",
            " epoch:3 auc: 0.5824\n",
            "Epoch 5/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6511 - accuracy: 0.6298 - my_auc: 0.6450 - val_loss: 0.6725 - val_accuracy: 0.4729 - val_my_auc: 0.5946\n",
            " epoch:4 auc: 0.5948\n",
            "Epoch 6/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6490 - accuracy: 0.6264 - my_auc: 0.6546 - val_loss: 0.6700 - val_accuracy: 0.5150 - val_my_auc: 0.6040\n",
            " epoch:5 auc: 0.6037\n",
            "Epoch 7/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6749 - accuracy: 0.6275 - my_auc: 0.6379 - val_loss: 0.6672 - val_accuracy: 0.5385 - val_my_auc: 0.6132\n",
            " epoch:6 auc: 0.6133\n",
            "Epoch 8/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6239 - accuracy: 0.6318 - my_auc: 0.6867 - val_loss: 0.6665 - val_accuracy: 0.5588 - val_my_auc: 0.6190\n",
            " epoch:7 auc: 0.6182\n",
            "Epoch 9/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6562 - accuracy: 0.6207 - my_auc: 0.6919 - val_loss: 0.6674 - val_accuracy: 0.6035 - val_my_auc: 0.6226\n",
            " epoch:8 auc: 0.6226\n",
            "Epoch 10/30\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.6342 - accuracy: 0.6555 - my_auc: 0.6908 - val_loss: 0.6658 - val_accuracy: 0.5897 - val_my_auc: 0.6277\n",
            " epoch:9 auc: 0.6278\n",
            "Epoch 11/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.5950 - accuracy: 0.6463 - my_auc: 0.7155 - val_loss: 0.6650 - val_accuracy: 0.5812 - val_my_auc: 0.6314\n",
            " epoch:10 auc: 0.6315\n",
            "Epoch 12/30\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.6289 - accuracy: 0.6305 - my_auc: 0.7215 - val_loss: 0.6646 - val_accuracy: 0.5758 - val_my_auc: 0.6338\n",
            " epoch:11 auc: 0.6339\n",
            "Epoch 13/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6170 - accuracy: 0.6299 - my_auc: 0.7101 - val_loss: 0.6643 - val_accuracy: 0.5828 - val_my_auc: 0.6354\n",
            " epoch:12 auc: 0.6351\n",
            "Epoch 14/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6079 - accuracy: 0.6330 - my_auc: 0.7032 - val_loss: 0.6636 - val_accuracy: 0.5785 - val_my_auc: 0.6374\n",
            " epoch:13 auc: 0.6371\n",
            "Epoch 15/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6228 - accuracy: 0.6241 - my_auc: 0.6758 - val_loss: 0.6663 - val_accuracy: 0.5945 - val_my_auc: 0.6370\n",
            " epoch:14 auc: 0.6370\n",
            "Epoch 16/30\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.6288 - accuracy: 0.6280 - my_auc: 0.6912 - val_loss: 0.6659 - val_accuracy: 0.5889 - val_my_auc: 0.6380\n",
            " epoch:15 auc: 0.6382\n",
            "Epoch 17/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6312 - accuracy: 0.6236 - my_auc: 0.6928 - val_loss: 0.6658 - val_accuracy: 0.5854 - val_my_auc: 0.6386\n",
            " epoch:16 auc: 0.6386\n",
            "Epoch 18/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6722 - accuracy: 0.6146 - my_auc: 0.6890 - val_loss: 0.6665 - val_accuracy: 0.5823 - val_my_auc: 0.6380\n",
            " epoch:17 auc: 0.6378\n",
            "Epoch 19/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6219 - accuracy: 0.6276 - my_auc: 0.7046 - val_loss: 0.6681 - val_accuracy: 0.5831 - val_my_auc: 0.6385\n",
            " epoch:18 auc: 0.6382\n",
            "Epoch 20/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.5990 - accuracy: 0.6228 - my_auc: 0.7249 - val_loss: 0.6689 - val_accuracy: 0.5942 - val_my_auc: 0.6410\n",
            " epoch:19 auc: 0.6408\n",
            "Epoch 21/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6194 - accuracy: 0.6280 - my_auc: 0.7179 - val_loss: 0.6699 - val_accuracy: 0.5991 - val_my_auc: 0.6407\n",
            " epoch:20 auc: 0.6408\n",
            "Epoch 22/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6063 - accuracy: 0.6318 - my_auc: 0.7357 - val_loss: 0.6714 - val_accuracy: 0.6076 - val_my_auc: 0.6400\n",
            " epoch:21 auc: 0.6396\n",
            "Epoch 23/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6033 - accuracy: 0.6387 - my_auc: 0.7420 - val_loss: 0.6703 - val_accuracy: 0.5905 - val_my_auc: 0.6407\n",
            " epoch:22 auc: 0.6402\n",
            "AUC:  0.6553\n",
            "iterate_num:  4 \n",
            " sum of test_y: 121.0\n",
            "train_x_shape (32181, 14)\n",
            "Epoch 1/30\n",
            "63/63 [==============================] - 3s 26ms/step - loss: 0.7374 - accuracy: 0.4365 - my_auc: 0.4429 - val_loss: 0.6904 - val_accuracy: 0.1454 - val_my_auc: 0.5606\n",
            " epoch:0 auc: 0.5621\n",
            "Epoch 2/30\n",
            "63/63 [==============================] - 0s 8ms/step - loss: 0.6821 - accuracy: 0.5767 - my_auc: 0.5075 - val_loss: 0.6827 - val_accuracy: 0.2928 - val_my_auc: 0.6076\n",
            " epoch:1 auc: 0.6072\n",
            "Epoch 3/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6988 - accuracy: 0.6168 - my_auc: 0.5149 - val_loss: 0.6786 - val_accuracy: 0.4105 - val_my_auc: 0.6250\n",
            " epoch:2 auc: 0.6225\n",
            "Epoch 4/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6658 - accuracy: 0.6277 - my_auc: 0.6067 - val_loss: 0.6750 - val_accuracy: 0.4733 - val_my_auc: 0.6216\n",
            " epoch:3 auc: 0.6224\n",
            "Epoch 5/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6904 - accuracy: 0.6016 - my_auc: 0.5911 - val_loss: 0.6691 - val_accuracy: 0.5232 - val_my_auc: 0.6360\n",
            " epoch:4 auc: 0.6342\n",
            "Epoch 6/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6567 - accuracy: 0.6266 - my_auc: 0.5940 - val_loss: 0.6638 - val_accuracy: 0.5308 - val_my_auc: 0.6409\n",
            " epoch:5 auc: 0.6403\n",
            "Epoch 7/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6726 - accuracy: 0.5853 - my_auc: 0.6341 - val_loss: 0.6589 - val_accuracy: 0.5410 - val_my_auc: 0.6429\n",
            " epoch:6 auc: 0.6442\n",
            "Epoch 8/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6162 - accuracy: 0.6092 - my_auc: 0.6374 - val_loss: 0.6552 - val_accuracy: 0.5267 - val_my_auc: 0.6471\n",
            " epoch:7 auc: 0.6476\n",
            "Epoch 9/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6390 - accuracy: 0.5806 - my_auc: 0.6216 - val_loss: 0.6516 - val_accuracy: 0.5322 - val_my_auc: 0.6528\n",
            " epoch:8 auc: 0.6532\n",
            "Epoch 10/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6640 - accuracy: 0.5532 - my_auc: 0.6173 - val_loss: 0.6481 - val_accuracy: 0.5466 - val_my_auc: 0.6595\n",
            " epoch:9 auc: 0.6580\n",
            "Epoch 11/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6954 - accuracy: 0.5598 - my_auc: 0.6069 - val_loss: 0.6442 - val_accuracy: 0.5573 - val_my_auc: 0.6676\n",
            " epoch:10 auc: 0.6657\n",
            "Epoch 12/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6682 - accuracy: 0.5733 - my_auc: 0.6253 - val_loss: 0.6424 - val_accuracy: 0.5539 - val_my_auc: 0.6668\n",
            " epoch:11 auc: 0.6677\n",
            "Epoch 13/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6409 - accuracy: 0.5780 - my_auc: 0.6531 - val_loss: 0.6402 - val_accuracy: 0.5520 - val_my_auc: 0.6712\n",
            " epoch:12 auc: 0.6709\n",
            "Epoch 14/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6568 - accuracy: 0.5568 - my_auc: 0.6312 - val_loss: 0.6397 - val_accuracy: 0.5357 - val_my_auc: 0.6712\n",
            " epoch:13 auc: 0.6712\n",
            "Epoch 15/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6709 - accuracy: 0.5385 - my_auc: 0.6575 - val_loss: 0.6371 - val_accuracy: 0.5592 - val_my_auc: 0.6750\n",
            " epoch:14 auc: 0.6751\n",
            "Epoch 16/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6548 - accuracy: 0.5663 - my_auc: 0.6773 - val_loss: 0.6380 - val_accuracy: 0.5676 - val_my_auc: 0.6729\n",
            " epoch:15 auc: 0.6723\n",
            "Epoch 17/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6445 - accuracy: 0.5775 - my_auc: 0.6342 - val_loss: 0.6354 - val_accuracy: 0.5830 - val_my_auc: 0.6768\n",
            " epoch:16 auc: 0.6767\n",
            "Epoch 18/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6482 - accuracy: 0.5890 - my_auc: 0.6712 - val_loss: 0.6351 - val_accuracy: 0.5751 - val_my_auc: 0.6755\n",
            " epoch:17 auc: 0.6753\n",
            "Epoch 19/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6095 - accuracy: 0.5877 - my_auc: 0.6664 - val_loss: 0.6359 - val_accuracy: 0.5667 - val_my_auc: 0.6730\n",
            " epoch:18 auc: 0.6727\n",
            "Epoch 20/30\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6643 - accuracy: 0.5648 - my_auc: 0.6372 - val_loss: 0.6358 - val_accuracy: 0.5633 - val_my_auc: 0.6723\n",
            " epoch:19 auc: 0.6721\n",
            "AUC:  0.6669\n",
            "avg_AUC :  0.664600909121805\n",
            "avg_AUC_2 :  0.6647527982712916\n",
            "('perf', ['aqi', 'asset_turnover', 'depi', 'gmi', 'opm', 'rg', 'sg', 'sgee', 'ch_rec', 'ch_inv', 'soft_asset', 'ch_cs', 'ch_roa', 'issue'])\n",
            "0.664600909121805\n",
            "['aqi', 'asset_turnover', 'depi', 'gmi', 'opm', 'rg', 'sg', 'sgee', 'ch_rec', 'ch_inv', 'soft_asset', 'ch_cs', 'ch_roa', 'issue', 's1', 'pastavg3', 'cr3']\n",
            "iterate_num:  1 \n",
            " sum of test_y: 102.0\n",
            "train_x_shape (27366, 17)\n",
            "Epoch 1/30\n",
            "54/54 [==============================] - 3s 29ms/step - loss: 0.7350 - accuracy: 0.5573 - my_auc: 0.4976 - val_loss: 0.6910 - val_accuracy: 0.1314 - val_my_auc: 0.5644\n",
            " epoch:0 auc: 0.5691\n",
            "Epoch 2/30\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 0.6738 - accuracy: 0.6327 - my_auc: 0.5327 - val_loss: 0.6845 - val_accuracy: 0.1840 - val_my_auc: 0.5969\n",
            " epoch:1 auc: 0.5975\n",
            "Epoch 3/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.6517 - accuracy: 0.6523 - my_auc: 0.6004 - val_loss: 0.6747 - val_accuracy: 0.3059 - val_my_auc: 0.6125\n",
            " epoch:2 auc: 0.6143\n",
            "Epoch 4/30\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 0.6393 - accuracy: 0.6897 - my_auc: 0.6103 - val_loss: 0.6687 - val_accuracy: 0.4160 - val_my_auc: 0.6228\n",
            " epoch:3 auc: 0.6230\n",
            "Epoch 5/30\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 0.6275 - accuracy: 0.6904 - my_auc: 0.6808 - val_loss: 0.6644 - val_accuracy: 0.5386 - val_my_auc: 0.6295\n",
            " epoch:4 auc: 0.6291\n",
            "Epoch 6/30\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 0.5922 - accuracy: 0.7186 - my_auc: 0.6943 - val_loss: 0.6621 - val_accuracy: 0.5927 - val_my_auc: 0.6350\n",
            " epoch:5 auc: 0.6349\n",
            "Epoch 7/30\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 0.6382 - accuracy: 0.6897 - my_auc: 0.6713 - val_loss: 0.6622 - val_accuracy: 0.6346 - val_my_auc: 0.6399\n",
            " epoch:6 auc: 0.6403\n",
            "Epoch 8/30\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 0.6389 - accuracy: 0.6881 - my_auc: 0.6788 - val_loss: 0.6634 - val_accuracy: 0.6453 - val_my_auc: 0.6449\n",
            " epoch:7 auc: 0.6449\n",
            "Epoch 9/30\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 0.5913 - accuracy: 0.6915 - my_auc: 0.7131 - val_loss: 0.6631 - val_accuracy: 0.6258 - val_my_auc: 0.6482\n",
            " epoch:8 auc: 0.6481\n",
            "Epoch 10/30\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 0.6340 - accuracy: 0.6501 - my_auc: 0.7019 - val_loss: 0.6655 - val_accuracy: 0.6326 - val_my_auc: 0.6501\n",
            " epoch:9 auc: 0.6502\n",
            "Epoch 11/30\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 0.6087 - accuracy: 0.6436 - my_auc: 0.6972 - val_loss: 0.6671 - val_accuracy: 0.6504 - val_my_auc: 0.6529\n",
            " epoch:10 auc: 0.6525\n",
            "Epoch 12/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.6373 - accuracy: 0.6440 - my_auc: 0.6788 - val_loss: 0.6672 - val_accuracy: 0.6592 - val_my_auc: 0.6549\n",
            " epoch:11 auc: 0.6551\n",
            "Epoch 13/30\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 0.6236 - accuracy: 0.6535 - my_auc: 0.6998 - val_loss: 0.6676 - val_accuracy: 0.6466 - val_my_auc: 0.6561\n",
            " epoch:12 auc: 0.6559\n",
            "Epoch 14/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.6347 - accuracy: 0.6343 - my_auc: 0.7124 - val_loss: 0.6697 - val_accuracy: 0.6615 - val_my_auc: 0.6575\n",
            " epoch:13 auc: 0.6579\n",
            "Epoch 15/30\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 0.6250 - accuracy: 0.6502 - my_auc: 0.7086 - val_loss: 0.6711 - val_accuracy: 0.6643 - val_my_auc: 0.6584\n",
            " epoch:14 auc: 0.6579\n",
            "Epoch 16/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.6210 - accuracy: 0.6480 - my_auc: 0.7168 - val_loss: 0.6720 - val_accuracy: 0.6609 - val_my_auc: 0.6581\n",
            " epoch:15 auc: 0.6579\n",
            "Epoch 17/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.6050 - accuracy: 0.6458 - my_auc: 0.7151 - val_loss: 0.6752 - val_accuracy: 0.6735 - val_my_auc: 0.6587\n",
            " epoch:16 auc: 0.6590\n",
            "Epoch 18/30\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 0.6120 - accuracy: 0.6502 - my_auc: 0.7246 - val_loss: 0.6757 - val_accuracy: 0.6716 - val_my_auc: 0.6591\n",
            " epoch:17 auc: 0.6596\n",
            "Epoch 19/30\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 0.5753 - accuracy: 0.6601 - my_auc: 0.7527 - val_loss: 0.6753 - val_accuracy: 0.6665 - val_my_auc: 0.6614\n",
            " epoch:18 auc: 0.6614\n",
            "Epoch 20/30\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 0.6234 - accuracy: 0.6418 - my_auc: 0.7025 - val_loss: 0.6759 - val_accuracy: 0.6697 - val_my_auc: 0.6626\n",
            " epoch:19 auc: 0.6623\n",
            "Epoch 21/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.6090 - accuracy: 0.6504 - my_auc: 0.7043 - val_loss: 0.6770 - val_accuracy: 0.6796 - val_my_auc: 0.6658\n",
            " epoch:20 auc: 0.6648\n",
            "Epoch 22/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.5976 - accuracy: 0.6527 - my_auc: 0.7053 - val_loss: 0.6756 - val_accuracy: 0.6735 - val_my_auc: 0.6670\n",
            " epoch:21 auc: 0.6665\n",
            "Epoch 23/30\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 0.6016 - accuracy: 0.6502 - my_auc: 0.7391 - val_loss: 0.6762 - val_accuracy: 0.6675 - val_my_auc: 0.6667\n",
            " epoch:22 auc: 0.6662\n",
            "Epoch 24/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.5716 - accuracy: 0.6464 - my_auc: 0.7328 - val_loss: 0.6768 - val_accuracy: 0.6682 - val_my_auc: 0.6671\n",
            " epoch:23 auc: 0.6673\n",
            "Epoch 25/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.6093 - accuracy: 0.6441 - my_auc: 0.7340 - val_loss: 0.6781 - val_accuracy: 0.6723 - val_my_auc: 0.6681\n",
            " epoch:24 auc: 0.6682\n",
            "Epoch 26/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.6182 - accuracy: 0.6383 - my_auc: 0.7183 - val_loss: 0.6805 - val_accuracy: 0.6899 - val_my_auc: 0.6693\n",
            " epoch:25 auc: 0.6695\n",
            "Epoch 27/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.6216 - accuracy: 0.6522 - my_auc: 0.7253 - val_loss: 0.6782 - val_accuracy: 0.6808 - val_my_auc: 0.6720\n",
            " epoch:26 auc: 0.6720\n",
            "Epoch 28/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.5797 - accuracy: 0.6560 - my_auc: 0.7549 - val_loss: 0.6808 - val_accuracy: 0.6858 - val_my_auc: 0.6728\n",
            " epoch:27 auc: 0.6726\n",
            "Epoch 29/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.5943 - accuracy: 0.6614 - my_auc: 0.7142 - val_loss: 0.6810 - val_accuracy: 0.6843 - val_my_auc: 0.6730\n",
            " epoch:28 auc: 0.6732\n",
            "Epoch 30/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.5968 - accuracy: 0.6540 - my_auc: 0.7350 - val_loss: 0.6802 - val_accuracy: 0.6846 - val_my_auc: 0.6749\n",
            " epoch:29 auc: 0.6754\n",
            "AUC:  0.6902\n",
            "iterate_num:  2 \n",
            " sum of test_y: 102.0\n",
            "train_x_shape (27366, 17)\n",
            "Epoch 1/30\n",
            "54/54 [==============================] - 3s 25ms/step - loss: 0.6803 - accuracy: 0.6935 - my_auc: 0.5449 - val_loss: 0.7026 - val_accuracy: 0.9043 - val_my_auc: 0.4855\n",
            " epoch:0 auc: 0.4839\n",
            "Epoch 2/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.6903 - accuracy: 0.6441 - my_auc: 0.5746 - val_loss: 0.6909 - val_accuracy: 0.7512 - val_my_auc: 0.5514\n",
            " epoch:1 auc: 0.5508\n",
            "Epoch 3/30\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 0.7088 - accuracy: 0.6240 - my_auc: 0.5983 - val_loss: 0.6851 - val_accuracy: 0.7188 - val_my_auc: 0.5910\n",
            " epoch:2 auc: 0.5931\n",
            "Epoch 4/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.7090 - accuracy: 0.6594 - my_auc: 0.6030 - val_loss: 0.6787 - val_accuracy: 0.6732 - val_my_auc: 0.6245\n",
            " epoch:3 auc: 0.6229\n",
            "Epoch 5/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.6716 - accuracy: 0.6718 - my_auc: 0.6412 - val_loss: 0.6716 - val_accuracy: 0.6622 - val_my_auc: 0.6475\n",
            " epoch:4 auc: 0.6477\n",
            "Epoch 6/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.6455 - accuracy: 0.6700 - my_auc: 0.7052 - val_loss: 0.6647 - val_accuracy: 0.6747 - val_my_auc: 0.6672\n",
            " epoch:5 auc: 0.6675\n",
            "Epoch 7/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.6742 - accuracy: 0.6618 - my_auc: 0.6553 - val_loss: 0.6581 - val_accuracy: 0.6874 - val_my_auc: 0.6840\n",
            " epoch:6 auc: 0.6836\n",
            "Epoch 8/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.6425 - accuracy: 0.6831 - my_auc: 0.6630 - val_loss: 0.6512 - val_accuracy: 0.6399 - val_my_auc: 0.6931\n",
            " epoch:7 auc: 0.6930\n",
            "Epoch 9/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.6366 - accuracy: 0.6555 - my_auc: 0.6775 - val_loss: 0.6473 - val_accuracy: 0.6672 - val_my_auc: 0.6991\n",
            " epoch:8 auc: 0.6989\n",
            "Epoch 10/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.6551 - accuracy: 0.6625 - my_auc: 0.6844 - val_loss: 0.6428 - val_accuracy: 0.6656 - val_my_auc: 0.7061\n",
            " epoch:9 auc: 0.7050\n",
            "Epoch 11/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.6429 - accuracy: 0.6654 - my_auc: 0.6714 - val_loss: 0.6396 - val_accuracy: 0.6545 - val_my_auc: 0.7080\n",
            " epoch:10 auc: 0.7080\n",
            "Epoch 12/30\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 0.6206 - accuracy: 0.6620 - my_auc: 0.6969 - val_loss: 0.6383 - val_accuracy: 0.6505 - val_my_auc: 0.7072\n",
            " epoch:11 auc: 0.7077\n",
            "Epoch 13/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.6374 - accuracy: 0.6570 - my_auc: 0.6882 - val_loss: 0.6354 - val_accuracy: 0.6685 - val_my_auc: 0.7119\n",
            " epoch:12 auc: 0.7120\n",
            "Epoch 14/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.6313 - accuracy: 0.6644 - my_auc: 0.7214 - val_loss: 0.6345 - val_accuracy: 0.6732 - val_my_auc: 0.7135\n",
            " epoch:13 auc: 0.7138\n",
            "Epoch 15/30\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 0.6761 - accuracy: 0.6520 - my_auc: 0.6764 - val_loss: 0.6330 - val_accuracy: 0.6590 - val_my_auc: 0.7152\n",
            " epoch:14 auc: 0.7146\n",
            "Epoch 16/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.6249 - accuracy: 0.6545 - my_auc: 0.7022 - val_loss: 0.6330 - val_accuracy: 0.6358 - val_my_auc: 0.7125\n",
            " epoch:15 auc: 0.7129\n",
            "Epoch 17/30\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 0.6457 - accuracy: 0.6319 - my_auc: 0.7068 - val_loss: 0.6323 - val_accuracy: 0.6615 - val_my_auc: 0.7140\n",
            " epoch:16 auc: 0.7142\n",
            "Epoch 18/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.6426 - accuracy: 0.6550 - my_auc: 0.6966 - val_loss: 0.6311 - val_accuracy: 0.6745 - val_my_auc: 0.7163\n",
            " epoch:17 auc: 0.7168\n",
            "Epoch 19/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.6588 - accuracy: 0.6611 - my_auc: 0.6912 - val_loss: 0.6310 - val_accuracy: 0.6725 - val_my_auc: 0.7174\n",
            " epoch:18 auc: 0.7172\n",
            "Epoch 20/30\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 0.6198 - accuracy: 0.6626 - my_auc: 0.7247 - val_loss: 0.6307 - val_accuracy: 0.6771 - val_my_auc: 0.7183\n",
            " epoch:19 auc: 0.7188\n",
            "Epoch 21/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.6142 - accuracy: 0.6763 - my_auc: 0.7098 - val_loss: 0.6302 - val_accuracy: 0.6745 - val_my_auc: 0.7198\n",
            " epoch:20 auc: 0.7197\n",
            "Epoch 22/30\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 0.6158 - accuracy: 0.6696 - my_auc: 0.7068 - val_loss: 0.6299 - val_accuracy: 0.6700 - val_my_auc: 0.7204\n",
            " epoch:21 auc: 0.7203\n",
            "Epoch 23/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.6141 - accuracy: 0.6717 - my_auc: 0.7041 - val_loss: 0.6289 - val_accuracy: 0.6650 - val_my_auc: 0.7213\n",
            " epoch:22 auc: 0.7216\n",
            "Epoch 24/30\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 0.6170 - accuracy: 0.6618 - my_auc: 0.7312 - val_loss: 0.6277 - val_accuracy: 0.6619 - val_my_auc: 0.7224\n",
            " epoch:23 auc: 0.7226\n",
            "Epoch 25/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.5927 - accuracy: 0.6658 - my_auc: 0.7209 - val_loss: 0.6264 - val_accuracy: 0.6559 - val_my_auc: 0.7238\n",
            " epoch:24 auc: 0.7237\n",
            "Epoch 26/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.6224 - accuracy: 0.6522 - my_auc: 0.7263 - val_loss: 0.6280 - val_accuracy: 0.6909 - val_my_auc: 0.7244\n",
            " epoch:25 auc: 0.7244\n",
            "Epoch 27/30\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 0.5919 - accuracy: 0.6841 - my_auc: 0.7166 - val_loss: 0.6272 - val_accuracy: 0.6602 - val_my_auc: 0.7225\n",
            " epoch:26 auc: 0.7227\n",
            "Epoch 28/30\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 0.6112 - accuracy: 0.6584 - my_auc: 0.7087 - val_loss: 0.6270 - val_accuracy: 0.6593 - val_my_auc: 0.7225\n",
            " epoch:27 auc: 0.7223\n",
            "Epoch 29/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.6180 - accuracy: 0.6566 - my_auc: 0.7012 - val_loss: 0.6281 - val_accuracy: 0.6690 - val_my_auc: 0.7211\n",
            " epoch:28 auc: 0.7215\n",
            "AUC:  0.6425\n",
            "iterate_num:  3 \n",
            " sum of test_y: 102.0\n",
            "train_x_shape (27366, 17)\n",
            "Epoch 1/30\n",
            "54/54 [==============================] - 3s 26ms/step - loss: 0.7139 - accuracy: 0.2949 - my_auc: 0.5314 - val_loss: 0.7102 - val_accuracy: 0.9623 - val_my_auc: 0.5611\n",
            " epoch:0 auc: 0.5650\n",
            "Epoch 2/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.6862 - accuracy: 0.4863 - my_auc: 0.5979 - val_loss: 0.6991 - val_accuracy: 0.9170 - val_my_auc: 0.5849\n",
            " epoch:1 auc: 0.5825\n",
            "Epoch 3/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.6665 - accuracy: 0.5807 - my_auc: 0.6308 - val_loss: 0.6885 - val_accuracy: 0.8780 - val_my_auc: 0.6088\n",
            " epoch:2 auc: 0.6089\n",
            "Epoch 4/30\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 0.6697 - accuracy: 0.6575 - my_auc: 0.6458 - val_loss: 0.6764 - val_accuracy: 0.8208 - val_my_auc: 0.6352\n",
            " epoch:3 auc: 0.6356\n",
            "Epoch 5/30\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 0.6873 - accuracy: 0.6645 - my_auc: 0.6275 - val_loss: 0.6705 - val_accuracy: 0.7787 - val_my_auc: 0.6451\n",
            " epoch:4 auc: 0.6453\n",
            "Epoch 6/30\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 0.6635 - accuracy: 0.6938 - my_auc: 0.6658 - val_loss: 0.6672 - val_accuracy: 0.7520 - val_my_auc: 0.6483\n",
            " epoch:5 auc: 0.6482\n",
            "Epoch 7/30\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 0.6488 - accuracy: 0.6959 - my_auc: 0.6839 - val_loss: 0.6632 - val_accuracy: 0.7290 - val_my_auc: 0.6535\n",
            " epoch:6 auc: 0.6532\n",
            "Epoch 8/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.5950 - accuracy: 0.7154 - my_auc: 0.7079 - val_loss: 0.6616 - val_accuracy: 0.7144 - val_my_auc: 0.6539\n",
            " epoch:7 auc: 0.6540\n",
            "Epoch 9/30\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 0.6095 - accuracy: 0.7115 - my_auc: 0.7230 - val_loss: 0.6585 - val_accuracy: 0.7128 - val_my_auc: 0.6580\n",
            " epoch:8 auc: 0.6579\n",
            "Epoch 10/30\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 0.6653 - accuracy: 0.7037 - my_auc: 0.6910 - val_loss: 0.6564 - val_accuracy: 0.7103 - val_my_auc: 0.6626\n",
            " epoch:9 auc: 0.6621\n",
            "Epoch 11/30\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 0.6348 - accuracy: 0.7059 - my_auc: 0.6967 - val_loss: 0.6548 - val_accuracy: 0.6925 - val_my_auc: 0.6653\n",
            " epoch:10 auc: 0.6649\n",
            "Epoch 12/30\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 0.5983 - accuracy: 0.7040 - my_auc: 0.7134 - val_loss: 0.6533 - val_accuracy: 0.6862 - val_my_auc: 0.6679\n",
            " epoch:11 auc: 0.6685\n",
            "Epoch 13/30\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 0.6317 - accuracy: 0.6909 - my_auc: 0.7180 - val_loss: 0.6533 - val_accuracy: 0.6939 - val_my_auc: 0.6714\n",
            " epoch:12 auc: 0.6709\n",
            "Epoch 14/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.6347 - accuracy: 0.6847 - my_auc: 0.7152 - val_loss: 0.6532 - val_accuracy: 0.7030 - val_my_auc: 0.6744\n",
            " epoch:13 auc: 0.6740\n",
            "Epoch 15/30\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 0.6132 - accuracy: 0.7065 - my_auc: 0.7297 - val_loss: 0.6527 - val_accuracy: 0.6922 - val_my_auc: 0.6750\n",
            " epoch:14 auc: 0.6752\n",
            "Epoch 16/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.6095 - accuracy: 0.6970 - my_auc: 0.7466 - val_loss: 0.6519 - val_accuracy: 0.6795 - val_my_auc: 0.6759\n",
            " epoch:15 auc: 0.6760\n",
            "Epoch 17/30\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 0.6496 - accuracy: 0.6790 - my_auc: 0.7120 - val_loss: 0.6546 - val_accuracy: 0.6891 - val_my_auc: 0.6749\n",
            " epoch:16 auc: 0.6752\n",
            "Epoch 18/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.5965 - accuracy: 0.6963 - my_auc: 0.7428 - val_loss: 0.6556 - val_accuracy: 0.6916 - val_my_auc: 0.6749\n",
            " epoch:17 auc: 0.6751\n",
            "Epoch 19/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.6336 - accuracy: 0.6910 - my_auc: 0.7009 - val_loss: 0.6580 - val_accuracy: 0.7049 - val_my_auc: 0.6758\n",
            " epoch:18 auc: 0.6756\n",
            "AUC:  0.6601\n",
            "iterate_num:  4 \n",
            " sum of test_y: 101.0\n",
            "train_x_shape (27367, 17)\n",
            "Epoch 1/30\n",
            "54/54 [==============================] - 2s 25ms/step - loss: 0.7774 - accuracy: 0.3239 - my_auc: 0.5084 - val_loss: 0.6947 - val_accuracy: 0.9412 - val_my_auc: 0.5744\n",
            " epoch:0 auc: 0.5774\n",
            "Epoch 2/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.7239 - accuracy: 0.5287 - my_auc: 0.5337 - val_loss: 0.6890 - val_accuracy: 0.8917 - val_my_auc: 0.5950\n",
            " epoch:1 auc: 0.5919\n",
            "Epoch 3/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.7074 - accuracy: 0.5905 - my_auc: 0.5569 - val_loss: 0.6861 - val_accuracy: 0.8404 - val_my_auc: 0.5948\n",
            " epoch:2 auc: 0.5947\n",
            "Epoch 4/30\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 0.6997 - accuracy: 0.6321 - my_auc: 0.5926 - val_loss: 0.6827 - val_accuracy: 0.7844 - val_my_auc: 0.6055\n",
            " epoch:3 auc: 0.6056\n",
            "Epoch 5/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.6658 - accuracy: 0.6627 - my_auc: 0.6238 - val_loss: 0.6788 - val_accuracy: 0.7246 - val_my_auc: 0.6128\n",
            " epoch:4 auc: 0.6138\n",
            "Epoch 6/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.6513 - accuracy: 0.6482 - my_auc: 0.6148 - val_loss: 0.6736 - val_accuracy: 0.6991 - val_my_auc: 0.6250\n",
            " epoch:5 auc: 0.6263\n",
            "Epoch 7/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.6534 - accuracy: 0.6433 - my_auc: 0.6487 - val_loss: 0.6687 - val_accuracy: 0.6967 - val_my_auc: 0.6403\n",
            " epoch:6 auc: 0.6390\n",
            "Epoch 8/30\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 0.6602 - accuracy: 0.6451 - my_auc: 0.6299 - val_loss: 0.6639 - val_accuracy: 0.7096 - val_my_auc: 0.6481\n",
            " epoch:7 auc: 0.6489\n",
            "Epoch 9/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.6707 - accuracy: 0.6592 - my_auc: 0.6574 - val_loss: 0.6594 - val_accuracy: 0.6979 - val_my_auc: 0.6564\n",
            " epoch:8 auc: 0.6560\n",
            "Epoch 10/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.6704 - accuracy: 0.6523 - my_auc: 0.6382 - val_loss: 0.6577 - val_accuracy: 0.7094 - val_my_auc: 0.6596\n",
            " epoch:9 auc: 0.6597\n",
            "Epoch 11/30\n",
            "54/54 [==============================] - 0s 7ms/step - loss: 0.6749 - accuracy: 0.6563 - my_auc: 0.6464 - val_loss: 0.6562 - val_accuracy: 0.6964 - val_my_auc: 0.6601\n",
            " epoch:10 auc: 0.6599\n",
            "Epoch 12/30\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 0.6751 - accuracy: 0.6432 - my_auc: 0.6725 - val_loss: 0.6548 - val_accuracy: 0.7001 - val_my_auc: 0.6628\n",
            " epoch:11 auc: 0.6631\n",
            "Epoch 13/30\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 0.6306 - accuracy: 0.6666 - my_auc: 0.6896 - val_loss: 0.6540 - val_accuracy: 0.6982 - val_my_auc: 0.6624\n",
            " epoch:12 auc: 0.6619\n",
            "Epoch 14/30\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 0.6172 - accuracy: 0.6736 - my_auc: 0.6907 - val_loss: 0.6514 - val_accuracy: 0.6922 - val_my_auc: 0.6649\n",
            " epoch:13 auc: 0.6653\n",
            "Epoch 15/30\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 0.6199 - accuracy: 0.6671 - my_auc: 0.6658 - val_loss: 0.6518 - val_accuracy: 0.6773 - val_my_auc: 0.6640\n",
            " epoch:14 auc: 0.6647\n",
            "Epoch 16/30\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 0.6680 - accuracy: 0.6418 - my_auc: 0.6720 - val_loss: 0.6507 - val_accuracy: 0.6739 - val_my_auc: 0.6649\n",
            " epoch:15 auc: 0.6649\n",
            "Epoch 17/30\n",
            "54/54 [==============================] - 0s 8ms/step - loss: 0.6616 - accuracy: 0.6456 - my_auc: 0.6917 - val_loss: 0.6511 - val_accuracy: 0.6749 - val_my_auc: 0.6630\n",
            " epoch:16 auc: 0.6634\n",
            "AUC:  0.6831\n",
            "avg_AUC :  0.6689966807389838\n",
            "avg_AUC_2 :  0.6692205985304411\n",
            "('perf+spc', ['aqi', 'asset_turnover', 'depi', 'gmi', 'opm', 'rg', 'sg', 'sgee', 'ch_rec', 'ch_inv', 'soft_asset', 'ch_cs', 'ch_roa', 'issue', 's1', 'pastavg3', 'cr3'])\n",
            "0.6689966807389838\n",
            "['Litigious_3_p', 'Litigious_3_n', 'Litigious_3_new', 'Litigious_3_dis', 'Uncertainty_3_p', 'Uncertainty_3_n', 'Uncertainty_3_new', 'Uncertainty_3_dis', 'StrongModal_3_p', 'StrongModal_3_n', 'StrongModal_3_new', 'StrongModal_3_dis', 'Reward_3_p', 'Reward_3_n', 'Reward_3_new', 'Reward_3_dis', 'Achieve_3_p', 'Achieve_3_n', 'Achieve_3_new', 'Achieve_3_dis', 'Positive_3_p', 'Positive_3_n', 'Positive_3_new', 'Positive_3_dis', 'Discrep_3_p', 'Discrep_3_n', 'Discrep_3_new', 'Discrep_3_dis', 'Compare_3_p', 'Compare_3_n', 'Compare_3_new', 'Compare_3_dis', 'Negative_3_p', 'Negative_3_n', 'Negative_3_new', 'Negative_3_dis', 'WeakModal_3_p', 'WeakModal_3_n', 'WeakModal_3_new', 'WeakModal_3_dis', 's1', 'pastavg3', 'cr3']\n",
            "iterate_num:  1 \n",
            " sum of test_y: 102.0\n",
            "train_x_shape (27366, 43)\n",
            "Epoch 1/30\n",
            "54/54 [==============================] - 3s 27ms/step - loss: 0.7065 - accuracy: 0.5927 - my_auc: 0.4970 - val_loss: 0.6912 - val_accuracy: 0.1115 - val_my_auc: 0.5753\n",
            " epoch:0 auc: 0.5835\n",
            "Epoch 2/30\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 0.7117 - accuracy: 0.6641 - my_auc: 0.5665 - val_loss: 0.6886 - val_accuracy: 0.4051 - val_my_auc: 0.6248\n",
            " epoch:1 auc: 0.6288\n",
            "Epoch 3/30\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 0.6513 - accuracy: 0.7155 - my_auc: 0.6343 - val_loss: 0.6868 - val_accuracy: 0.3655 - val_my_auc: 0.6277\n",
            " epoch:2 auc: 0.6370\n",
            "Epoch 4/30\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 0.6600 - accuracy: 0.7005 - my_auc: 0.7200 - val_loss: 0.6841 - val_accuracy: 0.4171 - val_my_auc: 0.6465\n",
            " epoch:3 auc: 0.6468\n",
            "Epoch 5/30\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 0.6915 - accuracy: 0.6687 - my_auc: 0.6476 - val_loss: 0.6804 - val_accuracy: 0.5053 - val_my_auc: 0.6450\n",
            " epoch:4 auc: 0.6450\n",
            "Epoch 6/30\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 0.6612 - accuracy: 0.6816 - my_auc: 0.6930 - val_loss: 0.6783 - val_accuracy: 0.5045 - val_my_auc: 0.6335\n",
            " epoch:5 auc: 0.6329\n",
            "Epoch 7/30\n",
            "54/54 [==============================] - 1s 9ms/step - loss: 0.6270 - accuracy: 0.6804 - my_auc: 0.6920 - val_loss: 0.6746 - val_accuracy: 0.4980 - val_my_auc: 0.6363\n",
            " epoch:6 auc: 0.6352\n",
            "AUC:  0.6126\n",
            "iterate_num:  2 \n",
            " sum of test_y: 102.0\n",
            "train_x_shape (27366, 43)\n",
            "Epoch 1/30\n",
            "54/54 [==============================] - 3s 28ms/step - loss: 0.7125 - accuracy: 0.3176 - my_auc: 0.4734 - val_loss: 0.6908 - val_accuracy: 0.9344 - val_my_auc: 0.5930\n",
            " epoch:0 auc: 0.5880\n",
            "Epoch 2/30\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 0.6520 - accuracy: 0.6236 - my_auc: 0.6199 - val_loss: 0.6893 - val_accuracy: 0.9247 - val_my_auc: 0.6032\n",
            " epoch:1 auc: 0.6040\n",
            "Epoch 3/30\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 0.6793 - accuracy: 0.6092 - my_auc: 0.6084 - val_loss: 0.6867 - val_accuracy: 0.8372 - val_my_auc: 0.6196\n",
            " epoch:2 auc: 0.6165\n",
            "Epoch 4/30\n",
            "54/54 [==============================] - 1s 9ms/step - loss: 0.6856 - accuracy: 0.6480 - my_auc: 0.6065 - val_loss: 0.6846 - val_accuracy: 0.7140 - val_my_auc: 0.6179\n",
            " epoch:3 auc: 0.6165\n",
            "Epoch 5/30\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 0.6571 - accuracy: 0.6379 - my_auc: 0.6689 - val_loss: 0.6822 - val_accuracy: 0.6711 - val_my_auc: 0.6202\n",
            " epoch:4 auc: 0.6206\n",
            "Epoch 6/30\n",
            "54/54 [==============================] - 1s 10ms/step - loss: 0.6828 - accuracy: 0.6321 - my_auc: 0.6510 - val_loss: 0.6779 - val_accuracy: 0.6555 - val_my_auc: 0.6212\n",
            " epoch:5 auc: 0.6234\n",
            "Epoch 7/30\n",
            "54/54 [==============================] - 1s 10ms/step - loss: 0.6689 - accuracy: 0.6520 - my_auc: 0.6807 - val_loss: 0.6770 - val_accuracy: 0.6402 - val_my_auc: 0.6204\n",
            " epoch:6 auc: 0.6199\n",
            "Epoch 8/30\n",
            "54/54 [==============================] - 1s 10ms/step - loss: 0.6670 - accuracy: 0.6400 - my_auc: 0.7115 - val_loss: 0.6737 - val_accuracy: 0.6647 - val_my_auc: 0.6213\n",
            " epoch:7 auc: 0.6221\n",
            "Epoch 9/30\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 0.6637 - accuracy: 0.6669 - my_auc: 0.6926 - val_loss: 0.6720 - val_accuracy: 0.6925 - val_my_auc: 0.6250\n",
            " epoch:8 auc: 0.6253\n",
            "Epoch 10/30\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 0.6646 - accuracy: 0.6701 - my_auc: 0.6928 - val_loss: 0.6735 - val_accuracy: 0.7267 - val_my_auc: 0.6239\n",
            " epoch:9 auc: 0.6237\n",
            "Epoch 11/30\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 0.6220 - accuracy: 0.6968 - my_auc: 0.7288 - val_loss: 0.6730 - val_accuracy: 0.6862 - val_my_auc: 0.6203\n",
            " epoch:10 auc: 0.6208\n",
            "Epoch 12/30\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 0.6059 - accuracy: 0.6791 - my_auc: 0.7230 - val_loss: 0.6763 - val_accuracy: 0.6893 - val_my_auc: 0.6181\n",
            " epoch:11 auc: 0.6184\n",
            "AUC:  0.5849\n",
            "iterate_num:  3 \n",
            " sum of test_y: 102.0\n",
            "train_x_shape (27366, 43)\n",
            "Epoch 1/30\n",
            "54/54 [==============================] - 3s 27ms/step - loss: 0.7441 - accuracy: 0.3780 - my_auc: 0.4503 - val_loss: 0.6965 - val_accuracy: 0.0368 - val_my_auc: 0.4501\n",
            " epoch:0 auc: 0.4530\n",
            "Epoch 2/30\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 0.6975 - accuracy: 0.6357 - my_auc: 0.5586 - val_loss: 0.6944 - val_accuracy: 0.1980 - val_my_auc: 0.5001\n",
            " epoch:1 auc: 0.4960\n",
            "Epoch 3/30\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 0.6683 - accuracy: 0.6586 - my_auc: 0.5675 - val_loss: 0.6933 - val_accuracy: 0.2818 - val_my_auc: 0.5212\n",
            " epoch:2 auc: 0.5246\n",
            "Epoch 4/30\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 0.6598 - accuracy: 0.6345 - my_auc: 0.6277 - val_loss: 0.6910 - val_accuracy: 0.3655 - val_my_auc: 0.5647\n",
            " epoch:3 auc: 0.5661\n",
            "Epoch 5/30\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 0.6612 - accuracy: 0.6309 - my_auc: 0.6342 - val_loss: 0.6879 - val_accuracy: 0.4735 - val_my_auc: 0.5894\n",
            " epoch:4 auc: 0.5888\n",
            "Epoch 6/30\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 0.6615 - accuracy: 0.6569 - my_auc: 0.6813 - val_loss: 0.6857 - val_accuracy: 0.4906 - val_my_auc: 0.6030\n",
            " epoch:5 auc: 0.6001\n",
            "Epoch 7/30\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 0.6608 - accuracy: 0.6555 - my_auc: 0.6824 - val_loss: 0.6844 - val_accuracy: 0.5314 - val_my_auc: 0.6079\n",
            " epoch:6 auc: 0.6085\n",
            "Epoch 8/30\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 0.6499 - accuracy: 0.6632 - my_auc: 0.6745 - val_loss: 0.6840 - val_accuracy: 0.5552 - val_my_auc: 0.6128\n",
            " epoch:7 auc: 0.6139\n",
            "Epoch 9/30\n",
            "54/54 [==============================] - 1s 9ms/step - loss: 0.6651 - accuracy: 0.6524 - my_auc: 0.6617 - val_loss: 0.6850 - val_accuracy: 0.6361 - val_my_auc: 0.6225\n",
            " epoch:8 auc: 0.6218\n",
            "Epoch 10/30\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 0.6733 - accuracy: 0.6868 - my_auc: 0.6612 - val_loss: 0.6870 - val_accuracy: 0.6415 - val_my_auc: 0.6264\n",
            " epoch:9 auc: 0.6264\n",
            "Epoch 11/30\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 0.6237 - accuracy: 0.6921 - my_auc: 0.6785 - val_loss: 0.6897 - val_accuracy: 0.6276 - val_my_auc: 0.6269\n",
            " epoch:10 auc: 0.6284\n",
            "Epoch 12/30\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 0.6302 - accuracy: 0.6673 - my_auc: 0.6966 - val_loss: 0.6914 - val_accuracy: 0.6388 - val_my_auc: 0.6277\n",
            " epoch:11 auc: 0.6282\n",
            "Epoch 13/30\n",
            "54/54 [==============================] - 1s 10ms/step - loss: 0.6508 - accuracy: 0.6592 - my_auc: 0.7109 - val_loss: 0.6968 - val_accuracy: 0.6725 - val_my_auc: 0.6293\n",
            " epoch:12 auc: 0.6295\n",
            "Epoch 14/30\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 0.6412 - accuracy: 0.6888 - my_auc: 0.7019 - val_loss: 0.6984 - val_accuracy: 0.6413 - val_my_auc: 0.6264\n",
            " epoch:13 auc: 0.6264\n",
            "Epoch 15/30\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 0.6277 - accuracy: 0.6621 - my_auc: 0.7194 - val_loss: 0.7022 - val_accuracy: 0.6825 - val_my_auc: 0.6261\n",
            " epoch:14 auc: 0.6266\n",
            "Epoch 16/30\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 0.6005 - accuracy: 0.6810 - my_auc: 0.7444 - val_loss: 0.7038 - val_accuracy: 0.6757 - val_my_auc: 0.6236\n",
            " epoch:15 auc: 0.6235\n",
            "AUC:  0.5801\n",
            "iterate_num:  4 \n",
            " sum of test_y: 101.0\n",
            "train_x_shape (27367, 43)\n",
            "Epoch 1/30\n",
            "54/54 [==============================] - 3s 28ms/step - loss: 0.7210 - accuracy: 0.8577 - my_auc: 0.4873 - val_loss: 0.6933 - val_accuracy: 0.0203 - val_my_auc: 0.5303\n",
            " epoch:0 auc: 0.5403\n",
            "Epoch 2/30\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 0.7253 - accuracy: 0.6375 - my_auc: 0.5412 - val_loss: 0.6921 - val_accuracy: 0.0851 - val_my_auc: 0.5569\n",
            " epoch:1 auc: 0.5640\n",
            "Epoch 3/30\n",
            "54/54 [==============================] - 1s 10ms/step - loss: 0.7174 - accuracy: 0.6449 - my_auc: 0.5778 - val_loss: 0.6891 - val_accuracy: 0.2681 - val_my_auc: 0.5821\n",
            " epoch:2 auc: 0.5884\n",
            "Epoch 4/30\n",
            "54/54 [==============================] - 1s 10ms/step - loss: 0.7077 - accuracy: 0.6328 - my_auc: 0.6009 - val_loss: 0.6866 - val_accuracy: 0.3509 - val_my_auc: 0.5771\n",
            " epoch:3 auc: 0.5813\n",
            "Epoch 5/30\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 0.6563 - accuracy: 0.6797 - my_auc: 0.6423 - val_loss: 0.6835 - val_accuracy: 0.3844 - val_my_auc: 0.5935\n",
            " epoch:4 auc: 0.5959\n",
            "Epoch 6/30\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 0.6441 - accuracy: 0.6667 - my_auc: 0.6340 - val_loss: 0.6795 - val_accuracy: 0.4624 - val_my_auc: 0.6036\n",
            " epoch:5 auc: 0.6023\n",
            "Epoch 7/30\n",
            "54/54 [==============================] - 1s 9ms/step - loss: 0.6333 - accuracy: 0.6681 - my_auc: 0.6645 - val_loss: 0.6753 - val_accuracy: 0.4961 - val_my_auc: 0.6105\n",
            " epoch:6 auc: 0.6122\n",
            "Epoch 8/30\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 0.6474 - accuracy: 0.6554 - my_auc: 0.6734 - val_loss: 0.6707 - val_accuracy: 0.5795 - val_my_auc: 0.6142\n",
            " epoch:7 auc: 0.6165\n",
            "Epoch 9/30\n",
            "54/54 [==============================] - 1s 11ms/step - loss: 0.6086 - accuracy: 0.7205 - my_auc: 0.6877 - val_loss: 0.6672 - val_accuracy: 0.5643 - val_my_auc: 0.6211\n",
            " epoch:8 auc: 0.6205\n",
            "Epoch 10/30\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 0.6316 - accuracy: 0.6588 - my_auc: 0.7125 - val_loss: 0.6657 - val_accuracy: 0.6362 - val_my_auc: 0.6185\n",
            " epoch:9 auc: 0.6173\n",
            "Epoch 11/30\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 0.6530 - accuracy: 0.6692 - my_auc: 0.6796 - val_loss: 0.6626 - val_accuracy: 0.6454 - val_my_auc: 0.6227\n",
            " epoch:10 auc: 0.6228\n",
            "Epoch 12/30\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 0.6411 - accuracy: 0.6593 - my_auc: 0.6938 - val_loss: 0.6628 - val_accuracy: 0.7046 - val_my_auc: 0.6248\n",
            " epoch:11 auc: 0.6255\n",
            "Epoch 13/30\n",
            "54/54 [==============================] - 1s 10ms/step - loss: 0.6405 - accuracy: 0.6893 - my_auc: 0.7212 - val_loss: 0.6628 - val_accuracy: 0.6728 - val_my_auc: 0.6250\n",
            " epoch:12 auc: 0.6248\n",
            "Epoch 14/30\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 0.6423 - accuracy: 0.6648 - my_auc: 0.6973 - val_loss: 0.6665 - val_accuracy: 0.7089 - val_my_auc: 0.6231\n",
            " epoch:13 auc: 0.6229\n",
            "Epoch 15/30\n",
            "54/54 [==============================] - 1s 9ms/step - loss: 0.5737 - accuracy: 0.7096 - my_auc: 0.7614 - val_loss: 0.6645 - val_accuracy: 0.6855 - val_my_auc: 0.6287\n",
            " epoch:14 auc: 0.6293\n",
            "Epoch 16/30\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 0.6074 - accuracy: 0.6755 - my_auc: 0.7162 - val_loss: 0.6624 - val_accuracy: 0.6815 - val_my_auc: 0.6340\n",
            " epoch:15 auc: 0.6342\n",
            "Epoch 17/30\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 0.5628 - accuracy: 0.6900 - my_auc: 0.7315 - val_loss: 0.6644 - val_accuracy: 0.6690 - val_my_auc: 0.6324\n",
            " epoch:16 auc: 0.6326\n",
            "Epoch 18/30\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 0.6128 - accuracy: 0.6656 - my_auc: 0.7546 - val_loss: 0.6713 - val_accuracy: 0.7366 - val_my_auc: 0.6309\n",
            " epoch:17 auc: 0.6313\n",
            "Epoch 19/30\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 0.6086 - accuracy: 0.7044 - my_auc: 0.7464 - val_loss: 0.6692 - val_accuracy: 0.7175 - val_my_auc: 0.6361\n",
            " epoch:18 auc: 0.6359\n",
            "Epoch 20/30\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 0.5868 - accuracy: 0.7092 - my_auc: 0.7385 - val_loss: 0.6666 - val_accuracy: 0.6782 - val_my_auc: 0.6368\n",
            " epoch:19 auc: 0.6374\n",
            "Epoch 21/30\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 0.6133 - accuracy: 0.6743 - my_auc: 0.7322 - val_loss: 0.6741 - val_accuracy: 0.7217 - val_my_auc: 0.6351\n",
            " epoch:20 auc: 0.6355\n",
            "Epoch 22/30\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 0.5919 - accuracy: 0.7046 - my_auc: 0.7683 - val_loss: 0.6770 - val_accuracy: 0.7251 - val_my_auc: 0.6342\n",
            " epoch:21 auc: 0.6348\n",
            "Epoch 23/30\n",
            "54/54 [==============================] - 0s 9ms/step - loss: 0.6243 - accuracy: 0.6874 - my_auc: 0.7499 - val_loss: 0.6837 - val_accuracy: 0.7467 - val_my_auc: 0.6310\n",
            " epoch:22 auc: 0.6308\n",
            "AUC:  0.6358\n",
            "avg_AUC :  0.6033563611049654\n",
            "avg_AUC_2 :  0.6031257537518457\n",
            "('wrd+spc', ['Litigious_3_p', 'Litigious_3_n', 'Litigious_3_new', 'Litigious_3_dis', 'Uncertainty_3_p', 'Uncertainty_3_n', 'Uncertainty_3_new', 'Uncertainty_3_dis', 'StrongModal_3_p', 'StrongModal_3_n', 'StrongModal_3_new', 'StrongModal_3_dis', 'Reward_3_p', 'Reward_3_n', 'Reward_3_new', 'Reward_3_dis', 'Achieve_3_p', 'Achieve_3_n', 'Achieve_3_new', 'Achieve_3_dis', 'Positive_3_p', 'Positive_3_n', 'Positive_3_new', 'Positive_3_dis', 'Discrep_3_p', 'Discrep_3_n', 'Discrep_3_new', 'Discrep_3_dis', 'Compare_3_p', 'Compare_3_n', 'Compare_3_new', 'Compare_3_dis', 'Negative_3_p', 'Negative_3_n', 'Negative_3_new', 'Negative_3_dis', 'WeakModal_3_p', 'WeakModal_3_n', 'WeakModal_3_new', 'WeakModal_3_dis', 's1', 'pastavg3', 'cr3'])\n",
            "0.6033563611049654\n",
            "['aqi', 'asset_turnover', 'depi', 'gmi', 'opm', 'rg', 'sg', 'sgee', 'ch_rec', 'ch_inv', 'soft_asset', 'ch_cs', 'ch_roa', 'issue', 's1', 'pastavg3', 'cr3', 'Litigious_3_p', 'Litigious_3_n', 'Litigious_3_new', 'Litigious_3_dis', 'Uncertainty_3_p', 'Uncertainty_3_n', 'Uncertainty_3_new', 'Uncertainty_3_dis', 'StrongModal_3_p', 'StrongModal_3_n', 'StrongModal_3_new', 'StrongModal_3_dis', 'Reward_3_p', 'Reward_3_n', 'Reward_3_new', 'Reward_3_dis', 'Achieve_3_p', 'Achieve_3_n', 'Achieve_3_new', 'Achieve_3_dis', 'Positive_3_p', 'Positive_3_n', 'Positive_3_new', 'Positive_3_dis', 'Discrep_3_p', 'Discrep_3_n', 'Discrep_3_new', 'Discrep_3_dis', 'Compare_3_p', 'Compare_3_n', 'Compare_3_new', 'Compare_3_dis', 'Negative_3_p', 'Negative_3_n', 'Negative_3_new', 'Negative_3_dis', 'WeakModal_3_p', 'WeakModal_3_n', 'WeakModal_3_new', 'WeakModal_3_dis']\n",
            "iterate_num:  1 \n",
            " sum of test_y: 102.0\n",
            "train_x_shape (27366, 57)\n",
            "Epoch 1/30\n",
            "54/54 [==============================] - 3s 28ms/step - loss: 0.7424 - accuracy: 0.8817 - my_auc: 0.4970 - val_loss: 0.6824 - val_accuracy: 0.1536 - val_my_auc: 0.6391\n",
            " epoch:0 auc: 0.6424\n",
            "Epoch 2/30\n",
            "54/54 [==============================] - 1s 11ms/step - loss: 0.6779 - accuracy: 0.6649 - my_auc: 0.6334 - val_loss: 0.6731 - val_accuracy: 0.2404 - val_my_auc: 0.6636\n",
            " epoch:1 auc: 0.6631\n",
            "Epoch 3/30\n",
            "54/54 [==============================] - 1s 11ms/step - loss: 0.6348 - accuracy: 0.7045 - my_auc: 0.7096 - val_loss: 0.6624 - val_accuracy: 0.2536 - val_my_auc: 0.6850\n",
            " epoch:2 auc: 0.6866\n",
            "Epoch 4/30\n",
            "54/54 [==============================] - 1s 11ms/step - loss: 0.6394 - accuracy: 0.6630 - my_auc: 0.7175 - val_loss: 0.6455 - val_accuracy: 0.3987 - val_my_auc: 0.7020\n",
            " epoch:3 auc: 0.7013\n",
            "Epoch 5/30\n",
            "54/54 [==============================] - 1s 11ms/step - loss: 0.5886 - accuracy: 0.7269 - my_auc: 0.7665 - val_loss: 0.6356 - val_accuracy: 0.4182 - val_my_auc: 0.7152\n",
            " epoch:4 auc: 0.7152\n",
            "Epoch 6/30\n",
            "54/54 [==============================] - 1s 11ms/step - loss: 0.5800 - accuracy: 0.7049 - my_auc: 0.7435 - val_loss: 0.6247 - val_accuracy: 0.4722 - val_my_auc: 0.7249\n",
            " epoch:5 auc: 0.7250\n",
            "Epoch 7/30\n",
            "54/54 [==============================] - 1s 10ms/step - loss: 0.6256 - accuracy: 0.6653 - my_auc: 0.7762 - val_loss: 0.6161 - val_accuracy: 0.5479 - val_my_auc: 0.7288\n",
            " epoch:6 auc: 0.7294\n",
            "Epoch 8/30\n",
            "54/54 [==============================] - 1s 11ms/step - loss: 0.5618 - accuracy: 0.7267 - my_auc: 0.7930 - val_loss: 0.6148 - val_accuracy: 0.4893 - val_my_auc: 0.7358\n",
            " epoch:7 auc: 0.7357\n",
            "Epoch 9/30\n",
            "54/54 [==============================] - 1s 11ms/step - loss: 0.5558 - accuracy: 0.6804 - my_auc: 0.7837 - val_loss: 0.6091 - val_accuracy: 0.5571 - val_my_auc: 0.7357\n",
            " epoch:8 auc: 0.7356\n",
            "Epoch 10/30\n",
            "54/54 [==============================] - 1s 11ms/step - loss: 0.5346 - accuracy: 0.7013 - my_auc: 0.7974 - val_loss: 0.6087 - val_accuracy: 0.5358 - val_my_auc: 0.7403\n",
            " epoch:9 auc: 0.7399\n",
            "Epoch 11/30\n",
            "54/54 [==============================] - 1s 12ms/step - loss: 0.5623 - accuracy: 0.6689 - my_auc: 0.8014 - val_loss: 0.6060 - val_accuracy: 0.6166 - val_my_auc: 0.7375\n",
            " epoch:10 auc: 0.7380\n",
            "Epoch 12/30\n",
            "54/54 [==============================] - 1s 11ms/step - loss: 0.5301 - accuracy: 0.7127 - my_auc: 0.8175 - val_loss: 0.6094 - val_accuracy: 0.6606 - val_my_auc: 0.7377\n",
            " epoch:11 auc: 0.7372\n",
            "Epoch 13/30\n",
            "54/54 [==============================] - 1s 11ms/step - loss: 0.5289 - accuracy: 0.7252 - my_auc: 0.8185 - val_loss: 0.6222 - val_accuracy: 0.7243 - val_my_auc: 0.7350\n",
            " epoch:12 auc: 0.7349\n",
            "AUC:  0.7013\n",
            "iterate_num:  2 \n",
            " sum of test_y: 102.0\n",
            "train_x_shape (27366, 57)\n",
            "Epoch 1/30\n",
            "54/54 [==============================] - 3s 30ms/step - loss: 0.7642 - accuracy: 0.7556 - my_auc: 0.5126 - val_loss: 0.6813 - val_accuracy: 0.6505 - val_my_auc: 0.6720\n",
            " epoch:0 auc: 0.6721\n",
            "Epoch 2/30\n",
            "54/54 [==============================] - 1s 10ms/step - loss: 0.6408 - accuracy: 0.7636 - my_auc: 0.6343 - val_loss: 0.6719 - val_accuracy: 0.1941 - val_my_auc: 0.7166\n",
            " epoch:1 auc: 0.7188\n",
            "Epoch 3/30\n",
            "54/54 [==============================] - 1s 12ms/step - loss: 0.6407 - accuracy: 0.6881 - my_auc: 0.6906 - val_loss: 0.6592 - val_accuracy: 0.3498 - val_my_auc: 0.7261\n",
            " epoch:2 auc: 0.7267\n",
            "Epoch 4/30\n",
            "54/54 [==============================] - 1s 11ms/step - loss: 0.5810 - accuracy: 0.7448 - my_auc: 0.7103 - val_loss: 0.6465 - val_accuracy: 0.3958 - val_my_auc: 0.7344\n",
            " epoch:3 auc: 0.7330\n",
            "Epoch 5/30\n",
            "54/54 [==============================] - 1s 11ms/step - loss: 0.6162 - accuracy: 0.6838 - my_auc: 0.7192 - val_loss: 0.6335 - val_accuracy: 0.4678 - val_my_auc: 0.7439\n",
            " epoch:4 auc: 0.7440\n",
            "Epoch 6/30\n",
            "54/54 [==============================] - 1s 11ms/step - loss: 0.6072 - accuracy: 0.7027 - my_auc: 0.7438 - val_loss: 0.6214 - val_accuracy: 0.5690 - val_my_auc: 0.7444\n",
            " epoch:5 auc: 0.7445\n",
            "Epoch 7/30\n",
            "54/54 [==============================] - 1s 11ms/step - loss: 0.5568 - accuracy: 0.7466 - my_auc: 0.7683 - val_loss: 0.6138 - val_accuracy: 0.5533 - val_my_auc: 0.7466\n",
            " epoch:6 auc: 0.7472\n",
            "Epoch 8/30\n",
            "54/54 [==============================] - 1s 11ms/step - loss: 0.5776 - accuracy: 0.7062 - my_auc: 0.7418 - val_loss: 0.6100 - val_accuracy: 0.5668 - val_my_auc: 0.7446\n",
            " epoch:7 auc: 0.7443\n",
            "Epoch 9/30\n",
            "54/54 [==============================] - 1s 11ms/step - loss: 0.6086 - accuracy: 0.6740 - my_auc: 0.7661 - val_loss: 0.6109 - val_accuracy: 0.6635 - val_my_auc: 0.7379\n",
            " epoch:8 auc: 0.7378\n",
            "Epoch 10/30\n",
            "54/54 [==============================] - 1s 10ms/step - loss: 0.5452 - accuracy: 0.7404 - my_auc: 0.7787 - val_loss: 0.6079 - val_accuracy: 0.5906 - val_my_auc: 0.7388\n",
            " epoch:9 auc: 0.7391\n",
            "AUC:  0.6846\n",
            "iterate_num:  3 \n",
            " sum of test_y: 102.0\n",
            "train_x_shape (27366, 57)\n",
            "Epoch 1/30\n",
            "54/54 [==============================] - 3s 30ms/step - loss: 0.7278 - accuracy: 0.8343 - my_auc: 0.5613 - val_loss: 0.6857 - val_accuracy: 0.0449 - val_my_auc: 0.6693\n",
            " epoch:0 auc: 0.6701\n",
            "Epoch 2/30\n",
            "54/54 [==============================] - 1s 11ms/step - loss: 0.6423 - accuracy: 0.7414 - my_auc: 0.6272 - val_loss: 0.6855 - val_accuracy: 0.0612 - val_my_auc: 0.6835\n",
            " epoch:1 auc: 0.6809\n",
            "Epoch 3/30\n",
            "54/54 [==============================] - 1s 11ms/step - loss: 0.6695 - accuracy: 0.6374 - my_auc: 0.6923 - val_loss: 0.6636 - val_accuracy: 0.2761 - val_my_auc: 0.6949\n",
            " epoch:2 auc: 0.6946\n",
            "Epoch 4/30\n",
            "54/54 [==============================] - 1s 12ms/step - loss: 0.6094 - accuracy: 0.7533 - my_auc: 0.7150 - val_loss: 0.6552 - val_accuracy: 0.3145 - val_my_auc: 0.7025\n",
            " epoch:3 auc: 0.7017\n",
            "Epoch 5/30\n",
            "54/54 [==============================] - 1s 11ms/step - loss: 0.6467 - accuracy: 0.6585 - my_auc: 0.7310 - val_loss: 0.6394 - val_accuracy: 0.4478 - val_my_auc: 0.7117\n",
            " epoch:4 auc: 0.7115\n",
            "Epoch 6/30\n",
            "54/54 [==============================] - 1s 11ms/step - loss: 0.5982 - accuracy: 0.7146 - my_auc: 0.7530 - val_loss: 0.6283 - val_accuracy: 0.5165 - val_my_auc: 0.7126\n",
            " epoch:5 auc: 0.7120\n",
            "Epoch 7/30\n",
            "54/54 [==============================] - 1s 12ms/step - loss: 0.5861 - accuracy: 0.7095 - my_auc: 0.7552 - val_loss: 0.6222 - val_accuracy: 0.5351 - val_my_auc: 0.7190\n",
            " epoch:6 auc: 0.7189\n",
            "Epoch 8/30\n",
            "54/54 [==============================] - 1s 12ms/step - loss: 0.5830 - accuracy: 0.6918 - my_auc: 0.7740 - val_loss: 0.6121 - val_accuracy: 0.5816 - val_my_auc: 0.7252\n",
            " epoch:7 auc: 0.7255\n",
            "Epoch 9/30\n",
            "54/54 [==============================] - 1s 12ms/step - loss: 0.5482 - accuracy: 0.7060 - my_auc: 0.7925 - val_loss: 0.6080 - val_accuracy: 0.6358 - val_my_auc: 0.7266\n",
            " epoch:8 auc: 0.7268\n",
            "Epoch 10/30\n",
            "54/54 [==============================] - 1s 11ms/step - loss: 0.5531 - accuracy: 0.7200 - my_auc: 0.7784 - val_loss: 0.6045 - val_accuracy: 0.6451 - val_my_auc: 0.7318\n",
            " epoch:9 auc: 0.7315\n",
            "Epoch 11/30\n",
            "54/54 [==============================] - 1s 11ms/step - loss: 0.5552 - accuracy: 0.7048 - my_auc: 0.7926 - val_loss: 0.6101 - val_accuracy: 0.6894 - val_my_auc: 0.7245\n",
            " epoch:10 auc: 0.7249\n",
            "Epoch 12/30\n",
            "54/54 [==============================] - 1s 11ms/step - loss: 0.5395 - accuracy: 0.7183 - my_auc: 0.8030 - val_loss: 0.6119 - val_accuracy: 0.6595 - val_my_auc: 0.7238\n",
            " epoch:11 auc: 0.7238\n",
            "Epoch 13/30\n",
            "54/54 [==============================] - 1s 11ms/step - loss: 0.5261 - accuracy: 0.7056 - my_auc: 0.8069 - val_loss: 0.6216 - val_accuracy: 0.6741 - val_my_auc: 0.7159\n",
            " epoch:12 auc: 0.7161\n",
            "AUC:  0.7288\n",
            "iterate_num:  4 \n",
            " sum of test_y: 101.0\n",
            "train_x_shape (27367, 57)\n",
            "Epoch 1/30\n",
            "54/54 [==============================] - 3s 30ms/step - loss: 0.7093 - accuracy: 0.5754 - my_auc: 0.5040 - val_loss: 0.6886 - val_accuracy: 0.0262 - val_my_auc: 0.6470\n",
            " epoch:0 auc: 0.6476\n",
            "Epoch 2/30\n",
            "54/54 [==============================] - 1s 11ms/step - loss: 0.6623 - accuracy: 0.6510 - my_auc: 0.6639 - val_loss: 0.6786 - val_accuracy: 0.1628 - val_my_auc: 0.6758\n",
            " epoch:1 auc: 0.6766\n",
            "Epoch 3/30\n",
            "54/54 [==============================] - 1s 11ms/step - loss: 0.6792 - accuracy: 0.6591 - my_auc: 0.6948 - val_loss: 0.6642 - val_accuracy: 0.4467 - val_my_auc: 0.6964\n",
            " epoch:2 auc: 0.6955\n",
            "Epoch 4/30\n",
            "54/54 [==============================] - 1s 12ms/step - loss: 0.5921 - accuracy: 0.7684 - my_auc: 0.7198 - val_loss: 0.6558 - val_accuracy: 0.3975 - val_my_auc: 0.6986\n",
            " epoch:3 auc: 0.6980\n",
            "Epoch 5/30\n",
            "54/54 [==============================] - 1s 11ms/step - loss: 0.5992 - accuracy: 0.7220 - my_auc: 0.7225 - val_loss: 0.6452 - val_accuracy: 0.4626 - val_my_auc: 0.7034\n",
            " epoch:4 auc: 0.7037\n",
            "Epoch 6/30\n",
            "54/54 [==============================] - 1s 11ms/step - loss: 0.5501 - accuracy: 0.7339 - my_auc: 0.7718 - val_loss: 0.6365 - val_accuracy: 0.5105 - val_my_auc: 0.7044\n",
            " epoch:5 auc: 0.7051\n",
            "Epoch 7/30\n",
            "54/54 [==============================] - 1s 11ms/step - loss: 0.5697 - accuracy: 0.7070 - my_auc: 0.7842 - val_loss: 0.6264 - val_accuracy: 0.5818 - val_my_auc: 0.7069\n",
            " epoch:6 auc: 0.7069\n",
            "Epoch 8/30\n",
            "54/54 [==============================] - 1s 11ms/step - loss: 0.5777 - accuracy: 0.7065 - my_auc: 0.7706 - val_loss: 0.6201 - val_accuracy: 0.6019 - val_my_auc: 0.7085\n",
            " epoch:7 auc: 0.7086\n",
            "Epoch 9/30\n",
            "54/54 [==============================] - 1s 10ms/step - loss: 0.5754 - accuracy: 0.6904 - my_auc: 0.8022 - val_loss: 0.6183 - val_accuracy: 0.6631 - val_my_auc: 0.7086\n",
            " epoch:8 auc: 0.7081\n",
            "Epoch 10/30\n",
            "54/54 [==============================] - 1s 11ms/step - loss: 0.5303 - accuracy: 0.7358 - my_auc: 0.8032 - val_loss: 0.6226 - val_accuracy: 0.6918 - val_my_auc: 0.7041\n",
            " epoch:9 auc: 0.7046\n",
            "Epoch 11/30\n",
            "54/54 [==============================] - 1s 10ms/step - loss: 0.5394 - accuracy: 0.7359 - my_auc: 0.8143 - val_loss: 0.6217 - val_accuracy: 0.6646 - val_my_auc: 0.7033\n",
            " epoch:10 auc: 0.7034\n",
            "Epoch 12/30\n",
            "54/54 [==============================] - 1s 10ms/step - loss: 0.5273 - accuracy: 0.7138 - my_auc: 0.8216 - val_loss: 0.6314 - val_accuracy: 0.7230 - val_my_auc: 0.7025\n",
            " epoch:11 auc: 0.7029\n",
            "AUC:  0.7209\n",
            "avg_AUC :  0.7089143433737806\n",
            "avg_AUC_2 :  0.7089983508154736\n",
            "('perf+spc+wrd', ['aqi', 'asset_turnover', 'depi', 'gmi', 'opm', 'rg', 'sg', 'sgee', 'ch_rec', 'ch_inv', 'soft_asset', 'ch_cs', 'ch_roa', 'issue', 's1', 'pastavg3', 'cr3', 'Litigious_3_p', 'Litigious_3_n', 'Litigious_3_new', 'Litigious_3_dis', 'Uncertainty_3_p', 'Uncertainty_3_n', 'Uncertainty_3_new', 'Uncertainty_3_dis', 'StrongModal_3_p', 'StrongModal_3_n', 'StrongModal_3_new', 'StrongModal_3_dis', 'Reward_3_p', 'Reward_3_n', 'Reward_3_new', 'Reward_3_dis', 'Achieve_3_p', 'Achieve_3_n', 'Achieve_3_new', 'Achieve_3_dis', 'Positive_3_p', 'Positive_3_n', 'Positive_3_new', 'Positive_3_dis', 'Discrep_3_p', 'Discrep_3_n', 'Discrep_3_new', 'Discrep_3_dis', 'Compare_3_p', 'Compare_3_n', 'Compare_3_new', 'Compare_3_dis', 'Negative_3_p', 'Negative_3_n', 'Negative_3_new', 'Negative_3_dis', 'WeakModal_3_p', 'WeakModal_3_n', 'WeakModal_3_new', 'WeakModal_3_dis'])\n",
            "0.7089143433737806\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk2YpCVFO6H4"
      },
      "source": [
        "\r\n",
        "\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKH2sgEZuSIE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKC8WKYauSZD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsdMlLzguWej"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OS0QupnfuSjL"
      },
      "source": [
        "def model_lstm(n1,n2,n,w,l):\r\n",
        "    model = None\r\n",
        "    \r\n",
        "    input_all = Input(shape=(w,l), \\\r\n",
        "               dtype='float32', name='input')\r\n",
        "    nor = BatchNormalization()(input_all)\r\n",
        "    LSTM_w_1 = LSTM(n1, dropout = 0.3, recurrent_dropout = 0.3, \\\r\n",
        "              name = 'layer_lstm_1', return_sequences=True)(nor)\r\n",
        "    LSTM_w_2 = LSTM(n2, activation='relu', dropout = 0.3, recurrent_dropout = 0.3,\r\n",
        "                   name = 'layer_lstm_2', return_sequences=False)(LSTM_w_1)\r\n",
        "\r\n",
        "    dense = Dense(n, activation='relu', name='dense')(LSTM_w_2)\r\n",
        "    preds = Dense(1, activation='sigmoid', name='output')(dense)\r\n",
        "    model = Model(inputs=input_all, outputs=preds)\r\n",
        "    model._name = \"model_lstm\"\r\n",
        "    model.summary()\r\n",
        "    \r\n",
        "    return model"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQAUtKL6uaML"
      },
      "source": [
        "def performance_measure(pred_yp, y):\r\n",
        "    '''\r\n",
        "    Given lists of predicted y probability and x, y, return a dataframe of AR, AUC, Brier, Decile Table\r\n",
        "    '''\r\n",
        "    \r\n",
        "    tenc_dat = pd.DataFrame({'y_true':y,'probability':pred_yp.flatten()})\r\n",
        "    tenc_dat.sort_values('probability',axis = 0,ascending=False, inplace = True)\r\n",
        "    tenc_dat.index = range(0,len(tenc_dat))\r\n",
        "    y = tenc_dat['y_true']\r\n",
        "    point = float(len(tenc_dat))/10\r\n",
        "    point = int(round(point))\r\n",
        "    tenc = []\r\n",
        "    for i in range(0,10):\r\n",
        "        tenc.append(y[(i*point):((i+1)*point)])\r\n",
        "    tenc[9]=tenc[9].append(y[10*point:])\r\n",
        "    total = sum(y)\r\n",
        "    num_of_bkr = []\r\n",
        "    for j in range(0,10):\r\n",
        "        num_of_bkr.append(sum(tenc[j]))\r\n",
        "    tencile_bkr = np.array(num_of_bkr)\r\n",
        "    rate = tencile_bkr.astype(float)/total\r\n",
        "\r\n",
        "    return rate"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pEz7OmyuaNx"
      },
      "source": [
        "class AUCEvaluation(Callback):\r\n",
        "    \"\"\" Show AUC after interval number of epoches \"\"\"\r\n",
        "    def __init__(self, validation_data=(), interval=1):\r\n",
        "        super(Callback, self).__init__()\r\n",
        "        self.interval = interval\r\n",
        "        self.X_val, self.y_val = validation_data\r\n",
        "\r\n",
        "    def on_epoch_end(self, epoch, logs={}):\r\n",
        "        if epoch % self.interval == 0:\r\n",
        "            y_pred = self.model.predict(self.X_val, verbose=0)\r\n",
        "            score = roc_auc_score(self.y_val, y_pred)\r\n",
        "            logs['auc'] = score\r\n",
        "            tencile=performance_measure(y_pred, self.y_val)\r\n",
        "            logs['tencile'] = tencile\r\n",
        "            print(\" epoch:{:d} auc: {:.4f}\".format(epoch, score))"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l1iWWvguaPR"
      },
      "source": [
        "def fit_model( model,x_train, y_train, x_val, y_val, x_test, y_test, model_name, verbose = 0):\r\n",
        "    \r\n",
        "    history = None\r\n",
        "    result = None\r\n",
        "    \r\n",
        "    model_df = model\r\n",
        "    \r\n",
        "    #class weight for test \r\n",
        "    class_weights = class_weight.compute_class_weight('balanced',\r\n",
        "                              np.unique(y_train),\r\n",
        "                              y_train)\r\n",
        "    class_weights = {l:c for l,c in zip(np.unique(y_train), class_weights)}\r\n",
        "    # class weight for val\r\n",
        "    val_class_weights = class_weight.compute_class_weight('balanced',\r\n",
        "                                np.unique(y_val),\r\n",
        "                                y_val)\r\n",
        "    val_class_weights = {l:c for l,c in zip(np.unique(y_val), val_class_weights)}\r\n",
        "    val_sample_weights = []\r\n",
        "    for y in y_val:\r\n",
        "        if y == 1:\r\n",
        "          val_sample_weights.append(val_class_weights[1])\r\n",
        "        else: val_sample_weights.append(val_class_weights[0])\r\n",
        "    val_sample_weights = np.asarray(val_sample_weights)\r\n",
        "    \r\n",
        "    \r\n",
        "    auc_eval = AUCEvaluation(validation_data=(x_val, y_val), interval=1)\r\n",
        "    earlyStopping = EarlyStopping(monitor='val_my_auc',patience = 3, \r\n",
        "                      verbose =verbose, mode ='max')\r\n",
        "    checkpoint = ModelCheckpoint(model_name,monitor='val_my_auc',verbose=verbose,\r\n",
        "              save_best_only=True, save_weights_only=True, mode ='max')\r\n",
        "\r\n",
        "    opt = optimizers.RMSprop(lr=0.0005)\r\n",
        "    model_df.compile(optimizer= opt,\r\n",
        "              loss='binary_crossentropy',\r\n",
        "              metrics=['accuracy', metrics.AUC(name='my_auc')])\r\n",
        "    \r\n",
        "    history = model_df.fit(x_train,\r\n",
        "                y_train,\r\n",
        "                epochs=30,\r\n",
        "                batch_size=512,\r\n",
        "                callbacks=[auc_eval, earlyStopping,checkpoint], #checkpoint\r\n",
        "                class_weight = class_weights, \\\r\n",
        "                validation_data=(x_val,y_val,val_sample_weights)) \r\n",
        "    model_df.load_weights(model_name)\r\n",
        "    y_pred = model_df.predict(x_test)\r\n",
        "    y_pred_1=np.reshape(y_pred, -1)\r\n",
        "    auc_score = roc_auc_score(y_test, y_pred_1)\r\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_1)\r\n",
        "    print(\"AUC: \" ,round(auc_score,4))\r\n",
        "        \r\n",
        "    return history, auc_score, fpr, tpr, thresholds, [y_test, y_pred_1]"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MvqhMZUuVS9"
      },
      "source": [
        "def cross_val(data, label, perf_cols, name, w):\r\n",
        "    tprs = []\r\n",
        "    auc_list = []\r\n",
        "    mean_fpr = np.linspace(0,1,100)\r\n",
        "    predicted_res =[]\r\n",
        "    his_auc = []\r\n",
        "    \r\n",
        "    kf = StratifiedKFold(n_splits = 4, shuffle = True, random_state = 42)\r\n",
        "    c = 0\r\n",
        "\r\n",
        "    X_perf,  Y = shift_data(df_fl, w, \\\r\n",
        "                    perf_cols, \\\r\n",
        "                    'label')\r\n",
        "    \r\n",
        "    for train_index, test_index in kf.split(range(len(X_perf)),Y):\r\n",
        "        \r\n",
        "        c += 1\r\n",
        "        \r\n",
        "        l1 = X_perf.shape[-1] + 16\r\n",
        "        \r\n",
        "        model = model_lstm(l1,l1,32,\\\r\n",
        "                    X_perf.shape[1],X_perf.shape[2])\r\n",
        "    \r\n",
        "        #model = model_lstm(n1,n2,n,w)\r\n",
        "        # train_x, train_val = train_test_split(train_index,test_size=0.2, \\\r\n",
        "        #             random_state=42, stratify = Y[train_index])\r\n",
        "        train_perf_data = X_perf[train_index]\r\n",
        "        #train_word_data = X_word[train_x]\r\n",
        "        #train_perf_val = X_perf[train_val]\r\n",
        "        #train_word_val = X_word[train_val]\r\n",
        "\r\n",
        "        train_label = Y[train_index]\r\n",
        "        #val_label = Y[train_val]\r\n",
        "\r\n",
        "        test_perf_x = X_perf[test_index]\r\n",
        "        #test_word_x = X_word[test_index]\r\n",
        "        test_y = Y[test_index] \r\n",
        "        \r\n",
        "        # train_data = [train_perf_data, train_word_data]\r\n",
        "        # val_data = [train_perf_val,train_word_val]       \r\n",
        "        # test_x = [test_perf_x, test_word_x]\r\n",
        "\r\n",
        "        mod_res = fit_model(model, train_perf_data, train_label, test_perf_x, test_y, test_perf_x, test_y,\\\r\n",
        "                  name+'_'+str(c))\r\n",
        "        his_auc.append(mod_res[0].history['val_my_auc'])\r\n",
        "        \r\n",
        "        \r\n",
        "        \r\n",
        "        \r\n",
        "        auc_list.append(mod_res[1])\r\n",
        "        tprs.append(np.interp(mean_fpr, mod_res[2], mod_res[3]))\r\n",
        "        temp_pred_res = [mod_res[-1],test_index]\r\n",
        "        print(len(test_index))\r\n",
        "        predicted_res.append(temp_pred_res)\r\n",
        "        \r\n",
        "        \r\n",
        "    mean_tpr = np.mean(tprs, axis=0)\r\n",
        "    print('avg_AUC : ', np.mean(auc_list))\r\n",
        "    print('avg_AUC_2 : ', auc(mean_fpr, mean_tpr))\r\n",
        "    print(pd.DataFrame(his_auc))\r\n",
        "    print(pd.DataFrame(his_auc).mean())\r\n",
        "    \r\n",
        "    return np.average(auc_list), mean_tpr, predicted_res"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CTzH8m2_uAB"
      },
      "source": [
        "def shift_data(data, step, perf_cols, label):\r\n",
        "    A = []\r\n",
        "    \r\n",
        "    cols = perf_cols #+ words_cols\r\n",
        "    A.append(data[cols].values)\r\n",
        "    \r\n",
        "    for t in range(1, step):\r\n",
        "        d = data.groupby(\"cik\")[cols].shift(t)\r\n",
        "        A.append(d.values)\r\n",
        "    A = A[::-1]\r\n",
        "    A = np.concatenate(A, axis = 1)  # flatten shifted columns\r\n",
        "    A = np.concatenate([data[label].values[:,None], A], axis = 1)  # add target\r\n",
        "    #np.random.shuffle(A)\r\n",
        "    #print(A[3])\r\n",
        "    print('init A shape: ',A.shape)\r\n",
        "    #print(A[3,:])\r\n",
        "    #print(data[cols].iloc[4,:])\r\n",
        "\r\n",
        "\r\n",
        "    \r\n",
        "    A = A[~np.isnan(A).any(axis=1)]  # drop nan\r\n",
        "    \r\n",
        "\r\n",
        "    Y = A[:,0]  # get target\r\n",
        "    #A = np.reshape(A[:,1:], (len(A), step, len(cols))) # reshape\r\n",
        "\r\n",
        "    A = np.reshape(A[:,1:], (len(A), step, len(perf_cols) + len(words_cols)))\r\n",
        "    \r\n",
        "    A_perf = A[:, :, 0:len(perf_cols)]\r\n",
        "    # # CNN_LSTM must be None x T x words x 4\r\n",
        "    # A_words = A[:, :, len(perf_cols):]\r\n",
        "    # #convert the shape to [[_p,_new][_dis,_n]]\r\n",
        "    # A_words = A_words.reshape((len(A), step, int(len(words_cols)/2), 2), order = 'C')\r\n",
        "    \r\n",
        "    print(A_perf.shape, Y.sum())\r\n",
        "    return A_perf, Y\r\n"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-Ldo2V_IWPq",
        "outputId": "1d63c0aa-89fb-4545-e0cf-dfbab8b4a92f"
      },
      "source": [
        "# financial performance + overall change timestep = 3\r\n",
        "cross_val(df_fl, 'label', v_perf + v_1, 'lstm_perf', 3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "init A shape:  (53635, 46)\n",
            "(39123, 3, 15) 341.0\n",
            "Model: \"model_lstm\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 3, 15)]           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_68 (Batc (None, 3, 15)             60        \n",
            "_________________________________________________________________\n",
            "layer_lstm_1 (LSTM)          (None, 3, 31)             5828      \n",
            "_________________________________________________________________\n",
            "layer_lstm_2 (LSTM)          (None, 31)                7812      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                1024      \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 14,757\n",
            "Trainable params: 14,727\n",
            "Non-trainable params: 30\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "58/58 [==============================] - 9s 56ms/step - loss: 0.7106 - accuracy: 0.3629 - my_auc: 0.5765 - val_loss: 0.6906 - val_accuracy: 0.1111 - val_my_auc: 0.6377\n",
            " epoch:0 auc: 0.6560\n",
            "Epoch 2/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6921 - accuracy: 0.6229 - my_auc: 0.6712 - val_loss: 0.6830 - val_accuracy: 0.2577 - val_my_auc: 0.7038\n",
            " epoch:1 auc: 0.7005\n",
            "Epoch 3/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6524 - accuracy: 0.6463 - my_auc: 0.6869 - val_loss: 0.6672 - val_accuracy: 0.3270 - val_my_auc: 0.7189\n",
            " epoch:2 auc: 0.7201\n",
            "Epoch 4/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6464 - accuracy: 0.6003 - my_auc: 0.6950 - val_loss: 0.6447 - val_accuracy: 0.4195 - val_my_auc: 0.7255\n",
            " epoch:3 auc: 0.7253\n",
            "Epoch 5/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6457 - accuracy: 0.5777 - my_auc: 0.6729 - val_loss: 0.6267 - val_accuracy: 0.4858 - val_my_auc: 0.7282\n",
            " epoch:4 auc: 0.7281\n",
            "Epoch 6/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6303 - accuracy: 0.5804 - my_auc: 0.6926 - val_loss: 0.6152 - val_accuracy: 0.5085 - val_my_auc: 0.7291\n",
            " epoch:5 auc: 0.7291\n",
            "Epoch 7/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6100 - accuracy: 0.5730 - my_auc: 0.6843 - val_loss: 0.6083 - val_accuracy: 0.5294 - val_my_auc: 0.7325\n",
            " epoch:6 auc: 0.7327\n",
            "Epoch 8/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6006 - accuracy: 0.5743 - my_auc: 0.7186 - val_loss: 0.6038 - val_accuracy: 0.5377 - val_my_auc: 0.7363\n",
            " epoch:7 auc: 0.7362\n",
            "Epoch 9/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6260 - accuracy: 0.5639 - my_auc: 0.7073 - val_loss: 0.5989 - val_accuracy: 0.5511 - val_my_auc: 0.7393\n",
            " epoch:8 auc: 0.7392\n",
            "Epoch 10/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.5768 - accuracy: 0.5818 - my_auc: 0.7046 - val_loss: 0.5969 - val_accuracy: 0.5391 - val_my_auc: 0.7413\n",
            " epoch:9 auc: 0.7414\n",
            "Epoch 11/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6197 - accuracy: 0.5555 - my_auc: 0.7128 - val_loss: 0.5930 - val_accuracy: 0.5681 - val_my_auc: 0.7416\n",
            " epoch:10 auc: 0.7416\n",
            "Epoch 12/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6018 - accuracy: 0.5853 - my_auc: 0.6963 - val_loss: 0.5885 - val_accuracy: 0.5740 - val_my_auc: 0.7453\n",
            " epoch:11 auc: 0.7454\n",
            "Epoch 13/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6604 - accuracy: 0.5653 - my_auc: 0.6948 - val_loss: 0.5860 - val_accuracy: 0.5832 - val_my_auc: 0.7492\n",
            " epoch:12 auc: 0.7490\n",
            "Epoch 14/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6342 - accuracy: 0.5842 - my_auc: 0.7279 - val_loss: 0.5854 - val_accuracy: 0.6398 - val_my_auc: 0.7462\n",
            " epoch:13 auc: 0.7463\n",
            "Epoch 15/30\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.6178 - accuracy: 0.6205 - my_auc: 0.6837 - val_loss: 0.5827 - val_accuracy: 0.6165 - val_my_auc: 0.7495\n",
            " epoch:14 auc: 0.7493\n",
            "Epoch 16/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6294 - accuracy: 0.6045 - my_auc: 0.7359 - val_loss: 0.5820 - val_accuracy: 0.6270 - val_my_auc: 0.7515\n",
            " epoch:15 auc: 0.7518\n",
            "Epoch 17/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.5807 - accuracy: 0.6378 - my_auc: 0.7418 - val_loss: 0.5812 - val_accuracy: 0.6010 - val_my_auc: 0.7523\n",
            " epoch:16 auc: 0.7521\n",
            "Epoch 18/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.5830 - accuracy: 0.6110 - my_auc: 0.7441 - val_loss: 0.5818 - val_accuracy: 0.6176 - val_my_auc: 0.7519\n",
            " epoch:17 auc: 0.7516\n",
            "Epoch 19/30\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.5795 - accuracy: 0.6329 - my_auc: 0.7319 - val_loss: 0.5794 - val_accuracy: 0.6117 - val_my_auc: 0.7538\n",
            " epoch:18 auc: 0.7537\n",
            "Epoch 20/30\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.5950 - accuracy: 0.6048 - my_auc: 0.7425 - val_loss: 0.5787 - val_accuracy: 0.6240 - val_my_auc: 0.7545\n",
            " epoch:19 auc: 0.7550\n",
            "Epoch 21/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6169 - accuracy: 0.6198 - my_auc: 0.7076 - val_loss: 0.5758 - val_accuracy: 0.6103 - val_my_auc: 0.7577\n",
            " epoch:20 auc: 0.7577\n",
            "Epoch 22/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.5880 - accuracy: 0.6137 - my_auc: 0.7378 - val_loss: 0.5770 - val_accuracy: 0.6194 - val_my_auc: 0.7569\n",
            " epoch:21 auc: 0.7570\n",
            "Epoch 23/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6072 - accuracy: 0.6145 - my_auc: 0.7486 - val_loss: 0.5770 - val_accuracy: 0.6190 - val_my_auc: 0.7568\n",
            " epoch:22 auc: 0.7566\n",
            "Epoch 24/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6082 - accuracy: 0.6199 - my_auc: 0.7259 - val_loss: 0.5756 - val_accuracy: 0.6487 - val_my_auc: 0.7578\n",
            " epoch:23 auc: 0.7583\n",
            "Epoch 25/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6164 - accuracy: 0.6493 - my_auc: 0.7109 - val_loss: 0.5726 - val_accuracy: 0.6359 - val_my_auc: 0.7615\n",
            " epoch:24 auc: 0.7612\n",
            "Epoch 26/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.5945 - accuracy: 0.6382 - my_auc: 0.7535 - val_loss: 0.5709 - val_accuracy: 0.6441 - val_my_auc: 0.7625\n",
            " epoch:25 auc: 0.7624\n",
            "Epoch 27/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.5779 - accuracy: 0.6496 - my_auc: 0.7774 - val_loss: 0.5740 - val_accuracy: 0.6431 - val_my_auc: 0.7601\n",
            " epoch:26 auc: 0.7599\n",
            "Epoch 28/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6198 - accuracy: 0.6471 - my_auc: 0.7147 - val_loss: 0.5742 - val_accuracy: 0.6543 - val_my_auc: 0.7604\n",
            " epoch:27 auc: 0.7604\n",
            "Epoch 29/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6163 - accuracy: 0.6368 - my_auc: 0.7393 - val_loss: 0.5707 - val_accuracy: 0.6698 - val_my_auc: 0.7625\n",
            " epoch:28 auc: 0.7625\n",
            "AUC:  0.7624\n",
            "9781\n",
            "Model: \"model_lstm\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 3, 15)]           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_69 (Batc (None, 3, 15)             60        \n",
            "_________________________________________________________________\n",
            "layer_lstm_1 (LSTM)          (None, 3, 31)             5828      \n",
            "_________________________________________________________________\n",
            "layer_lstm_2 (LSTM)          (None, 31)                7812      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                1024      \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 14,757\n",
            "Trainable params: 14,727\n",
            "Non-trainable params: 30\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "58/58 [==============================] - 9s 58ms/step - loss: 0.6669 - accuracy: 0.6994 - my_auc: 0.5898 - val_loss: 0.6916 - val_accuracy: 0.5266 - val_my_auc: 0.5969\n",
            " epoch:0 auc: 0.6049\n",
            "Epoch 2/30\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.6642 - accuracy: 0.6585 - my_auc: 0.6205 - val_loss: 0.6857 - val_accuracy: 0.3809 - val_my_auc: 0.6555\n",
            " epoch:1 auc: 0.6556\n",
            "Epoch 3/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6671 - accuracy: 0.6246 - my_auc: 0.6700 - val_loss: 0.6704 - val_accuracy: 0.4490 - val_my_auc: 0.6735\n",
            " epoch:2 auc: 0.6731\n",
            "Epoch 4/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6621 - accuracy: 0.6134 - my_auc: 0.7074 - val_loss: 0.6526 - val_accuracy: 0.5341 - val_my_auc: 0.6803\n",
            " epoch:3 auc: 0.6798\n",
            "Epoch 5/30\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.6282 - accuracy: 0.6320 - my_auc: 0.7111 - val_loss: 0.6387 - val_accuracy: 0.5287 - val_my_auc: 0.6883\n",
            " epoch:4 auc: 0.6884\n",
            "Epoch 6/30\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.5960 - accuracy: 0.6090 - my_auc: 0.7216 - val_loss: 0.6283 - val_accuracy: 0.5638 - val_my_auc: 0.6964\n",
            " epoch:5 auc: 0.6963\n",
            "Epoch 7/30\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.5946 - accuracy: 0.6124 - my_auc: 0.7200 - val_loss: 0.6216 - val_accuracy: 0.5695 - val_my_auc: 0.7028\n",
            " epoch:6 auc: 0.7029\n",
            "Epoch 8/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.5885 - accuracy: 0.6169 - my_auc: 0.7366 - val_loss: 0.6162 - val_accuracy: 0.5999 - val_my_auc: 0.7076\n",
            " epoch:7 auc: 0.7076\n",
            "Epoch 9/30\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.6249 - accuracy: 0.6168 - my_auc: 0.6993 - val_loss: 0.6113 - val_accuracy: 0.6135 - val_my_auc: 0.7100\n",
            " epoch:8 auc: 0.7102\n",
            "Epoch 10/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6034 - accuracy: 0.6334 - my_auc: 0.6995 - val_loss: 0.6079 - val_accuracy: 0.6329 - val_my_auc: 0.7144\n",
            " epoch:9 auc: 0.7143\n",
            "Epoch 11/30\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.6347 - accuracy: 0.6294 - my_auc: 0.7240 - val_loss: 0.6063 - val_accuracy: 0.6612 - val_my_auc: 0.7188\n",
            " epoch:10 auc: 0.7185\n",
            "Epoch 12/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.5800 - accuracy: 0.6695 - my_auc: 0.7489 - val_loss: 0.6044 - val_accuracy: 0.6126 - val_my_auc: 0.7183\n",
            " epoch:11 auc: 0.7183\n",
            "Epoch 13/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.5808 - accuracy: 0.6316 - my_auc: 0.7254 - val_loss: 0.6027 - val_accuracy: 0.6228 - val_my_auc: 0.7198\n",
            " epoch:12 auc: 0.7196\n",
            "Epoch 14/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6299 - accuracy: 0.6194 - my_auc: 0.7012 - val_loss: 0.6015 - val_accuracy: 0.6447 - val_my_auc: 0.7198\n",
            " epoch:13 auc: 0.7195\n",
            "Epoch 15/30\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.6248 - accuracy: 0.6324 - my_auc: 0.7281 - val_loss: 0.6008 - val_accuracy: 0.6729 - val_my_auc: 0.7204\n",
            " epoch:14 auc: 0.7202\n",
            "Epoch 16/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.5599 - accuracy: 0.6828 - my_auc: 0.7388 - val_loss: 0.5982 - val_accuracy: 0.6269 - val_my_auc: 0.7214\n",
            " epoch:15 auc: 0.7215\n",
            "Epoch 17/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6075 - accuracy: 0.6293 - my_auc: 0.7290 - val_loss: 0.5951 - val_accuracy: 0.6625 - val_my_auc: 0.7246\n",
            " epoch:16 auc: 0.7247\n",
            "Epoch 18/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6012 - accuracy: 0.6581 - my_auc: 0.7423 - val_loss: 0.5933 - val_accuracy: 0.6606 - val_my_auc: 0.7262\n",
            " epoch:17 auc: 0.7260\n",
            "Epoch 19/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.5989 - accuracy: 0.6611 - my_auc: 0.7476 - val_loss: 0.5923 - val_accuracy: 0.6473 - val_my_auc: 0.7278\n",
            " epoch:18 auc: 0.7276\n",
            "Epoch 20/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6212 - accuracy: 0.6371 - my_auc: 0.7290 - val_loss: 0.5917 - val_accuracy: 0.6876 - val_my_auc: 0.7278\n",
            " epoch:19 auc: 0.7273\n",
            "Epoch 21/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.5734 - accuracy: 0.6819 - my_auc: 0.7430 - val_loss: 0.5914 - val_accuracy: 0.6476 - val_my_auc: 0.7282\n",
            " epoch:20 auc: 0.7285\n",
            "Epoch 22/30\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.6031 - accuracy: 0.6502 - my_auc: 0.7177 - val_loss: 0.5897 - val_accuracy: 0.6753 - val_my_auc: 0.7290\n",
            " epoch:21 auc: 0.7292\n",
            "Epoch 23/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6072 - accuracy: 0.6692 - my_auc: 0.7295 - val_loss: 0.5909 - val_accuracy: 0.6583 - val_my_auc: 0.7281\n",
            " epoch:22 auc: 0.7285\n",
            "Epoch 24/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6081 - accuracy: 0.6569 - my_auc: 0.7205 - val_loss: 0.5910 - val_accuracy: 0.6909 - val_my_auc: 0.7282\n",
            " epoch:23 auc: 0.7280\n",
            "Epoch 25/30\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.5628 - accuracy: 0.6981 - my_auc: 0.7523 - val_loss: 0.5905 - val_accuracy: 0.6517 - val_my_auc: 0.7286\n",
            " epoch:24 auc: 0.7289\n",
            "AUC:  0.7292\n",
            "9781\n",
            "Model: \"model_lstm\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 3, 15)]           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_70 (Batc (None, 3, 15)             60        \n",
            "_________________________________________________________________\n",
            "layer_lstm_1 (LSTM)          (None, 3, 31)             5828      \n",
            "_________________________________________________________________\n",
            "layer_lstm_2 (LSTM)          (None, 31)                7812      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                1024      \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 14,757\n",
            "Trainable params: 14,727\n",
            "Non-trainable params: 30\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "58/58 [==============================] - 10s 56ms/step - loss: 0.7104 - accuracy: 0.6252 - my_auc: 0.5145 - val_loss: 0.6904 - val_accuracy: 0.4149 - val_my_auc: 0.6239\n",
            " epoch:0 auc: 0.6340\n",
            "Epoch 2/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6885 - accuracy: 0.7205 - my_auc: 0.6487 - val_loss: 0.6835 - val_accuracy: 0.2243 - val_my_auc: 0.6656\n",
            " epoch:1 auc: 0.6708\n",
            "Epoch 3/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6607 - accuracy: 0.6709 - my_auc: 0.6641 - val_loss: 0.6664 - val_accuracy: 0.3412 - val_my_auc: 0.6803\n",
            " epoch:2 auc: 0.6816\n",
            "Epoch 4/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6798 - accuracy: 0.6459 - my_auc: 0.6797 - val_loss: 0.6485 - val_accuracy: 0.4169 - val_my_auc: 0.6849\n",
            " epoch:3 auc: 0.6860\n",
            "Epoch 5/30\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.6526 - accuracy: 0.6208 - my_auc: 0.7004 - val_loss: 0.6357 - val_accuracy: 0.5001 - val_my_auc: 0.6903\n",
            " epoch:4 auc: 0.6904\n",
            "Epoch 6/30\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.6467 - accuracy: 0.6263 - my_auc: 0.6822 - val_loss: 0.6286 - val_accuracy: 0.5306 - val_my_auc: 0.6932\n",
            " epoch:5 auc: 0.6933\n",
            "Epoch 7/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6159 - accuracy: 0.6191 - my_auc: 0.7159 - val_loss: 0.6230 - val_accuracy: 0.5932 - val_my_auc: 0.6967\n",
            " epoch:6 auc: 0.6966\n",
            "Epoch 8/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6383 - accuracy: 0.6474 - my_auc: 0.6807 - val_loss: 0.6215 - val_accuracy: 0.5866 - val_my_auc: 0.6984\n",
            " epoch:7 auc: 0.6988\n",
            "Epoch 9/30\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.6282 - accuracy: 0.6308 - my_auc: 0.7052 - val_loss: 0.6193 - val_accuracy: 0.6201 - val_my_auc: 0.7004\n",
            " epoch:8 auc: 0.7002\n",
            "Epoch 10/30\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.6223 - accuracy: 0.6513 - my_auc: 0.7121 - val_loss: 0.6180 - val_accuracy: 0.6290 - val_my_auc: 0.7011\n",
            " epoch:9 auc: 0.7012\n",
            "Epoch 11/30\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.6373 - accuracy: 0.6602 - my_auc: 0.7126 - val_loss: 0.6157 - val_accuracy: 0.6215 - val_my_auc: 0.7045\n",
            " epoch:10 auc: 0.7049\n",
            "Epoch 12/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6249 - accuracy: 0.6374 - my_auc: 0.7323 - val_loss: 0.6172 - val_accuracy: 0.6652 - val_my_auc: 0.7067\n",
            " epoch:11 auc: 0.7064\n",
            "Epoch 13/30\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.6449 - accuracy: 0.6701 - my_auc: 0.7155 - val_loss: 0.6156 - val_accuracy: 0.6345 - val_my_auc: 0.7081\n",
            " epoch:12 auc: 0.7083\n",
            "Epoch 14/30\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.6116 - accuracy: 0.6526 - my_auc: 0.7218 - val_loss: 0.6179 - val_accuracy: 0.6701 - val_my_auc: 0.7098\n",
            " epoch:13 auc: 0.7098\n",
            "Epoch 15/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6122 - accuracy: 0.6871 - my_auc: 0.7180 - val_loss: 0.6177 - val_accuracy: 0.6256 - val_my_auc: 0.7093\n",
            " epoch:14 auc: 0.7094\n",
            "Epoch 16/30\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.5926 - accuracy: 0.6596 - my_auc: 0.7482 - val_loss: 0.6176 - val_accuracy: 0.6420 - val_my_auc: 0.7127\n",
            " epoch:15 auc: 0.7125\n",
            "Epoch 17/30\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.6100 - accuracy: 0.6534 - my_auc: 0.7410 - val_loss: 0.6189 - val_accuracy: 0.6528 - val_my_auc: 0.7145\n",
            " epoch:16 auc: 0.7143\n",
            "Epoch 18/30\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.5825 - accuracy: 0.6791 - my_auc: 0.7301 - val_loss: 0.6188 - val_accuracy: 0.6417 - val_my_auc: 0.7146\n",
            " epoch:17 auc: 0.7145\n",
            "Epoch 19/30\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.5665 - accuracy: 0.6714 - my_auc: 0.7326 - val_loss: 0.6241 - val_accuracy: 0.6502 - val_my_auc: 0.7151\n",
            " epoch:18 auc: 0.7154\n",
            "Epoch 20/30\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.6354 - accuracy: 0.6512 - my_auc: 0.7220 - val_loss: 0.6281 - val_accuracy: 0.6765 - val_my_auc: 0.7174\n",
            " epoch:19 auc: 0.7174\n",
            "Epoch 21/30\n",
            "15/58 [======>.......................] - ETA: 1s - loss: 0.6405 - accuracy: 0.6844 - my_auc: 0.7453"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4JxEK6NEwfl",
        "outputId": "62d48432-ee1c-4e86-82c8-117b8bd8fdc0"
      },
      "source": [
        "# financial performance + overall change timestep = 2\r\n",
        "cross_val(df_fl, 'label', v_perf + v_1, 'lstm_perf', 2)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "init A shape:  (53635, 31)\n",
            "(45945, 2, 15) 408.0\n",
            "Model: \"model_lstm\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 2, 15)]           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_60 (Batc (None, 2, 15)             60        \n",
            "_________________________________________________________________\n",
            "layer_lstm_1 (LSTM)          (None, 2, 31)             5828      \n",
            "_________________________________________________________________\n",
            "layer_lstm_2 (LSTM)          (None, 31)                7812      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                1024      \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 14,757\n",
            "Trainable params: 14,727\n",
            "Non-trainable params: 30\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 9s 49ms/step - loss: 0.6850 - accuracy: 0.4367 - my_auc: 0.5236 - val_loss: 0.6908 - val_accuracy: 0.0614 - val_my_auc: 0.6617\n",
            " epoch:0 auc: 0.6951\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6775 - accuracy: 0.5394 - my_auc: 0.6906 - val_loss: 0.6834 - val_accuracy: 0.2359 - val_my_auc: 0.6995\n",
            " epoch:1 auc: 0.6987\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6368 - accuracy: 0.6149 - my_auc: 0.6883 - val_loss: 0.6702 - val_accuracy: 0.3550 - val_my_auc: 0.7009\n",
            " epoch:2 auc: 0.7000\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6717 - accuracy: 0.5650 - my_auc: 0.6695 - val_loss: 0.6514 - val_accuracy: 0.5118 - val_my_auc: 0.7009\n",
            " epoch:3 auc: 0.7016\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6496 - accuracy: 0.6037 - my_auc: 0.6837 - val_loss: 0.6368 - val_accuracy: 0.5719 - val_my_auc: 0.7020\n",
            " epoch:4 auc: 0.7020\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6513 - accuracy: 0.6064 - my_auc: 0.6720 - val_loss: 0.6286 - val_accuracy: 0.6112 - val_my_auc: 0.7026\n",
            " epoch:5 auc: 0.7025\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6437 - accuracy: 0.6192 - my_auc: 0.6811 - val_loss: 0.6241 - val_accuracy: 0.5912 - val_my_auc: 0.7036\n",
            " epoch:6 auc: 0.7034\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6186 - accuracy: 0.6141 - my_auc: 0.7155 - val_loss: 0.6239 - val_accuracy: 0.6278 - val_my_auc: 0.7026\n",
            " epoch:7 auc: 0.7027\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6287 - accuracy: 0.6276 - my_auc: 0.6827 - val_loss: 0.6220 - val_accuracy: 0.6258 - val_my_auc: 0.7034\n",
            " epoch:8 auc: 0.7037\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6444 - accuracy: 0.6246 - my_auc: 0.6806 - val_loss: 0.6200 - val_accuracy: 0.6217 - val_my_auc: 0.7054\n",
            " epoch:9 auc: 0.7050\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6442 - accuracy: 0.6176 - my_auc: 0.6803 - val_loss: 0.6191 - val_accuracy: 0.6152 - val_my_auc: 0.7062\n",
            " epoch:10 auc: 0.7064\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6398 - accuracy: 0.6159 - my_auc: 0.6828 - val_loss: 0.6191 - val_accuracy: 0.6224 - val_my_auc: 0.7056\n",
            " epoch:11 auc: 0.7057\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6295 - accuracy: 0.6253 - my_auc: 0.6973 - val_loss: 0.6181 - val_accuracy: 0.6262 - val_my_auc: 0.7068\n",
            " epoch:12 auc: 0.7070\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6260 - accuracy: 0.6254 - my_auc: 0.6939 - val_loss: 0.6174 - val_accuracy: 0.6426 - val_my_auc: 0.7087\n",
            " epoch:13 auc: 0.7087\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6068 - accuracy: 0.6447 - my_auc: 0.7109 - val_loss: 0.6169 - val_accuracy: 0.6466 - val_my_auc: 0.7089\n",
            " epoch:14 auc: 0.7091\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6572 - accuracy: 0.6291 - my_auc: 0.6969 - val_loss: 0.6174 - val_accuracy: 0.6498 - val_my_auc: 0.7089\n",
            " epoch:15 auc: 0.7088\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 1s 20ms/step - loss: 0.6078 - accuracy: 0.6483 - my_auc: 0.7181 - val_loss: 0.6175 - val_accuracy: 0.6431 - val_my_auc: 0.7083\n",
            " epoch:16 auc: 0.7087\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6071 - accuracy: 0.6515 - my_auc: 0.6880 - val_loss: 0.6149 - val_accuracy: 0.6077 - val_my_auc: 0.7108\n",
            " epoch:17 auc: 0.7110\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6033 - accuracy: 0.6254 - my_auc: 0.7086 - val_loss: 0.6152 - val_accuracy: 0.6241 - val_my_auc: 0.7111\n",
            " epoch:18 auc: 0.7115\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6295 - accuracy: 0.6295 - my_auc: 0.7094 - val_loss: 0.6163 - val_accuracy: 0.6215 - val_my_auc: 0.7105\n",
            " epoch:19 auc: 0.7105\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6432 - accuracy: 0.6239 - my_auc: 0.6938 - val_loss: 0.6175 - val_accuracy: 0.6407 - val_my_auc: 0.7110\n",
            " epoch:20 auc: 0.7108\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6488 - accuracy: 0.6350 - my_auc: 0.6919 - val_loss: 0.6182 - val_accuracy: 0.6379 - val_my_auc: 0.7110\n",
            " epoch:21 auc: 0.7106\n",
            "AUC:  0.7115\n",
            "11487\n",
            "Model: \"model_lstm\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 2, 15)]           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_61 (Batc (None, 2, 15)             60        \n",
            "_________________________________________________________________\n",
            "layer_lstm_1 (LSTM)          (None, 2, 31)             5828      \n",
            "_________________________________________________________________\n",
            "layer_lstm_2 (LSTM)          (None, 31)                7812      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                1024      \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 14,757\n",
            "Trainable params: 14,727\n",
            "Non-trainable params: 30\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 9s 48ms/step - loss: 0.7152 - accuracy: 0.1600 - my_auc: 0.5172 - val_loss: 0.6912 - val_accuracy: 0.3636 - val_my_auc: 0.6279\n",
            " epoch:0 auc: 0.6451\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6622 - accuracy: 0.6818 - my_auc: 0.6180 - val_loss: 0.6851 - val_accuracy: 0.3099 - val_my_auc: 0.6622\n",
            " epoch:1 auc: 0.6658\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6991 - accuracy: 0.5777 - my_auc: 0.6659 - val_loss: 0.6724 - val_accuracy: 0.4781 - val_my_auc: 0.6670\n",
            " epoch:2 auc: 0.6664\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6548 - accuracy: 0.6220 - my_auc: 0.6932 - val_loss: 0.6591 - val_accuracy: 0.5247 - val_my_auc: 0.6682\n",
            " epoch:3 auc: 0.6684\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6287 - accuracy: 0.6193 - my_auc: 0.6715 - val_loss: 0.6481 - val_accuracy: 0.5607 - val_my_auc: 0.6744\n",
            " epoch:4 auc: 0.6743\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6396 - accuracy: 0.6067 - my_auc: 0.7125 - val_loss: 0.6406 - val_accuracy: 0.6275 - val_my_auc: 0.6806\n",
            " epoch:5 auc: 0.6806\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6255 - accuracy: 0.6471 - my_auc: 0.6820 - val_loss: 0.6367 - val_accuracy: 0.6051 - val_my_auc: 0.6851\n",
            " epoch:6 auc: 0.6851\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6691 - accuracy: 0.6039 - my_auc: 0.6915 - val_loss: 0.6347 - val_accuracy: 0.6530 - val_my_auc: 0.6895\n",
            " epoch:7 auc: 0.6891\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6212 - accuracy: 0.6487 - my_auc: 0.7074 - val_loss: 0.6323 - val_accuracy: 0.6299 - val_my_auc: 0.6921\n",
            " epoch:8 auc: 0.6918\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6213 - accuracy: 0.6275 - my_auc: 0.6971 - val_loss: 0.6320 - val_accuracy: 0.6171 - val_my_auc: 0.6932\n",
            " epoch:9 auc: 0.6931\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6006 - accuracy: 0.6282 - my_auc: 0.7104 - val_loss: 0.6317 - val_accuracy: 0.6114 - val_my_auc: 0.6946\n",
            " epoch:10 auc: 0.6945\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6226 - accuracy: 0.6238 - my_auc: 0.6774 - val_loss: 0.6318 - val_accuracy: 0.5955 - val_my_auc: 0.6952\n",
            " epoch:11 auc: 0.6954\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6272 - accuracy: 0.6040 - my_auc: 0.6802 - val_loss: 0.6315 - val_accuracy: 0.6007 - val_my_auc: 0.6958\n",
            " epoch:12 auc: 0.6955\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6346 - accuracy: 0.5998 - my_auc: 0.6866 - val_loss: 0.6307 - val_accuracy: 0.6124 - val_my_auc: 0.6970\n",
            " epoch:13 auc: 0.6969\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.5825 - accuracy: 0.6198 - my_auc: 0.7314 - val_loss: 0.6307 - val_accuracy: 0.5950 - val_my_auc: 0.6965\n",
            " epoch:14 auc: 0.6972\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.5933 - accuracy: 0.6023 - my_auc: 0.7218 - val_loss: 0.6270 - val_accuracy: 0.5998 - val_my_auc: 0.7014\n",
            " epoch:15 auc: 0.7012\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.5915 - accuracy: 0.6052 - my_auc: 0.7157 - val_loss: 0.6280 - val_accuracy: 0.5664 - val_my_auc: 0.7014\n",
            " epoch:16 auc: 0.7012\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6043 - accuracy: 0.5782 - my_auc: 0.6941 - val_loss: 0.6302 - val_accuracy: 0.5798 - val_my_auc: 0.7004\n",
            " epoch:17 auc: 0.7002\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6071 - accuracy: 0.5830 - my_auc: 0.7229 - val_loss: 0.6276 - val_accuracy: 0.6075 - val_my_auc: 0.7017\n",
            " epoch:18 auc: 0.7017\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.5930 - accuracy: 0.6103 - my_auc: 0.7047 - val_loss: 0.6266 - val_accuracy: 0.5952 - val_my_auc: 0.7022\n",
            " epoch:19 auc: 0.7024\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6167 - accuracy: 0.5926 - my_auc: 0.7008 - val_loss: 0.6252 - val_accuracy: 0.6023 - val_my_auc: 0.7033\n",
            " epoch:20 auc: 0.7033\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6135 - accuracy: 0.5988 - my_auc: 0.7316 - val_loss: 0.6237 - val_accuracy: 0.6205 - val_my_auc: 0.7044\n",
            " epoch:21 auc: 0.7043\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 2s 22ms/step - loss: 0.6201 - accuracy: 0.6111 - my_auc: 0.6987 - val_loss: 0.6263 - val_accuracy: 0.6273 - val_my_auc: 0.7042\n",
            " epoch:22 auc: 0.7041\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.5674 - accuracy: 0.6444 - my_auc: 0.7437 - val_loss: 0.6245 - val_accuracy: 0.6207 - val_my_auc: 0.7076\n",
            " epoch:23 auc: 0.7072\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6128 - accuracy: 0.6098 - my_auc: 0.7141 - val_loss: 0.6226 - val_accuracy: 0.6029 - val_my_auc: 0.7078\n",
            " epoch:24 auc: 0.7078\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.5852 - accuracy: 0.6124 - my_auc: 0.7283 - val_loss: 0.6225 - val_accuracy: 0.6208 - val_my_auc: 0.7082\n",
            " epoch:25 auc: 0.7082\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6149 - accuracy: 0.6094 - my_auc: 0.7331 - val_loss: 0.6235 - val_accuracy: 0.6131 - val_my_auc: 0.7083\n",
            " epoch:26 auc: 0.7086\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6187 - accuracy: 0.5966 - my_auc: 0.7256 - val_loss: 0.6232 - val_accuracy: 0.6507 - val_my_auc: 0.7100\n",
            " epoch:27 auc: 0.7106\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.5876 - accuracy: 0.6457 - my_auc: 0.7316 - val_loss: 0.6226 - val_accuracy: 0.6417 - val_my_auc: 0.7117\n",
            " epoch:28 auc: 0.7115\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.5919 - accuracy: 0.6358 - my_auc: 0.7393 - val_loss: 0.6239 - val_accuracy: 0.6358 - val_my_auc: 0.7112\n",
            " epoch:29 auc: 0.7112\n",
            "AUC:  0.7115\n",
            "11486\n",
            "Model: \"model_lstm\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 2, 15)]           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_62 (Batc (None, 2, 15)             60        \n",
            "_________________________________________________________________\n",
            "layer_lstm_1 (LSTM)          (None, 2, 31)             5828      \n",
            "_________________________________________________________________\n",
            "layer_lstm_2 (LSTM)          (None, 31)                7812      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                1024      \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 14,757\n",
            "Trainable params: 14,727\n",
            "Non-trainable params: 30\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 10s 49ms/step - loss: 0.6705 - accuracy: 0.9868 - my_auc: 0.5316 - val_loss: 0.6918 - val_accuracy: 0.9160 - val_my_auc: 0.6170\n",
            " epoch:0 auc: 0.6526\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6679 - accuracy: 0.9460 - my_auc: 0.6363 - val_loss: 0.6866 - val_accuracy: 0.5691 - val_my_auc: 0.6603\n",
            " epoch:1 auc: 0.6784\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6987 - accuracy: 0.7687 - my_auc: 0.6512 - val_loss: 0.6746 - val_accuracy: 0.5439 - val_my_auc: 0.6836\n",
            " epoch:2 auc: 0.6852\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6660 - accuracy: 0.6939 - my_auc: 0.6683 - val_loss: 0.6621 - val_accuracy: 0.5156 - val_my_auc: 0.6881\n",
            " epoch:3 auc: 0.6889\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6389 - accuracy: 0.6412 - my_auc: 0.7023 - val_loss: 0.6525 - val_accuracy: 0.5164 - val_my_auc: 0.6916\n",
            " epoch:4 auc: 0.6917\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 2s 22ms/step - loss: 0.6235 - accuracy: 0.5981 - my_auc: 0.6876 - val_loss: 0.6440 - val_accuracy: 0.5389 - val_my_auc: 0.6927\n",
            " epoch:5 auc: 0.6931\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6430 - accuracy: 0.5720 - my_auc: 0.6875 - val_loss: 0.6392 - val_accuracy: 0.5619 - val_my_auc: 0.6938\n",
            " epoch:6 auc: 0.6946\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6264 - accuracy: 0.5834 - my_auc: 0.6691 - val_loss: 0.6358 - val_accuracy: 0.5445 - val_my_auc: 0.6957\n",
            " epoch:7 auc: 0.6962\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6477 - accuracy: 0.5477 - my_auc: 0.6726 - val_loss: 0.6331 - val_accuracy: 0.5606 - val_my_auc: 0.6978\n",
            " epoch:8 auc: 0.6974\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6443 - accuracy: 0.5583 - my_auc: 0.6927 - val_loss: 0.6331 - val_accuracy: 0.5740 - val_my_auc: 0.6961\n",
            " epoch:9 auc: 0.6966\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 2s 22ms/step - loss: 0.6092 - accuracy: 0.5858 - my_auc: 0.7158 - val_loss: 0.6332 - val_accuracy: 0.5670 - val_my_auc: 0.6967\n",
            " epoch:10 auc: 0.6971\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6459 - accuracy: 0.5708 - my_auc: 0.6911 - val_loss: 0.6321 - val_accuracy: 0.5862 - val_my_auc: 0.6968\n",
            " epoch:11 auc: 0.6968\n",
            "AUC:  0.6974\n",
            "11486\n",
            "Model: \"model_lstm\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 2, 15)]           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_63 (Batc (None, 2, 15)             60        \n",
            "_________________________________________________________________\n",
            "layer_lstm_1 (LSTM)          (None, 2, 31)             5828      \n",
            "_________________________________________________________________\n",
            "layer_lstm_2 (LSTM)          (None, 31)                7812      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                1024      \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 14,757\n",
            "Trainable params: 14,727\n",
            "Non-trainable params: 30\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 10s 48ms/step - loss: 0.6746 - accuracy: 0.9427 - my_auc: 0.5594 - val_loss: 0.6915 - val_accuracy: 0.9765 - val_my_auc: 0.6155\n",
            " epoch:0 auc: 0.6206\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6720 - accuracy: 0.8818 - my_auc: 0.6427 - val_loss: 0.6852 - val_accuracy: 0.5972 - val_my_auc: 0.6444\n",
            " epoch:1 auc: 0.6450\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6811 - accuracy: 0.6874 - my_auc: 0.6814 - val_loss: 0.6689 - val_accuracy: 0.5513 - val_my_auc: 0.6626\n",
            " epoch:2 auc: 0.6635\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6253 - accuracy: 0.6564 - my_auc: 0.6901 - val_loss: 0.6555 - val_accuracy: 0.5083 - val_my_auc: 0.6718\n",
            " epoch:3 auc: 0.6711\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6354 - accuracy: 0.5984 - my_auc: 0.7173 - val_loss: 0.6442 - val_accuracy: 0.5158 - val_my_auc: 0.6779\n",
            " epoch:4 auc: 0.6783\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6205 - accuracy: 0.5761 - my_auc: 0.7142 - val_loss: 0.6396 - val_accuracy: 0.5094 - val_my_auc: 0.6821\n",
            " epoch:5 auc: 0.6827\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6446 - accuracy: 0.5538 - my_auc: 0.7038 - val_loss: 0.6357 - val_accuracy: 0.5419 - val_my_auc: 0.6874\n",
            " epoch:6 auc: 0.6875\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6371 - accuracy: 0.5614 - my_auc: 0.6751 - val_loss: 0.6326 - val_accuracy: 0.5243 - val_my_auc: 0.6924\n",
            " epoch:7 auc: 0.6920\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6421 - accuracy: 0.5439 - my_auc: 0.6886 - val_loss: 0.6292 - val_accuracy: 0.5508 - val_my_auc: 0.6961\n",
            " epoch:8 auc: 0.6962\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 2s 22ms/step - loss: 0.5954 - accuracy: 0.5871 - my_auc: 0.7119 - val_loss: 0.6268 - val_accuracy: 0.5427 - val_my_auc: 0.6993\n",
            " epoch:9 auc: 0.6991\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6273 - accuracy: 0.5653 - my_auc: 0.6951 - val_loss: 0.6249 - val_accuracy: 0.5470 - val_my_auc: 0.7011\n",
            " epoch:10 auc: 0.7008\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6000 - accuracy: 0.5748 - my_auc: 0.7141 - val_loss: 0.6252 - val_accuracy: 0.5433 - val_my_auc: 0.7010\n",
            " epoch:11 auc: 0.7010\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6381 - accuracy: 0.5575 - my_auc: 0.7128 - val_loss: 0.6231 - val_accuracy: 0.5772 - val_my_auc: 0.7032\n",
            " epoch:12 auc: 0.7031\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6029 - accuracy: 0.6027 - my_auc: 0.7195 - val_loss: 0.6223 - val_accuracy: 0.5593 - val_my_auc: 0.7046\n",
            " epoch:13 auc: 0.7043\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6287 - accuracy: 0.5735 - my_auc: 0.6897 - val_loss: 0.6213 - val_accuracy: 0.5809 - val_my_auc: 0.7064\n",
            " epoch:14 auc: 0.7061\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6414 - accuracy: 0.5970 - my_auc: 0.6983 - val_loss: 0.6193 - val_accuracy: 0.5660 - val_my_auc: 0.7085\n",
            " epoch:15 auc: 0.7082\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6494 - accuracy: 0.5725 - my_auc: 0.6638 - val_loss: 0.6188 - val_accuracy: 0.5972 - val_my_auc: 0.7095\n",
            " epoch:16 auc: 0.7095\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6332 - accuracy: 0.6128 - my_auc: 0.7119 - val_loss: 0.6174 - val_accuracy: 0.5958 - val_my_auc: 0.7113\n",
            " epoch:17 auc: 0.7114\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6004 - accuracy: 0.6207 - my_auc: 0.7133 - val_loss: 0.6149 - val_accuracy: 0.6094 - val_my_auc: 0.7152\n",
            " epoch:18 auc: 0.7153\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6103 - accuracy: 0.6333 - my_auc: 0.7315 - val_loss: 0.6163 - val_accuracy: 0.5994 - val_my_auc: 0.7128\n",
            " epoch:19 auc: 0.7129\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6359 - accuracy: 0.6141 - my_auc: 0.7161 - val_loss: 0.6153 - val_accuracy: 0.5938 - val_my_auc: 0.7154\n",
            " epoch:20 auc: 0.7151\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 2s 22ms/step - loss: 0.6030 - accuracy: 0.6346 - my_auc: 0.7113 - val_loss: 0.6147 - val_accuracy: 0.6040 - val_my_auc: 0.7136\n",
            " epoch:21 auc: 0.7141\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6220 - accuracy: 0.6235 - my_auc: 0.7277 - val_loss: 0.6126 - val_accuracy: 0.6360 - val_my_auc: 0.7204\n",
            " epoch:22 auc: 0.7203\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.5681 - accuracy: 0.6762 - my_auc: 0.7475 - val_loss: 0.6109 - val_accuracy: 0.6265 - val_my_auc: 0.7210\n",
            " epoch:23 auc: 0.7210\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 2s 22ms/step - loss: 0.5980 - accuracy: 0.6512 - my_auc: 0.7218 - val_loss: 0.6121 - val_accuracy: 0.6154 - val_my_auc: 0.7171\n",
            " epoch:24 auc: 0.7171\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6277 - accuracy: 0.6406 - my_auc: 0.7109 - val_loss: 0.6101 - val_accuracy: 0.6473 - val_my_auc: 0.7184\n",
            " epoch:25 auc: 0.7182\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6064 - accuracy: 0.6601 - my_auc: 0.7340 - val_loss: 0.6097 - val_accuracy: 0.6293 - val_my_auc: 0.7170\n",
            " epoch:26 auc: 0.7171\n",
            "AUC:  0.721\n",
            "11486\n",
            "avg_AUC :  0.7103611252950334\n",
            "avg_AUC_2 :  0.7101901366607248\n",
            "         0         1         2   ...        27        28       29\n",
            "0  0.661650  0.699515  0.700945  ...       NaN       NaN      NaN\n",
            "1  0.627895  0.662185  0.667020  ...  0.710029  0.711716  0.71115\n",
            "2  0.617049  0.660260  0.683586  ...       NaN       NaN      NaN\n",
            "3  0.615459  0.644429  0.662586  ...       NaN       NaN      NaN\n",
            "\n",
            "[4 rows x 30 columns]\n",
            "0     0.630513\n",
            "1     0.666598\n",
            "2     0.678534\n",
            "3     0.682257\n",
            "4     0.686478\n",
            "5     0.689480\n",
            "6     0.692480\n",
            "7     0.695032\n",
            "8     0.697385\n",
            "9     0.698524\n",
            "10    0.699652\n",
            "11    0.699650\n",
            "12    0.701955\n",
            "13    0.703409\n",
            "14    0.703952\n",
            "15    0.706267\n",
            "16    0.706415\n",
            "17    0.707488\n",
            "18    0.709344\n",
            "19    0.708509\n",
            "20    0.709884\n",
            "21    0.709660\n",
            "22    0.712309\n",
            "23    0.714264\n",
            "24    0.712453\n",
            "25    0.713312\n",
            "26    0.712676\n",
            "27    0.710029\n",
            "28    0.711716\n",
            "29    0.711150\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7103611252950334,\n",
              " array([0.        , 0.06127451, 0.09558824, 0.12254902, 0.15441176,\n",
              "        0.18872549, 0.22303922, 0.24019608, 0.26715686, 0.29166667,\n",
              "        0.31617647, 0.33333333, 0.35539216, 0.35784314, 0.37990196,\n",
              "        0.39215686, 0.41176471, 0.43137255, 0.45098039, 0.46568627,\n",
              "        0.47794118, 0.48039216, 0.50245098, 0.51470588, 0.5245098 ,\n",
              "        0.53921569, 0.55147059, 0.57598039, 0.58578431, 0.59803922,\n",
              "        0.60539216, 0.6127451 , 0.62745098, 0.62990196, 0.64705882,\n",
              "        0.66176471, 0.66421569, 0.66666667, 0.67647059, 0.68382353,\n",
              "        0.69852941, 0.70343137, 0.72303922, 0.73284314, 0.7377451 ,\n",
              "        0.75245098, 0.7622549 , 0.76960784, 0.7745098 , 0.78186275,\n",
              "        0.78431373, 0.79166667, 0.80147059, 0.80637255, 0.81127451,\n",
              "        0.82107843, 0.82598039, 0.83088235, 0.83088235, 0.83578431,\n",
              "        0.83823529, 0.85294118, 0.85784314, 0.86519608, 0.87254902,\n",
              "        0.87745098, 0.88970588, 0.89460784, 0.8995098 , 0.90196078,\n",
              "        0.90931373, 0.91421569, 0.91911765, 0.92892157, 0.93382353,\n",
              "        0.93627451, 0.94117647, 0.95098039, 0.95588235, 0.96078431,\n",
              "        0.96323529, 0.97303922, 0.9754902 , 0.9754902 , 0.98039216,\n",
              "        0.98284314, 0.98529412, 0.9877451 , 0.9877451 , 0.9877451 ,\n",
              "        0.9877451 , 0.99019608, 0.99509804, 0.99754902, 0.99754902,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ]),\n",
              " [[[array([0., 0., 0., ..., 0., 0., 0.]),\n",
              "    array([0.21381113, 0.6130022 , 0.47159338, ..., 0.5258506 , 0.4387024 ,\n",
              "           0.6715356 ], dtype=float32)],\n",
              "   array([    0,    11,    12, ..., 45939, 45940, 45943])],\n",
              "  [[array([0., 0., 0., ..., 0., 0., 0.]),\n",
              "    array([0.403045  , 0.5094106 , 0.63376176, ..., 0.47078416, 0.6924894 ,\n",
              "           0.2759515 ], dtype=float32)],\n",
              "   array([    4,     8,    10, ..., 45936, 45938, 45944])],\n",
              "  [[array([0., 0., 0., ..., 0., 0., 0.]),\n",
              "    array([0.5015114 , 0.59619534, 0.4409119 , ..., 0.68626124, 0.57782936,\n",
              "           0.425609  ], dtype=float32)],\n",
              "   array([    1,     2,     5, ..., 45920, 45922, 45924])],\n",
              "  [[array([0., 0., 0., ..., 0., 0., 0.]),\n",
              "    array([0.44524217, 0.67424536, 0.48315954, ..., 0.3825953 , 0.5377977 ,\n",
              "           0.6067833 ], dtype=float32)],\n",
              "   array([    3,    17,    20, ..., 45937, 45941, 45942])]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqNshMR_GNnw",
        "outputId": "6fcd36d7-9f9c-4c60-b773-b122f45d6ffe"
      },
      "source": [
        "# financial performance timestep = 3\r\n",
        "cross_val(df_fl, 'label', v_perf, 'lstm_perf', 3)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "init A shape:  (53635, 43)\n",
            "(39123, 3, 14) 341.0\n",
            "Model: \"model_lstm\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 3, 14)]           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_64 (Batc (None, 3, 14)             56        \n",
            "_________________________________________________________________\n",
            "layer_lstm_1 (LSTM)          (None, 3, 30)             5400      \n",
            "_________________________________________________________________\n",
            "layer_lstm_2 (LSTM)          (None, 30)                7320      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                992       \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 13,801\n",
            "Trainable params: 13,773\n",
            "Non-trainable params: 28\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "58/58 [==============================] - 10s 54ms/step - loss: 0.7101 - accuracy: 0.1147 - my_auc: 0.5619 - val_loss: 0.6898 - val_accuracy: 0.0094 - val_my_auc: 0.6945\n",
            " epoch:0 auc: 0.6942\n",
            "Epoch 2/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6936 - accuracy: 0.4336 - my_auc: 0.6473 - val_loss: 0.6821 - val_accuracy: 0.0973 - val_my_auc: 0.7126\n",
            " epoch:1 auc: 0.7072\n",
            "Epoch 3/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6570 - accuracy: 0.5389 - my_auc: 0.6854 - val_loss: 0.6703 - val_accuracy: 0.2241 - val_my_auc: 0.7126\n",
            " epoch:2 auc: 0.7131\n",
            "Epoch 4/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6605 - accuracy: 0.5467 - my_auc: 0.6808 - val_loss: 0.6522 - val_accuracy: 0.3788 - val_my_auc: 0.7151\n",
            " epoch:3 auc: 0.7151\n",
            "Epoch 5/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6444 - accuracy: 0.5751 - my_auc: 0.6837 - val_loss: 0.6351 - val_accuracy: 0.4833 - val_my_auc: 0.7178\n",
            " epoch:4 auc: 0.7183\n",
            "Epoch 6/30\n",
            "58/58 [==============================] - 1s 26ms/step - loss: 0.6285 - accuracy: 0.5791 - my_auc: 0.6969 - val_loss: 0.6259 - val_accuracy: 0.4917 - val_my_auc: 0.7209\n",
            " epoch:5 auc: 0.7206\n",
            "Epoch 7/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6139 - accuracy: 0.5658 - my_auc: 0.6602 - val_loss: 0.6200 - val_accuracy: 0.5104 - val_my_auc: 0.7204\n",
            " epoch:6 auc: 0.7203\n",
            "Epoch 8/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6108 - accuracy: 0.5558 - my_auc: 0.6906 - val_loss: 0.6169 - val_accuracy: 0.5122 - val_my_auc: 0.7237\n",
            " epoch:7 auc: 0.7242\n",
            "Epoch 9/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6312 - accuracy: 0.5464 - my_auc: 0.7045 - val_loss: 0.6134 - val_accuracy: 0.5180 - val_my_auc: 0.7259\n",
            " epoch:8 auc: 0.7263\n",
            "Epoch 10/30\n",
            "58/58 [==============================] - 2s 26ms/step - loss: 0.5795 - accuracy: 0.5554 - my_auc: 0.6991 - val_loss: 0.6107 - val_accuracy: 0.5273 - val_my_auc: 0.7269\n",
            " epoch:9 auc: 0.7270\n",
            "Epoch 11/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6217 - accuracy: 0.5455 - my_auc: 0.6942 - val_loss: 0.6075 - val_accuracy: 0.5505 - val_my_auc: 0.7298\n",
            " epoch:10 auc: 0.7299\n",
            "Epoch 12/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6148 - accuracy: 0.5659 - my_auc: 0.6593 - val_loss: 0.6062 - val_accuracy: 0.5381 - val_my_auc: 0.7322\n",
            " epoch:11 auc: 0.7317\n",
            "Epoch 13/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6578 - accuracy: 0.5379 - my_auc: 0.6890 - val_loss: 0.6052 - val_accuracy: 0.5577 - val_my_auc: 0.7319\n",
            " epoch:12 auc: 0.7322\n",
            "Epoch 14/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6498 - accuracy: 0.5491 - my_auc: 0.7030 - val_loss: 0.6100 - val_accuracy: 0.5832 - val_my_auc: 0.7291\n",
            " epoch:13 auc: 0.7292\n",
            "Epoch 15/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6286 - accuracy: 0.5744 - my_auc: 0.6813 - val_loss: 0.6041 - val_accuracy: 0.5697 - val_my_auc: 0.7362\n",
            " epoch:14 auc: 0.7360\n",
            "Epoch 16/30\n",
            "58/58 [==============================] - 2s 26ms/step - loss: 0.6390 - accuracy: 0.5621 - my_auc: 0.7058 - val_loss: 0.6023 - val_accuracy: 0.5706 - val_my_auc: 0.7389\n",
            " epoch:15 auc: 0.7394\n",
            "Epoch 17/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.5878 - accuracy: 0.5890 - my_auc: 0.7284 - val_loss: 0.5974 - val_accuracy: 0.5541 - val_my_auc: 0.7426\n",
            " epoch:16 auc: 0.7431\n",
            "Epoch 18/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6004 - accuracy: 0.5626 - my_auc: 0.7209 - val_loss: 0.5959 - val_accuracy: 0.5577 - val_my_auc: 0.7443\n",
            " epoch:17 auc: 0.7446\n",
            "Epoch 19/30\n",
            "58/58 [==============================] - 2s 26ms/step - loss: 0.5761 - accuracy: 0.5721 - my_auc: 0.7263 - val_loss: 0.5945 - val_accuracy: 0.5493 - val_my_auc: 0.7455\n",
            " epoch:18 auc: 0.7455\n",
            "Epoch 20/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6051 - accuracy: 0.5547 - my_auc: 0.7146 - val_loss: 0.5929 - val_accuracy: 0.5604 - val_my_auc: 0.7476\n",
            " epoch:19 auc: 0.7473\n",
            "Epoch 21/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6378 - accuracy: 0.5543 - my_auc: 0.6992 - val_loss: 0.5903 - val_accuracy: 0.5462 - val_my_auc: 0.7480\n",
            " epoch:20 auc: 0.7487\n",
            "Epoch 22/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.5919 - accuracy: 0.5580 - my_auc: 0.7308 - val_loss: 0.5891 - val_accuracy: 0.5467 - val_my_auc: 0.7491\n",
            " epoch:21 auc: 0.7486\n",
            "Epoch 23/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6299 - accuracy: 0.5465 - my_auc: 0.6970 - val_loss: 0.5872 - val_accuracy: 0.5515 - val_my_auc: 0.7501\n",
            " epoch:22 auc: 0.7502\n",
            "Epoch 24/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6171 - accuracy: 0.5584 - my_auc: 0.7147 - val_loss: 0.5863 - val_accuracy: 0.5725 - val_my_auc: 0.7518\n",
            " epoch:23 auc: 0.7517\n",
            "Epoch 25/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6107 - accuracy: 0.5723 - my_auc: 0.6946 - val_loss: 0.5853 - val_accuracy: 0.5583 - val_my_auc: 0.7506\n",
            " epoch:24 auc: 0.7508\n",
            "Epoch 26/30\n",
            "58/58 [==============================] - 2s 26ms/step - loss: 0.5953 - accuracy: 0.5699 - my_auc: 0.7253 - val_loss: 0.5848 - val_accuracy: 0.5555 - val_my_auc: 0.7522\n",
            " epoch:25 auc: 0.7526\n",
            "Epoch 27/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.5980 - accuracy: 0.5697 - my_auc: 0.7362 - val_loss: 0.5850 - val_accuracy: 0.5593 - val_my_auc: 0.7531\n",
            " epoch:26 auc: 0.7531\n",
            "Epoch 28/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6127 - accuracy: 0.5730 - my_auc: 0.6962 - val_loss: 0.5885 - val_accuracy: 0.5827 - val_my_auc: 0.7554\n",
            " epoch:27 auc: 0.7555\n",
            "Epoch 29/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6196 - accuracy: 0.5711 - my_auc: 0.7241 - val_loss: 0.5884 - val_accuracy: 0.5749 - val_my_auc: 0.7557\n",
            " epoch:28 auc: 0.7556\n",
            "Epoch 30/30\n",
            "58/58 [==============================] - 2s 26ms/step - loss: 0.6281 - accuracy: 0.5750 - my_auc: 0.7090 - val_loss: 0.5827 - val_accuracy: 0.5474 - val_my_auc: 0.7568\n",
            " epoch:29 auc: 0.7566\n",
            "AUC:  0.7566\n",
            "9781\n",
            "Model: \"model_lstm\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 3, 14)]           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_65 (Batc (None, 3, 14)             56        \n",
            "_________________________________________________________________\n",
            "layer_lstm_1 (LSTM)          (None, 3, 30)             5400      \n",
            "_________________________________________________________________\n",
            "layer_lstm_2 (LSTM)          (None, 30)                7320      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                992       \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 13,801\n",
            "Trainable params: 13,773\n",
            "Non-trainable params: 28\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "58/58 [==============================] - 9s 55ms/step - loss: 0.6700 - accuracy: 0.5154 - my_auc: 0.4473 - val_loss: 0.6915 - val_accuracy: 0.1037 - val_my_auc: 0.6058\n",
            " epoch:0 auc: 0.6350\n",
            "Epoch 2/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6658 - accuracy: 0.6113 - my_auc: 0.6279 - val_loss: 0.6856 - val_accuracy: 0.1785 - val_my_auc: 0.6807\n",
            " epoch:1 auc: 0.6797\n",
            "Epoch 3/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6747 - accuracy: 0.5973 - my_auc: 0.6479 - val_loss: 0.6750 - val_accuracy: 0.3289 - val_my_auc: 0.6923\n",
            " epoch:2 auc: 0.6917\n",
            "Epoch 4/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6802 - accuracy: 0.5910 - my_auc: 0.6727 - val_loss: 0.6596 - val_accuracy: 0.4849 - val_my_auc: 0.6973\n",
            " epoch:3 auc: 0.6975\n",
            "Epoch 5/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6519 - accuracy: 0.6216 - my_auc: 0.6720 - val_loss: 0.6452 - val_accuracy: 0.4991 - val_my_auc: 0.7005\n",
            " epoch:4 auc: 0.7000\n",
            "Epoch 6/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6077 - accuracy: 0.6054 - my_auc: 0.7110 - val_loss: 0.6318 - val_accuracy: 0.5409 - val_my_auc: 0.7047\n",
            " epoch:5 auc: 0.7044\n",
            "Epoch 7/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6118 - accuracy: 0.6030 - my_auc: 0.6948 - val_loss: 0.6239 - val_accuracy: 0.5475 - val_my_auc: 0.7090\n",
            " epoch:6 auc: 0.7093\n",
            "Epoch 8/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6068 - accuracy: 0.5968 - my_auc: 0.7146 - val_loss: 0.6181 - val_accuracy: 0.5546 - val_my_auc: 0.7118\n",
            " epoch:7 auc: 0.7118\n",
            "Epoch 9/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6342 - accuracy: 0.5806 - my_auc: 0.6838 - val_loss: 0.6111 - val_accuracy: 0.5743 - val_my_auc: 0.7128\n",
            " epoch:8 auc: 0.7128\n",
            "Epoch 10/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6129 - accuracy: 0.5963 - my_auc: 0.6789 - val_loss: 0.6074 - val_accuracy: 0.5705 - val_my_auc: 0.7140\n",
            " epoch:9 auc: 0.7146\n",
            "Epoch 11/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6435 - accuracy: 0.5742 - my_auc: 0.7061 - val_loss: 0.6058 - val_accuracy: 0.5906 - val_my_auc: 0.7152\n",
            " epoch:10 auc: 0.7154\n",
            "Epoch 12/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.5893 - accuracy: 0.6105 - my_auc: 0.7240 - val_loss: 0.6041 - val_accuracy: 0.5500 - val_my_auc: 0.7172\n",
            " epoch:11 auc: 0.7174\n",
            "Epoch 13/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6005 - accuracy: 0.5730 - my_auc: 0.6959 - val_loss: 0.6019 - val_accuracy: 0.5749 - val_my_auc: 0.7170\n",
            " epoch:12 auc: 0.7171\n",
            "Epoch 14/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6288 - accuracy: 0.5806 - my_auc: 0.7048 - val_loss: 0.6012 - val_accuracy: 0.5886 - val_my_auc: 0.7166\n",
            " epoch:13 auc: 0.7166\n",
            "Epoch 15/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6515 - accuracy: 0.5763 - my_auc: 0.6969 - val_loss: 0.6001 - val_accuracy: 0.5918 - val_my_auc: 0.7180\n",
            " epoch:14 auc: 0.7181\n",
            "Epoch 16/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.5740 - accuracy: 0.6099 - my_auc: 0.7281 - val_loss: 0.5976 - val_accuracy: 0.5675 - val_my_auc: 0.7217\n",
            " epoch:15 auc: 0.7212\n",
            "Epoch 17/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6158 - accuracy: 0.5705 - my_auc: 0.7031 - val_loss: 0.5958 - val_accuracy: 0.5946 - val_my_auc: 0.7225\n",
            " epoch:16 auc: 0.7221\n",
            "Epoch 18/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6439 - accuracy: 0.5881 - my_auc: 0.7045 - val_loss: 0.5937 - val_accuracy: 0.5771 - val_my_auc: 0.7251\n",
            " epoch:17 auc: 0.7252\n",
            "Epoch 19/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6186 - accuracy: 0.5860 - my_auc: 0.7261 - val_loss: 0.5926 - val_accuracy: 0.5806 - val_my_auc: 0.7258\n",
            " epoch:18 auc: 0.7255\n",
            "Epoch 20/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6326 - accuracy: 0.5750 - my_auc: 0.7214 - val_loss: 0.5927 - val_accuracy: 0.6048 - val_my_auc: 0.7261\n",
            " epoch:19 auc: 0.7258\n",
            "Epoch 21/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.5822 - accuracy: 0.6072 - my_auc: 0.7218 - val_loss: 0.5906 - val_accuracy: 0.5866 - val_my_auc: 0.7270\n",
            " epoch:20 auc: 0.7274\n",
            "Epoch 22/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6311 - accuracy: 0.5795 - my_auc: 0.6796 - val_loss: 0.5898 - val_accuracy: 0.5854 - val_my_auc: 0.7271\n",
            " epoch:21 auc: 0.7271\n",
            "Epoch 23/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6047 - accuracy: 0.5797 - my_auc: 0.7165 - val_loss: 0.5891 - val_accuracy: 0.5538 - val_my_auc: 0.7294\n",
            " epoch:22 auc: 0.7299\n",
            "Epoch 24/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.5993 - accuracy: 0.5696 - my_auc: 0.7308 - val_loss: 0.5882 - val_accuracy: 0.5919 - val_my_auc: 0.7323\n",
            " epoch:23 auc: 0.7322\n",
            "Epoch 25/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.5801 - accuracy: 0.6000 - my_auc: 0.7340 - val_loss: 0.5881 - val_accuracy: 0.5506 - val_my_auc: 0.7329\n",
            " epoch:24 auc: 0.7327\n",
            "Epoch 26/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6154 - accuracy: 0.5601 - my_auc: 0.7511 - val_loss: 0.5881 - val_accuracy: 0.6244 - val_my_auc: 0.7306\n",
            " epoch:25 auc: 0.7309\n",
            "Epoch 27/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.5816 - accuracy: 0.6298 - my_auc: 0.7061 - val_loss: 0.5861 - val_accuracy: 0.6006 - val_my_auc: 0.7363\n",
            " epoch:26 auc: 0.7363\n",
            "Epoch 28/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6864 - accuracy: 0.5745 - my_auc: 0.7215 - val_loss: 0.5872 - val_accuracy: 0.6433 - val_my_auc: 0.7345\n",
            " epoch:27 auc: 0.7343\n",
            "Epoch 29/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6331 - accuracy: 0.6187 - my_auc: 0.7262 - val_loss: 0.5862 - val_accuracy: 0.6445 - val_my_auc: 0.7342\n",
            " epoch:28 auc: 0.7339\n",
            "Epoch 30/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6176 - accuracy: 0.6200 - my_auc: 0.7224 - val_loss: 0.5845 - val_accuracy: 0.6171 - val_my_auc: 0.7366\n",
            " epoch:29 auc: 0.7367\n",
            "AUC:  0.7367\n",
            "9781\n",
            "Model: \"model_lstm\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 3, 14)]           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_66 (Batc (None, 3, 14)             56        \n",
            "_________________________________________________________________\n",
            "layer_lstm_1 (LSTM)          (None, 3, 30)             5400      \n",
            "_________________________________________________________________\n",
            "layer_lstm_2 (LSTM)          (None, 30)                7320      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                992       \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 13,801\n",
            "Trainable params: 13,773\n",
            "Non-trainable params: 28\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "58/58 [==============================] - 10s 55ms/step - loss: 0.7083 - accuracy: 0.5261 - my_auc: 0.5979 - val_loss: 0.6911 - val_accuracy: 0.0302 - val_my_auc: 0.6365\n",
            " epoch:0 auc: 0.6508\n",
            "Epoch 2/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6850 - accuracy: 0.6246 - my_auc: 0.6589 - val_loss: 0.6843 - val_accuracy: 0.1171 - val_my_auc: 0.6675\n",
            " epoch:1 auc: 0.6679\n",
            "Epoch 3/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6600 - accuracy: 0.6173 - my_auc: 0.6477 - val_loss: 0.6693 - val_accuracy: 0.2616 - val_my_auc: 0.6665\n",
            " epoch:2 auc: 0.6664\n",
            "Epoch 4/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6918 - accuracy: 0.6090 - my_auc: 0.6517 - val_loss: 0.6547 - val_accuracy: 0.3693 - val_my_auc: 0.6712\n",
            " epoch:3 auc: 0.6709\n",
            "Epoch 5/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6689 - accuracy: 0.6011 - my_auc: 0.6718 - val_loss: 0.6441 - val_accuracy: 0.4483 - val_my_auc: 0.6741\n",
            " epoch:4 auc: 0.6743\n",
            "Epoch 6/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6468 - accuracy: 0.5937 - my_auc: 0.6745 - val_loss: 0.6369 - val_accuracy: 0.4950 - val_my_auc: 0.6763\n",
            " epoch:5 auc: 0.6767\n",
            "Epoch 7/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6290 - accuracy: 0.5838 - my_auc: 0.7009 - val_loss: 0.6333 - val_accuracy: 0.5549 - val_my_auc: 0.6789\n",
            " epoch:6 auc: 0.6786\n",
            "Epoch 8/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6330 - accuracy: 0.6121 - my_auc: 0.6884 - val_loss: 0.6307 - val_accuracy: 0.5629 - val_my_auc: 0.6817\n",
            " epoch:7 auc: 0.6816\n",
            "Epoch 9/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.6435 - accuracy: 0.5989 - my_auc: 0.6771 - val_loss: 0.6287 - val_accuracy: 0.5761 - val_my_auc: 0.6829\n",
            " epoch:8 auc: 0.6836\n",
            "Epoch 10/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6410 - accuracy: 0.6035 - my_auc: 0.6875 - val_loss: 0.6271 - val_accuracy: 0.5882 - val_my_auc: 0.6858\n",
            " epoch:9 auc: 0.6861\n",
            "Epoch 11/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6317 - accuracy: 0.6090 - my_auc: 0.7016 - val_loss: 0.6264 - val_accuracy: 0.5787 - val_my_auc: 0.6873\n",
            " epoch:10 auc: 0.6873\n",
            "Epoch 12/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6555 - accuracy: 0.5867 - my_auc: 0.6914 - val_loss: 0.6267 - val_accuracy: 0.6074 - val_my_auc: 0.6890\n",
            " epoch:11 auc: 0.6894\n",
            "Epoch 13/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6555 - accuracy: 0.6116 - my_auc: 0.6881 - val_loss: 0.6256 - val_accuracy: 0.5757 - val_my_auc: 0.6901\n",
            " epoch:12 auc: 0.6904\n",
            "Epoch 14/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6199 - accuracy: 0.5836 - my_auc: 0.7041 - val_loss: 0.6280 - val_accuracy: 0.5925 - val_my_auc: 0.6919\n",
            " epoch:13 auc: 0.6919\n",
            "Epoch 15/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6288 - accuracy: 0.6053 - my_auc: 0.6897 - val_loss: 0.6283 - val_accuracy: 0.5676 - val_my_auc: 0.6906\n",
            " epoch:14 auc: 0.6905\n",
            "Epoch 16/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6113 - accuracy: 0.6054 - my_auc: 0.7370 - val_loss: 0.6292 - val_accuracy: 0.5702 - val_my_auc: 0.6896\n",
            " epoch:15 auc: 0.6897\n",
            "Epoch 17/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6351 - accuracy: 0.5848 - my_auc: 0.7118 - val_loss: 0.6302 - val_accuracy: 0.5768 - val_my_auc: 0.6917\n",
            " epoch:16 auc: 0.6922\n",
            "AUC:  0.6919\n",
            "9781\n",
            "Model: \"model_lstm\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 3, 14)]           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_67 (Batc (None, 3, 14)             56        \n",
            "_________________________________________________________________\n",
            "layer_lstm_1 (LSTM)          (None, 3, 30)             5400      \n",
            "_________________________________________________________________\n",
            "layer_lstm_2 (LSTM)          (None, 30)                7320      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                992       \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 13,801\n",
            "Trainable params: 13,773\n",
            "Non-trainable params: 28\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "58/58 [==============================] - 10s 58ms/step - loss: 0.6918 - accuracy: 0.8370 - my_auc: 0.4985 - val_loss: 0.6919 - val_accuracy: 0.7770 - val_my_auc: 0.6034\n",
            " epoch:0 auc: 0.6176\n",
            "Epoch 2/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6837 - accuracy: 0.8231 - my_auc: 0.6648 - val_loss: 0.6875 - val_accuracy: 0.6009 - val_my_auc: 0.6393\n",
            " epoch:1 auc: 0.6396\n",
            "Epoch 3/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6653 - accuracy: 0.7440 - my_auc: 0.6645 - val_loss: 0.6781 - val_accuracy: 0.5228 - val_my_auc: 0.6504\n",
            " epoch:2 auc: 0.6545\n",
            "Epoch 4/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6772 - accuracy: 0.6732 - my_auc: 0.6712 - val_loss: 0.6648 - val_accuracy: 0.5385 - val_my_auc: 0.6588\n",
            " epoch:3 auc: 0.6588\n",
            "Epoch 5/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6235 - accuracy: 0.6559 - my_auc: 0.6980 - val_loss: 0.6559 - val_accuracy: 0.5257 - val_my_auc: 0.6625\n",
            " epoch:4 auc: 0.6623\n",
            "Epoch 6/30\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.6654 - accuracy: 0.5864 - my_auc: 0.6831 - val_loss: 0.6510 - val_accuracy: 0.5600 - val_my_auc: 0.6643\n",
            " epoch:5 auc: 0.6652\n",
            "Epoch 7/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6192 - accuracy: 0.6080 - my_auc: 0.7044 - val_loss: 0.6492 - val_accuracy: 0.5702 - val_my_auc: 0.6686\n",
            " epoch:6 auc: 0.6683\n",
            "Epoch 8/30\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.6024 - accuracy: 0.6032 - my_auc: 0.6869 - val_loss: 0.6465 - val_accuracy: 0.5712 - val_my_auc: 0.6725\n",
            " epoch:7 auc: 0.6723\n",
            "Epoch 9/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6323 - accuracy: 0.5860 - my_auc: 0.6854 - val_loss: 0.6441 - val_accuracy: 0.5810 - val_my_auc: 0.6769\n",
            " epoch:8 auc: 0.6767\n",
            "Epoch 10/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6066 - accuracy: 0.6023 - my_auc: 0.6930 - val_loss: 0.6445 - val_accuracy: 0.5788 - val_my_auc: 0.6784\n",
            " epoch:9 auc: 0.6788\n",
            "Epoch 11/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6336 - accuracy: 0.5787 - my_auc: 0.6584 - val_loss: 0.6464 - val_accuracy: 0.5820 - val_my_auc: 0.6802\n",
            " epoch:10 auc: 0.6804\n",
            "Epoch 12/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6209 - accuracy: 0.5874 - my_auc: 0.7144 - val_loss: 0.6454 - val_accuracy: 0.5880 - val_my_auc: 0.6833\n",
            " epoch:11 auc: 0.6829\n",
            "Epoch 13/30\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.6162 - accuracy: 0.5911 - my_auc: 0.7017 - val_loss: 0.6496 - val_accuracy: 0.5960 - val_my_auc: 0.6840\n",
            " epoch:12 auc: 0.6842\n",
            "Epoch 14/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6218 - accuracy: 0.5911 - my_auc: 0.6902 - val_loss: 0.6480 - val_accuracy: 0.5933 - val_my_auc: 0.6852\n",
            " epoch:13 auc: 0.6856\n",
            "Epoch 15/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6222 - accuracy: 0.5957 - my_auc: 0.7100 - val_loss: 0.6442 - val_accuracy: 0.5901 - val_my_auc: 0.6884\n",
            " epoch:14 auc: 0.6885\n",
            "Epoch 16/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6172 - accuracy: 0.5907 - my_auc: 0.7109 - val_loss: 0.6431 - val_accuracy: 0.5696 - val_my_auc: 0.6881\n",
            " epoch:15 auc: 0.6880\n",
            "Epoch 17/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6328 - accuracy: 0.5593 - my_auc: 0.7193 - val_loss: 0.6483 - val_accuracy: 0.6097 - val_my_auc: 0.6895\n",
            " epoch:16 auc: 0.6900\n",
            "Epoch 18/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6099 - accuracy: 0.5964 - my_auc: 0.7130 - val_loss: 0.6387 - val_accuracy: 0.5800 - val_my_auc: 0.6908\n",
            " epoch:17 auc: 0.6906\n",
            "Epoch 19/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.5960 - accuracy: 0.5813 - my_auc: 0.7178 - val_loss: 0.6333 - val_accuracy: 0.5728 - val_my_auc: 0.6928\n",
            " epoch:18 auc: 0.6930\n",
            "Epoch 20/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.6417 - accuracy: 0.5651 - my_auc: 0.7095 - val_loss: 0.6391 - val_accuracy: 0.5918 - val_my_auc: 0.6945\n",
            " epoch:19 auc: 0.6943\n",
            "Epoch 21/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.5957 - accuracy: 0.5864 - my_auc: 0.7103 - val_loss: 0.6409 - val_accuracy: 0.5922 - val_my_auc: 0.6949\n",
            " epoch:20 auc: 0.6947\n",
            "Epoch 22/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.5647 - accuracy: 0.6011 - my_auc: 0.7214 - val_loss: 0.6352 - val_accuracy: 0.5507 - val_my_auc: 0.6927\n",
            " epoch:21 auc: 0.6929\n",
            "Epoch 23/30\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.5942 - accuracy: 0.5613 - my_auc: 0.7388 - val_loss: 0.6383 - val_accuracy: 0.5797 - val_my_auc: 0.6934\n",
            " epoch:22 auc: 0.6933\n",
            "Epoch 24/30\n",
            "58/58 [==============================] - 2s 27ms/step - loss: 0.5769 - accuracy: 0.5839 - my_auc: 0.7479 - val_loss: 0.6326 - val_accuracy: 0.5751 - val_my_auc: 0.6943\n",
            " epoch:23 auc: 0.6942\n",
            "AUC:  0.6947\n",
            "9780\n",
            "avg_AUC :  0.7199705384336382\n",
            "avg_AUC_2 :  0.7200085672041896\n",
            "         0         1         2   ...        27        28        29\n",
            "0  0.694479  0.712592  0.712555  ...  0.755364  0.755689  0.756800\n",
            "1  0.605837  0.680680  0.692281  ...  0.734549  0.734226  0.736612\n",
            "2  0.636456  0.667510  0.666461  ...       NaN       NaN       NaN\n",
            "3  0.603447  0.639303  0.650440  ...       NaN       NaN       NaN\n",
            "\n",
            "[4 rows x 30 columns]\n",
            "0     0.635055\n",
            "1     0.675022\n",
            "2     0.680434\n",
            "3     0.685610\n",
            "4     0.688714\n",
            "5     0.691547\n",
            "6     0.694219\n",
            "7     0.697428\n",
            "8     0.699617\n",
            "9     0.701276\n",
            "10    0.703144\n",
            "11    0.705435\n",
            "12    0.705743\n",
            "13    0.705706\n",
            "14    0.708301\n",
            "15    0.709585\n",
            "16    0.711611\n",
            "17    0.720089\n",
            "18    0.721368\n",
            "19    0.722719\n",
            "20    0.723342\n",
            "21    0.722936\n",
            "22    0.724311\n",
            "23    0.726162\n",
            "24    0.741771\n",
            "25    0.741386\n",
            "26    0.744667\n",
            "27    0.744956\n",
            "28    0.744957\n",
            "29    0.746706\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7199705384336382,\n",
              " array([0.00294118, 0.07041724, 0.10560876, 0.12609439, 0.16138851,\n",
              "        0.20246238, 0.21716826, 0.2377223 , 0.25831053, 0.29353625,\n",
              "        0.32582079, 0.34640903, 0.36699726, 0.37869357, 0.3874829 ,\n",
              "        0.39921341, 0.40509576, 0.41976744, 0.44018468, 0.45188098,\n",
              "        0.46942544, 0.48112175, 0.48984268, 0.51036252, 0.51918605,\n",
              "        0.52797538, 0.53679891, 0.55735294, 0.56316689, 0.574829  ,\n",
              "        0.59247606, 0.60417237, 0.6246238 , 0.64514364, 0.65102599,\n",
              "        0.67746238, 0.69794802, 0.70383037, 0.70677155, 0.71556088,\n",
              "        0.71846785, 0.73023256, 0.73611491, 0.74493844, 0.75666895,\n",
              "        0.75961012, 0.76839945, 0.77428181, 0.78604651, 0.79189466,\n",
              "        0.80068399, 0.80068399, 0.80950752, 0.82407661, 0.83290014,\n",
              "        0.83874829, 0.83874829, 0.84459644, 0.85632695, 0.85923393,\n",
              "        0.8621751 , 0.87387141, 0.87975376, 0.88563611, 0.89736662,\n",
              "        0.89736662, 0.90913133, 0.9120383 , 0.91788646, 0.92376881,\n",
              "        0.93255814, 0.93549932, 0.95307798, 0.9619015 , 0.9619015 ,\n",
              "        0.9619015 , 0.96484268, 0.97069083, 0.97363201, 0.98536252,\n",
              "        0.99124487, 0.99124487, 0.99124487, 0.99124487, 0.99124487,\n",
              "        0.99124487, 0.99124487, 0.99124487, 0.99415185, 0.99705882,\n",
              "        0.99705882, 0.99705882, 0.99705882, 0.99705882, 0.99705882,\n",
              "        0.99705882, 1.        , 1.        , 1.        , 1.        ]),\n",
              " [[[array([0., 0., 0., ..., 0., 0., 0.]),\n",
              "    array([0.5903009 , 0.6746893 , 0.29193097, ..., 0.05000496, 0.5225965 ,\n",
              "           0.48077667], dtype=float32)],\n",
              "   array([    6,    10,    12, ..., 39113, 39118, 39121])],\n",
              "  [[array([0., 0., 0., ..., 0., 0., 0.]),\n",
              "    array([0.33004653, 0.5396575 , 0.6320083 , ..., 0.31081545, 0.3778099 ,\n",
              "           0.73899513], dtype=float32)],\n",
              "   array([    0,     5,     9, ..., 39117, 39119, 39122])],\n",
              "  [[array([0., 0., 0., ..., 0., 0., 0.]),\n",
              "    array([0.49678373, 0.52337164, 0.4388396 , ..., 0.6982635 , 0.74602824,\n",
              "           0.5116808 ], dtype=float32)],\n",
              "   array([    1,     2,     4, ..., 39106, 39107, 39115])],\n",
              "  [[array([0., 0., 0., ..., 0., 0., 0.]),\n",
              "    array([0.4384101 , 0.61293876, 0.6000879 , ..., 0.0162946 , 0.05389673,\n",
              "           0.4377035 ], dtype=float32)],\n",
              "   array([    3,     8,    11, ..., 39109, 39116, 39120])]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ph97mfeM_gCb",
        "outputId": "21cca843-13b3-4c66-f4ef-6c7357797aa8"
      },
      "source": [
        "# financial performance timestep = 2\r\n",
        "cross_val(df_fl, 'label', v_perf, 'lstm_perf', 2)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "init A shape:  (53635, 29)\n",
            "(45945, 2, 14) 408.0\n",
            "Model: \"model_lstm\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 2, 14)]           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_56 (Batc (None, 2, 14)             56        \n",
            "_________________________________________________________________\n",
            "layer_lstm_1 (LSTM)          (None, 2, 30)             5400      \n",
            "_________________________________________________________________\n",
            "layer_lstm_2 (LSTM)          (None, 30)                7320      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                992       \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 13,801\n",
            "Trainable params: 13,773\n",
            "Non-trainable params: 28\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 9s 47ms/step - loss: 0.6844 - accuracy: 0.7277 - my_auc: 0.5498 - val_loss: 0.6904 - val_accuracy: 0.7448 - val_my_auc: 0.6375\n",
            " epoch:0 auc: 0.6636\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6786 - accuracy: 0.6716 - my_auc: 0.6558 - val_loss: 0.6834 - val_accuracy: 0.4718 - val_my_auc: 0.6739\n",
            " epoch:1 auc: 0.6821\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6335 - accuracy: 0.6692 - my_auc: 0.6952 - val_loss: 0.6693 - val_accuracy: 0.4340 - val_my_auc: 0.6940\n",
            " epoch:2 auc: 0.6940\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 1s 20ms/step - loss: 0.6726 - accuracy: 0.5922 - my_auc: 0.6576 - val_loss: 0.6525 - val_accuracy: 0.5276 - val_my_auc: 0.6978\n",
            " epoch:3 auc: 0.6978\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 1s 20ms/step - loss: 0.6454 - accuracy: 0.6092 - my_auc: 0.6899 - val_loss: 0.6361 - val_accuracy: 0.5627 - val_my_auc: 0.7024\n",
            " epoch:4 auc: 0.7017\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 1s 20ms/step - loss: 0.6460 - accuracy: 0.6064 - my_auc: 0.6819 - val_loss: 0.6298 - val_accuracy: 0.5869 - val_my_auc: 0.7026\n",
            " epoch:5 auc: 0.7024\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 1s 20ms/step - loss: 0.6529 - accuracy: 0.6109 - my_auc: 0.6698 - val_loss: 0.6268 - val_accuracy: 0.5810 - val_my_auc: 0.7021\n",
            " epoch:6 auc: 0.7024\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6290 - accuracy: 0.6015 - my_auc: 0.7011 - val_loss: 0.6257 - val_accuracy: 0.6186 - val_my_auc: 0.7009\n",
            " epoch:7 auc: 0.7006\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 1s 20ms/step - loss: 0.6366 - accuracy: 0.6152 - my_auc: 0.6718 - val_loss: 0.6248 - val_accuracy: 0.6277 - val_my_auc: 0.6993\n",
            " epoch:8 auc: 0.6995\n",
            "AUC:  0.7024\n",
            "11487\n",
            "Model: \"model_lstm\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 2, 14)]           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_57 (Batc (None, 2, 14)             56        \n",
            "_________________________________________________________________\n",
            "layer_lstm_1 (LSTM)          (None, 2, 30)             5400      \n",
            "_________________________________________________________________\n",
            "layer_lstm_2 (LSTM)          (None, 30)                7320      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                992       \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 13,801\n",
            "Trainable params: 13,773\n",
            "Non-trainable params: 28\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 11s 47ms/step - loss: 0.7152 - accuracy: 0.2328 - my_auc: 0.5244 - val_loss: 0.6914 - val_accuracy: 0.1542 - val_my_auc: 0.6368\n",
            " epoch:0 auc: 0.6640\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6612 - accuracy: 0.7232 - my_auc: 0.6565 - val_loss: 0.6865 - val_accuracy: 0.2063 - val_my_auc: 0.6640\n",
            " epoch:1 auc: 0.6692\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.7019 - accuracy: 0.5857 - my_auc: 0.6634 - val_loss: 0.6736 - val_accuracy: 0.3919 - val_my_auc: 0.6703\n",
            " epoch:2 auc: 0.6713\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6553 - accuracy: 0.6118 - my_auc: 0.6945 - val_loss: 0.6595 - val_accuracy: 0.4706 - val_my_auc: 0.6722\n",
            " epoch:3 auc: 0.6722\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6236 - accuracy: 0.5997 - my_auc: 0.6835 - val_loss: 0.6483 - val_accuracy: 0.5013 - val_my_auc: 0.6759\n",
            " epoch:4 auc: 0.6758\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6508 - accuracy: 0.5588 - my_auc: 0.6889 - val_loss: 0.6441 - val_accuracy: 0.5238 - val_my_auc: 0.6781\n",
            " epoch:5 auc: 0.6779\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6102 - accuracy: 0.5630 - my_auc: 0.6979 - val_loss: 0.6424 - val_accuracy: 0.5171 - val_my_auc: 0.6795\n",
            " epoch:6 auc: 0.6793\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6584 - accuracy: 0.5350 - my_auc: 0.7027 - val_loss: 0.6413 - val_accuracy: 0.5606 - val_my_auc: 0.6804\n",
            " epoch:7 auc: 0.6805\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 1s 20ms/step - loss: 0.6227 - accuracy: 0.5772 - my_auc: 0.6982 - val_loss: 0.6394 - val_accuracy: 0.5622 - val_my_auc: 0.6818\n",
            " epoch:8 auc: 0.6821\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6356 - accuracy: 0.5568 - my_auc: 0.6785 - val_loss: 0.6403 - val_accuracy: 0.5570 - val_my_auc: 0.6822\n",
            " epoch:9 auc: 0.6818\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6068 - accuracy: 0.5693 - my_auc: 0.6979 - val_loss: 0.6389 - val_accuracy: 0.5554 - val_my_auc: 0.6829\n",
            " epoch:10 auc: 0.6831\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6124 - accuracy: 0.5593 - my_auc: 0.6773 - val_loss: 0.6402 - val_accuracy: 0.5465 - val_my_auc: 0.6825\n",
            " epoch:11 auc: 0.6827\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6095 - accuracy: 0.5602 - my_auc: 0.6989 - val_loss: 0.6418 - val_accuracy: 0.5549 - val_my_auc: 0.6825\n",
            " epoch:12 auc: 0.6830\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6294 - accuracy: 0.5533 - my_auc: 0.6966 - val_loss: 0.6391 - val_accuracy: 0.5607 - val_my_auc: 0.6854\n",
            " epoch:13 auc: 0.6850\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.5941 - accuracy: 0.5694 - my_auc: 0.7163 - val_loss: 0.6387 - val_accuracy: 0.5555 - val_my_auc: 0.6846\n",
            " epoch:14 auc: 0.6848\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6011 - accuracy: 0.5722 - my_auc: 0.7147 - val_loss: 0.6356 - val_accuracy: 0.5624 - val_my_auc: 0.6870\n",
            " epoch:15 auc: 0.6867\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.5923 - accuracy: 0.5732 - my_auc: 0.7098 - val_loss: 0.6360 - val_accuracy: 0.5615 - val_my_auc: 0.6888\n",
            " epoch:16 auc: 0.6886\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6088 - accuracy: 0.5718 - my_auc: 0.6911 - val_loss: 0.6355 - val_accuracy: 0.5737 - val_my_auc: 0.6897\n",
            " epoch:17 auc: 0.6899\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6049 - accuracy: 0.5751 - my_auc: 0.7180 - val_loss: 0.6346 - val_accuracy: 0.5737 - val_my_auc: 0.6910\n",
            " epoch:18 auc: 0.6911\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.5940 - accuracy: 0.5805 - my_auc: 0.6958 - val_loss: 0.6345 - val_accuracy: 0.5622 - val_my_auc: 0.6912\n",
            " epoch:19 auc: 0.6912\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6131 - accuracy: 0.5653 - my_auc: 0.6958 - val_loss: 0.6344 - val_accuracy: 0.5600 - val_my_auc: 0.6897\n",
            " epoch:20 auc: 0.6899\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6033 - accuracy: 0.5666 - my_auc: 0.7263 - val_loss: 0.6370 - val_accuracy: 0.5635 - val_my_auc: 0.6910\n",
            " epoch:21 auc: 0.6909\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6311 - accuracy: 0.5617 - my_auc: 0.6924 - val_loss: 0.6343 - val_accuracy: 0.5892 - val_my_auc: 0.6946\n",
            " epoch:22 auc: 0.6942\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.5868 - accuracy: 0.5992 - my_auc: 0.7202 - val_loss: 0.6325 - val_accuracy: 0.5751 - val_my_auc: 0.6944\n",
            " epoch:23 auc: 0.6947\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6106 - accuracy: 0.5740 - my_auc: 0.7168 - val_loss: 0.6324 - val_accuracy: 0.5598 - val_my_auc: 0.6950\n",
            " epoch:24 auc: 0.6954\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6066 - accuracy: 0.5634 - my_auc: 0.7077 - val_loss: 0.6319 - val_accuracy: 0.5774 - val_my_auc: 0.6966\n",
            " epoch:25 auc: 0.6964\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6322 - accuracy: 0.5687 - my_auc: 0.7143 - val_loss: 0.6290 - val_accuracy: 0.5507 - val_my_auc: 0.6962\n",
            " epoch:26 auc: 0.6964\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 1s 20ms/step - loss: 0.6161 - accuracy: 0.5532 - my_auc: 0.7286 - val_loss: 0.6312 - val_accuracy: 0.5990 - val_my_auc: 0.6990\n",
            " epoch:27 auc: 0.6988\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6007 - accuracy: 0.5975 - my_auc: 0.7143 - val_loss: 0.6276 - val_accuracy: 0.5848 - val_my_auc: 0.6997\n",
            " epoch:28 auc: 0.6994\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6000 - accuracy: 0.5842 - my_auc: 0.7324 - val_loss: 0.6261 - val_accuracy: 0.5927 - val_my_auc: 0.6995\n",
            " epoch:29 auc: 0.6997\n",
            "AUC:  0.6994\n",
            "11486\n",
            "Model: \"model_lstm\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 2, 14)]           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_58 (Batc (None, 2, 14)             56        \n",
            "_________________________________________________________________\n",
            "layer_lstm_1 (LSTM)          (None, 2, 30)             5400      \n",
            "_________________________________________________________________\n",
            "layer_lstm_2 (LSTM)          (None, 30)                7320      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                992       \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 13,801\n",
            "Trainable params: 13,773\n",
            "Non-trainable params: 28\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 10s 48ms/step - loss: 0.6725 - accuracy: 0.9304 - my_auc: 0.4251 - val_loss: 0.6922 - val_accuracy: 0.3055 - val_my_auc: 0.6003\n",
            " epoch:0 auc: 0.6558\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6718 - accuracy: 0.8400 - my_auc: 0.6494 - val_loss: 0.6891 - val_accuracy: 0.2590 - val_my_auc: 0.6637\n",
            " epoch:1 auc: 0.6852\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.7059 - accuracy: 0.7003 - my_auc: 0.6531 - val_loss: 0.6814 - val_accuracy: 0.4197 - val_my_auc: 0.6921\n",
            " epoch:2 auc: 0.6913\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6748 - accuracy: 0.6824 - my_auc: 0.6652 - val_loss: 0.6677 - val_accuracy: 0.5041 - val_my_auc: 0.6917\n",
            " epoch:3 auc: 0.6926\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6466 - accuracy: 0.6548 - my_auc: 0.6987 - val_loss: 0.6550 - val_accuracy: 0.5164 - val_my_auc: 0.6929\n",
            " epoch:4 auc: 0.6924\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6245 - accuracy: 0.6255 - my_auc: 0.6846 - val_loss: 0.6457 - val_accuracy: 0.5454 - val_my_auc: 0.6934\n",
            " epoch:5 auc: 0.6931\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6335 - accuracy: 0.6047 - my_auc: 0.7100 - val_loss: 0.6391 - val_accuracy: 0.5811 - val_my_auc: 0.6930\n",
            " epoch:6 auc: 0.6932\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6196 - accuracy: 0.6160 - my_auc: 0.6918 - val_loss: 0.6357 - val_accuracy: 0.5548 - val_my_auc: 0.6938\n",
            " epoch:7 auc: 0.6941\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6473 - accuracy: 0.5804 - my_auc: 0.6783 - val_loss: 0.6320 - val_accuracy: 0.5893 - val_my_auc: 0.6973\n",
            " epoch:8 auc: 0.6968\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6440 - accuracy: 0.5893 - my_auc: 0.6920 - val_loss: 0.6317 - val_accuracy: 0.5898 - val_my_auc: 0.6969\n",
            " epoch:9 auc: 0.6971\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6174 - accuracy: 0.5966 - my_auc: 0.6970 - val_loss: 0.6298 - val_accuracy: 0.5760 - val_my_auc: 0.7004\n",
            " epoch:10 auc: 0.7001\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 1s 20ms/step - loss: 0.6593 - accuracy: 0.5765 - my_auc: 0.6809 - val_loss: 0.6298 - val_accuracy: 0.6035 - val_my_auc: 0.6987\n",
            " epoch:11 auc: 0.6986\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 1s 20ms/step - loss: 0.6591 - accuracy: 0.5873 - my_auc: 0.6721 - val_loss: 0.6291 - val_accuracy: 0.5886 - val_my_auc: 0.6979\n",
            " epoch:12 auc: 0.6980\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6653 - accuracy: 0.5908 - my_auc: 0.6814 - val_loss: 0.6279 - val_accuracy: 0.5881 - val_my_auc: 0.7001\n",
            " epoch:13 auc: 0.7001\n",
            "AUC:  0.7001\n",
            "11486\n",
            "Model: \"model_lstm\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 2, 14)]           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_59 (Batc (None, 2, 14)             56        \n",
            "_________________________________________________________________\n",
            "layer_lstm_1 (LSTM)          (None, 2, 30)             5400      \n",
            "_________________________________________________________________\n",
            "layer_lstm_2 (LSTM)          (None, 30)                7320      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                992       \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 13,801\n",
            "Trainable params: 13,773\n",
            "Non-trainable params: 28\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 10s 47ms/step - loss: 0.6739 - accuracy: 0.6786 - my_auc: 0.5741 - val_loss: 0.6908 - val_accuracy: 0.0259 - val_my_auc: 0.6558\n",
            " epoch:0 auc: 0.6522\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6718 - accuracy: 0.6256 - my_auc: 0.6373 - val_loss: 0.6845 - val_accuracy: 0.1383 - val_my_auc: 0.6559\n",
            " epoch:1 auc: 0.6586\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6863 - accuracy: 0.5655 - my_auc: 0.6584 - val_loss: 0.6711 - val_accuracy: 0.3630 - val_my_auc: 0.6625\n",
            " epoch:2 auc: 0.6635\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6333 - accuracy: 0.6293 - my_auc: 0.6749 - val_loss: 0.6574 - val_accuracy: 0.4583 - val_my_auc: 0.6671\n",
            " epoch:3 auc: 0.6671\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6394 - accuracy: 0.6005 - my_auc: 0.7022 - val_loss: 0.6474 - val_accuracy: 0.5132 - val_my_auc: 0.6726\n",
            " epoch:4 auc: 0.6723\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6225 - accuracy: 0.6039 - my_auc: 0.7099 - val_loss: 0.6405 - val_accuracy: 0.5542 - val_my_auc: 0.6775\n",
            " epoch:5 auc: 0.6775\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6378 - accuracy: 0.6049 - my_auc: 0.6994 - val_loss: 0.6356 - val_accuracy: 0.5748 - val_my_auc: 0.6838\n",
            " epoch:6 auc: 0.6836\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6338 - accuracy: 0.6056 - my_auc: 0.6907 - val_loss: 0.6339 - val_accuracy: 0.5590 - val_my_auc: 0.6862\n",
            " epoch:7 auc: 0.6866\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6367 - accuracy: 0.5858 - my_auc: 0.6893 - val_loss: 0.6303 - val_accuracy: 0.5908 - val_my_auc: 0.6909\n",
            " epoch:8 auc: 0.6908\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.5881 - accuracy: 0.6237 - my_auc: 0.7164 - val_loss: 0.6274 - val_accuracy: 0.5728 - val_my_auc: 0.6946\n",
            " epoch:9 auc: 0.6944\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6210 - accuracy: 0.6046 - my_auc: 0.7071 - val_loss: 0.6256 - val_accuracy: 0.5712 - val_my_auc: 0.6972\n",
            " epoch:10 auc: 0.6969\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6085 - accuracy: 0.6007 - my_auc: 0.6921 - val_loss: 0.6257 - val_accuracy: 0.5491 - val_my_auc: 0.6974\n",
            " epoch:11 auc: 0.6974\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6646 - accuracy: 0.5693 - my_auc: 0.6946 - val_loss: 0.6236 - val_accuracy: 0.5865 - val_my_auc: 0.7012\n",
            " epoch:12 auc: 0.7013\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6112 - accuracy: 0.6078 - my_auc: 0.7104 - val_loss: 0.6242 - val_accuracy: 0.5596 - val_my_auc: 0.7005\n",
            " epoch:13 auc: 0.7003\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6251 - accuracy: 0.5822 - my_auc: 0.6939 - val_loss: 0.6212 - val_accuracy: 0.5880 - val_my_auc: 0.7041\n",
            " epoch:14 auc: 0.7038\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6456 - accuracy: 0.6030 - my_auc: 0.6964 - val_loss: 0.6211 - val_accuracy: 0.5699 - val_my_auc: 0.7044\n",
            " epoch:15 auc: 0.7039\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6381 - accuracy: 0.5864 - my_auc: 0.6791 - val_loss: 0.6198 - val_accuracy: 0.5746 - val_my_auc: 0.7060\n",
            " epoch:16 auc: 0.7059\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6347 - accuracy: 0.5941 - my_auc: 0.7064 - val_loss: 0.6188 - val_accuracy: 0.5892 - val_my_auc: 0.7077\n",
            " epoch:17 auc: 0.7074\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6167 - accuracy: 0.6122 - my_auc: 0.6825 - val_loss: 0.6178 - val_accuracy: 0.5710 - val_my_auc: 0.7080\n",
            " epoch:18 auc: 0.7082\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6199 - accuracy: 0.5945 - my_auc: 0.7112 - val_loss: 0.6190 - val_accuracy: 0.5564 - val_my_auc: 0.7081\n",
            " epoch:19 auc: 0.7076\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6550 - accuracy: 0.5750 - my_auc: 0.6941 - val_loss: 0.6190 - val_accuracy: 0.5523 - val_my_auc: 0.7083\n",
            " epoch:20 auc: 0.7083\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.5990 - accuracy: 0.5878 - my_auc: 0.7058 - val_loss: 0.6200 - val_accuracy: 0.5548 - val_my_auc: 0.7074\n",
            " epoch:21 auc: 0.7071\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6220 - accuracy: 0.5797 - my_auc: 0.7212 - val_loss: 0.6177 - val_accuracy: 0.5784 - val_my_auc: 0.7114\n",
            " epoch:22 auc: 0.7114\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.5693 - accuracy: 0.6166 - my_auc: 0.7342 - val_loss: 0.6179 - val_accuracy: 0.5687 - val_my_auc: 0.7113\n",
            " epoch:23 auc: 0.7112\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6198 - accuracy: 0.5922 - my_auc: 0.7185 - val_loss: 0.6179 - val_accuracy: 0.5608 - val_my_auc: 0.7126\n",
            " epoch:24 auc: 0.7125\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6443 - accuracy: 0.5896 - my_auc: 0.7047 - val_loss: 0.6171 - val_accuracy: 0.5929 - val_my_auc: 0.7128\n",
            " epoch:25 auc: 0.7129\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6072 - accuracy: 0.6135 - my_auc: 0.7320 - val_loss: 0.6174 - val_accuracy: 0.5604 - val_my_auc: 0.7125\n",
            " epoch:26 auc: 0.7124\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6277 - accuracy: 0.5790 - my_auc: 0.7138 - val_loss: 0.6167 - val_accuracy: 0.5773 - val_my_auc: 0.7138\n",
            " epoch:27 auc: 0.7137\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.5814 - accuracy: 0.6128 - my_auc: 0.7414 - val_loss: 0.6175 - val_accuracy: 0.5699 - val_my_auc: 0.7101\n",
            " epoch:28 auc: 0.7102\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 2s 22ms/step - loss: 0.5863 - accuracy: 0.6054 - my_auc: 0.7172 - val_loss: 0.6166 - val_accuracy: 0.5689 - val_my_auc: 0.7125\n",
            " epoch:29 auc: 0.7127\n",
            "AUC:  0.7137\n",
            "11486\n",
            "avg_AUC :  0.7039040328260695\n",
            "avg_AUC_2 :  0.7038646266587443\n",
            "         0         1         2   ...        27        28        29\n",
            "0  0.637482  0.673948  0.693951  ...       NaN       NaN       NaN\n",
            "1  0.636801  0.663993  0.670267  ...  0.699019  0.699723  0.699535\n",
            "2  0.600267  0.663698  0.692129  ...       NaN       NaN       NaN\n",
            "3  0.655799  0.655907  0.662526  ...  0.713808  0.710119  0.712507\n",
            "\n",
            "[4 rows x 30 columns]\n",
            "0     0.632587\n",
            "1     0.664386\n",
            "2     0.679718\n",
            "3     0.682217\n",
            "4     0.685936\n",
            "5     0.687918\n",
            "6     0.689591\n",
            "7     0.690321\n",
            "8     0.692344\n",
            "9     0.691225\n",
            "10    0.693508\n",
            "11    0.692872\n",
            "12    0.693850\n",
            "13    0.695302\n",
            "14    0.694336\n",
            "15    0.695663\n",
            "16    0.697407\n",
            "17    0.698690\n",
            "18    0.699533\n",
            "19    0.699636\n",
            "20    0.699017\n",
            "21    0.699190\n",
            "22    0.702992\n",
            "23    0.702838\n",
            "24    0.703800\n",
            "25    0.704714\n",
            "26    0.704348\n",
            "27    0.706414\n",
            "28    0.704921\n",
            "29    0.706021\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7039040328260695,\n",
              " array([0.00245098, 0.05882353, 0.09803922, 0.12745098, 0.16666667,\n",
              "        0.17892157, 0.20588235, 0.22303922, 0.2622549 , 0.29166667,\n",
              "        0.29656863, 0.31372549, 0.33823529, 0.3504902 , 0.36029412,\n",
              "        0.36519608, 0.37990196, 0.39705882, 0.40686275, 0.42892157,\n",
              "        0.44607843, 0.47303922, 0.47794118, 0.49019608, 0.5       ,\n",
              "        0.50980392, 0.5245098 , 0.54411765, 0.56372549, 0.57843137,\n",
              "        0.58578431, 0.59313725, 0.60784314, 0.6127451 , 0.62745098,\n",
              "        0.64215686, 0.65196078, 0.65441176, 0.66666667, 0.68382353,\n",
              "        0.70833333, 0.71813725, 0.7254902 , 0.73284314, 0.74264706,\n",
              "        0.75245098, 0.75735294, 0.75980392, 0.77696078, 0.78676471,\n",
              "        0.78921569, 0.79656863, 0.80392157, 0.80637255, 0.80882353,\n",
              "        0.81372549, 0.82598039, 0.82598039, 0.83088235, 0.84313725,\n",
              "        0.8504902 , 0.8627451 , 0.86519608, 0.87009804, 0.87254902,\n",
              "        0.88480392, 0.89215686, 0.89460784, 0.90196078, 0.90196078,\n",
              "        0.90196078, 0.90931373, 0.91176471, 0.92156863, 0.92892157,\n",
              "        0.93627451, 0.94362745, 0.95343137, 0.95343137, 0.96078431,\n",
              "        0.96813725, 0.97303922, 0.97794118, 0.97794118, 0.98284314,\n",
              "        0.98529412, 0.98529412, 0.98529412, 0.9877451 , 0.9877451 ,\n",
              "        0.9877451 , 0.99019608, 0.99509804, 0.99509804, 0.99754902,\n",
              "        0.99754902, 1.        , 1.        , 1.        , 1.        ]),\n",
              " [[[array([0., 0., 0., ..., 0., 0., 0.]),\n",
              "    array([0.33499786, 0.64066297, 0.5241118 , ..., 0.6259867 , 0.49027315,\n",
              "           0.6520592 ], dtype=float32)],\n",
              "   array([    0,    11,    12, ..., 45939, 45940, 45943])],\n",
              "  [[array([0., 0., 0., ..., 0., 0., 0.]),\n",
              "    array([0.43917713, 0.52758425, 0.70324165, ..., 0.54399246, 0.80846334,\n",
              "           0.27304435], dtype=float32)],\n",
              "   array([    4,     8,    10, ..., 45936, 45938, 45944])],\n",
              "  [[array([0., 0., 0., ..., 0., 0., 0.]),\n",
              "    array([0.4391513 , 0.5396592 , 0.3589238 , ..., 0.7339598 , 0.5912581 ,\n",
              "           0.46326712], dtype=float32)],\n",
              "   array([    1,     2,     5, ..., 45920, 45922, 45924])],\n",
              "  [[array([0., 0., 0., ..., 0., 0., 0.]),\n",
              "    array([0.47811422, 0.70148546, 0.5472333 , ..., 0.36513   , 0.56760126,\n",
              "           0.56641597], dtype=float32)],\n",
              "   array([    3,    17,    20, ..., 45937, 45941, 45942])]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkzIKyXuCtyq"
      },
      "source": [
        "# LSTM+CNN+TCN\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hLnGyW7J_Yg"
      },
      "source": [
        "# def model_cnn(w, num_wrds, num_depth):\r\n",
        "#   model = None\r\n",
        "#   input_wds = Input(shape=(w, num_wrds, 1),dtype='float32', name='input_words')\r\n",
        "\r\n",
        "#   cov = Conv2D(4, (2,2), activation='relu')(input_wds)\r\n",
        "#   maxpool = MaxPooling2D((1,1))(cov)\r\n",
        "#   #reshp = Reshape((1,64))(maxpool)\r\n",
        "#   #flt = Flatten()(maxpool)\r\n",
        "#   model = Model(inputs=input_wds, outputs= maxpool)\r\n",
        "#   model._name = 'cnn'          \r\n",
        "#   model.summary()\r\n",
        "#   return model\r\n",
        "\r\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVlUupiwsRkI"
      },
      "source": [
        "# def model_lstm(n1, n2, n3, w, num_wrds, num_perf, num_depth):\r\n",
        "#     model = None\r\n",
        "    \r\n",
        "#     input_perf = Input(shape=(1,num_perf),dtype='float32', name='input_financial')\r\n",
        "#     input_wds = Input(shape=(w,num_wrds),dtype='float32', name='input_words')\r\n",
        "\r\n",
        "#     cnnmodel = model_cnn(w, num_wrds, num_depth)\r\n",
        "#     cnn_wrds = cnnmodel(input_wds)\r\n",
        "\r\n",
        "#     reshp_perf = Reshape((1,num_perf))(input_perf)\r\n",
        "\r\n",
        "#     concate = Concatenate(axis=-1)([cnn_wrds,input_perf])\r\n",
        "\r\n",
        "#     #nor = BatchNormalization()(concate)\r\n",
        "#     drop1 = Dropout(0.3)(concate)\r\n",
        "#     #nor = BatchNormalization()(drop1)\r\n",
        "#     # LSTM_w_1 = Bidirectional(LSTM(81,recurrent_dropout = 0.2, name = 'layer_lstm_1',\\\r\n",
        "#     #                   return_sequences=True, \\\r\n",
        "#     #                #kernel_regularizer=regularizers.l2(0.01),\\\r\n",
        "#     #                #bias_regularizer=regularizers.l2(0.01),\r\n",
        "#     #               activity_regularizer=regularizers.l2(0.01)))(drop1)\r\n",
        "#     LSTM_w_2 = LSTM(81,recurrent_dropout = 0.2, name = 'layer_lstm_2', \\\r\n",
        "#                 return_sequences=False )(drop1)        \r\n",
        "#     #nor = BatchNormalization()(LSTM_w_2)\r\n",
        "#     dense1 = Dense(81, activation='relu', name='dense1')(LSTM_w_2)\r\n",
        "#     dense2 = Dense(n3, activation='relu', name='dense2')(dense1)\r\n",
        "#     nor = BatchNormalization()(dense2)\r\n",
        "#     drop2 = Dropout(0.3)(nor)\r\n",
        "    \r\n",
        "#     preds = Dense(1, activation='sigmoid', name='output')(drop2)\r\n",
        "#     model = Model(inputs=[input_perf, input_wds], outputs=preds)\r\n",
        "#     model._name = \"lstm\"\r\n",
        "#     model.summary()\r\n",
        "    \r\n",
        "#     return model"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8RP1jytmqrO"
      },
      "source": [
        "#LR\r\n",
        "# def model_cnn_lstm(n1, n2, n3, T, perf, words, channel, filters = 24):\r\n",
        "#     model = None\r\n",
        "    \r\n",
        "#     input_perf = Input(shape=(T,perf), \\\r\n",
        "#                       dtype='float32', name='input_perf')\r\n",
        "    \r\n",
        "#     input_words = Input(shape=(T, words, channel), \\\r\n",
        "#                       dtype='float32', name='input_words') \r\n",
        "    \r\n",
        "#     word_norm = BatchNormalization()(input_words)\r\n",
        "    \r\n",
        "    \r\n",
        "#     conv = Conv2D(filters = filters,\\\r\n",
        "#                   kernel_size = 1,\\\r\n",
        "#                   use_bias = False,\\\r\n",
        "#                   activation = None)(word_norm)  # Shape None x T x words x filters\r\n",
        "#     print(\"conv shape:\", K.int_shape(conv))\r\n",
        "#     conv = BatchNormalization()(conv)\r\n",
        "#     conv = Activation(\"relu\") (conv)\r\n",
        "    \r\n",
        "#     pool = MaxPooling2D(pool_size=(1, words), \\\r\n",
        "#                         strides=(1,1))(conv) # None x T x filters\r\n",
        "#     pool = Reshape((T, filters))(conv)\r\n",
        "#     print(\"pool shape:\", K.int_shape(pool))\r\n",
        "    \r\n",
        "#     #drop = Dropout(0.3)(input_all)\r\n",
        "#     # Now concatenate\r\n",
        "#     perf_norm = BatchNormalization()(input_perf)\r\n",
        "#     all_input = Concatenate(axis = -1)([perf_norm, pool])\r\n",
        "#     #nor = BatchNormalization()(all_input)\r\n",
        "    \r\n",
        "#     LSTM_w_1 = Bidirectional(LSTM(n1, dropout= 0.3, recurrent_dropout = 0.3,\\\r\n",
        "#                     name = 'layer_lstm_1', return_sequences=True))(all_input)\r\n",
        "#     LSTM_w_2 = LSTM(n2, dropout= 0.3, recurrent_dropout = 0.3,\r\n",
        "#                    name = 'layer_lstm_2', return_sequences=False)(LSTM_w_1)\r\n",
        "    \r\n",
        "#     dense = Dense(n3, activation='relu', name='dense')(LSTM_w_2)\r\n",
        "#     drop = Dropout(0.3)(dense)\r\n",
        "    \r\n",
        "#     preds = Dense(1, activation='sigmoid', name='output')(drop)\r\n",
        "#     model = Model(inputs=[input_perf, input_words], outputs=preds)\r\n",
        "#     model._name = \"model_cnnlstm\"\r\n",
        "#     model.summary()\r\n",
        "    \r\n",
        "#     return model"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDstFvvF2Jav"
      },
      "source": [
        "def model_cnn_lstm_1(n1,n2,n3,T, perf, words, types ,filters = 32): #channel,\r\n",
        "    model = None\r\n",
        "    filters = 32\r\n",
        "    \r\n",
        "    input_perf = Input(shape=(T,perf), \\\r\n",
        "                      dtype='float32', name='input_perf')\r\n",
        "    \r\n",
        "    input_words = Input(shape=(T,words,types), \\\r\n",
        "                      dtype='float32', name='input_words')\r\n",
        "    \r\n",
        "\r\n",
        "    conv = Conv2D(filters = filters,\\\r\n",
        "                  kernel_size = (1,4),\\\r\n",
        "                  activation = 'relu')(input_words)  # Shape None x T x words x filters\r\n",
        "    print(\"conv shape 1:\", K.int_shape(conv))\r\n",
        "    conv = BatchNormalization()(conv)\r\n",
        "    conv = Activation(\"relu\") (conv)\r\n",
        "    pool_1 = MaxPooling2D(pool_size= (1,17), \\\r\n",
        "                        strides=1)(conv)\r\n",
        "    pool_1 = Reshape((T, filters))(pool_1)\r\n",
        "\r\n",
        "    conv = Conv2D(filters = filters,\\\r\n",
        "                  kernel_size = (1,4),\\\r\n",
        "                  activation = 'relu')(conv)  # Shape None x T x words x filters\r\n",
        "    print(\"conv shape 2:\", K.int_shape(conv))\r\n",
        "    conv = BatchNormalization()(conv)\r\n",
        "    conv = Activation(\"relu\") (conv)\r\n",
        "    pool_2 = MaxPooling2D(pool_size= (1,14), \\\r\n",
        "                        strides=1)(conv)\r\n",
        "    pool_2 = Reshape((T, filters))(pool_2)\r\n",
        "\r\n",
        "\r\n",
        "    conv = Conv2D(filters = filters,\\\r\n",
        "                  kernel_size = (1,4),\\\r\n",
        "                  activation = 'relu')(conv)  # Shape None x T x words x filters\r\n",
        "    print(\"conv shape 3:\", K.int_shape(conv))\r\n",
        "    conv = BatchNormalization()(conv)\r\n",
        "    conv = Activation(\"relu\") (conv)\r\n",
        "    pool_3 = MaxPooling2D(pool_size= (1,11), \\\r\n",
        "                        strides=1)(conv)\r\n",
        "    pool_3 = Reshape((T, filters))(pool_3)\r\n",
        "    \r\n",
        "    # conv = Conv2D(filters = filters,\\\r\n",
        "    #               kernel_size = (1,4),\\\r\n",
        "    #               activation = 'relu')(conv)  # Shape None x T x words x filters\r\n",
        "    # print(\"conv shape 4:\", K.int_shape(conv))\r\n",
        "    # conv = BatchNormalization()(conv)\r\n",
        "    # conv = Activation(\"relu\") (conv)\r\n",
        "    # pool_4 = MaxPooling2D(pool_size= (1,8), \\\r\n",
        "    #                     strides=1)(conv)\r\n",
        "    # pool_4 = Reshape((T, filters))(pool_4)\r\n",
        "    \r\n",
        "    # pool = MaxPooling2D(pool_size= (1,8), \\\r\n",
        "    #                     strides=1)(conv) # None x T x filters\r\n",
        "    \r\n",
        "    # print(\"pool_init shape:\", K.int_shape(pool))\r\n",
        "    # pool = Reshape((T, filters))(pool)\r\n",
        "    # print(\"pool shape:\", K.int_shape(pool))\r\n",
        "    \r\n",
        "    #drop = Dropout(0.3)(input_all)\r\n",
        "    # Now concatenate\r\n",
        "    perf_norm = BatchNormalization()(input_perf)\r\n",
        "    all_input = Concatenate(axis = -1)([perf_norm, pool_3, pool_2, pool_1 ])\r\n",
        "    nor = BatchNormalization()(all_input)\r\n",
        "    #drop = Dropout(0.3)(nor)\r\n",
        "    \r\n",
        "    LSTM_w_1 =Bidirectional(LSTM(120,  recurrent_dropout = 0.2,\r\n",
        "                    name = 'layer_lstm_1', return_sequences=True,\r\n",
        "                    kernel_regularizer = regularizers.l2(0.01),\r\n",
        "                    activity_regularizer = regularizers.l2(0.01),\r\n",
        "                    bias_regularizer = regularizers.l2(0.01)\r\n",
        "                    ))(nor)\r\n",
        "    LSTM_w_2 = LSTM(120, recurrent_dropout = 0.2, \r\n",
        "                   name = 'layer_lstm_2', return_sequences=False)(LSTM_w_1)\r\n",
        "\r\n",
        "    dense = Dense(32, activation='relu', name='dense')(LSTM_w_2)\r\n",
        "    nor = BatchNormalization()(dense)\r\n",
        "    drop = Dropout(0.3)(nor)\r\n",
        "    preds = Dense(1, activation='sigmoid', name='output')(drop)\r\n",
        "    model = Model(inputs=[input_perf, input_words], outputs=preds)\r\n",
        "    model._name = \"model_cnnlstm_1\"\r\n",
        "    model.summary()\r\n",
        "    \r\n",
        "    return model"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4bg7qkX98EY"
      },
      "source": [
        "def model_cnn_lstm_2(n1,n2,n3,T, perf, words, types ,filters = 32): #channel,\r\n",
        "    model = None\r\n",
        "    filters = 32\r\n",
        "    \r\n",
        "    input_perf = Input(shape=(T,perf), \\\r\n",
        "                      dtype='float32', name='input_perf')\r\n",
        "    \r\n",
        "    input_words = Input(shape=(T,words,types), \\\r\n",
        "                      dtype='float32', name='input_words')\r\n",
        "    \r\n",
        "\r\n",
        "    conv = Conv2D(filters = filters,\\\r\n",
        "                  kernel_size = (1,4),\\\r\n",
        "                  activation = 'relu')(input_words)  # Shape None x T x words x filters\r\n",
        "    print(\"conv shape 1:\", K.int_shape(conv))\r\n",
        "    conv = BatchNormalization()(conv)\r\n",
        "    conv = Activation(\"relu\") (conv)\r\n",
        "\r\n",
        "    conv = Conv2D(filters = filters,\\\r\n",
        "                  kernel_size = (1,4),\\\r\n",
        "                  activation = 'relu')(conv)  # Shape None x T x words x filters\r\n",
        "    print(\"conv shape 2:\", K.int_shape(conv))\r\n",
        "    conv = BatchNormalization()(conv)\r\n",
        "    conv = Activation(\"relu\") (conv)\r\n",
        "\r\n",
        "\r\n",
        "    conv = Conv2D(filters = filters,\\\r\n",
        "                  kernel_size = (1,4),\\\r\n",
        "                  activation = 'relu')(conv)  # Shape None x T x words x filters\r\n",
        "    print(\"conv shape 3:\", K.int_shape(conv))\r\n",
        "    conv = BatchNormalization()(conv)\r\n",
        "    conv = Activation(\"relu\") (conv)\r\n",
        "    \r\n",
        "    conv = Conv2D(filters = filters,\\\r\n",
        "                  kernel_size = (1,4),\\\r\n",
        "                  activation = 'relu')(conv)  # Shape None x T x words x filters\r\n",
        "    print(\"conv shape 4:\", K.int_shape(conv))\r\n",
        "    conv = BatchNormalization()(conv)\r\n",
        "    conv = Activation(\"relu\") (conv)\r\n",
        "    \r\n",
        "    pool = MaxPooling2D(pool_size= (1,8), \\\r\n",
        "                        strides=1)(conv) # None x T x filters\r\n",
        "    \r\n",
        "    print(\"pool_init shape:\", K.int_shape(pool))\r\n",
        "    pool = Reshape((T, filters))(pool)\r\n",
        "    print(\"pool shape:\", K.int_shape(pool))\r\n",
        "    \r\n",
        "    #drop = Dropout(0.3)(input_all)\r\n",
        "    # Now concatenate\r\n",
        "    perf_norm = BatchNormalization()(input_perf)\r\n",
        "    all_input = Concatenate(axis = -1)([perf_norm, pool ])\r\n",
        "    nor = BatchNormalization()(all_input)\r\n",
        "    #drop = Dropout(0.3)(nor)\r\n",
        "    \r\n",
        "    LSTM_w_1 =Bidirectional(LSTM(n1,  recurrent_dropout = 0.2,\r\n",
        "                    name = 'layer_lstm_1', return_sequences=True,\r\n",
        "                    kernel_regularizer = regularizers.l2(0.01),\r\n",
        "                    activity_regularizer = regularizers.l2(0.01),\r\n",
        "                    bias_regularizer = regularizers.l2(0.01)\r\n",
        "                    ))(nor)\r\n",
        "    LSTM_w_2 = LSTM(n2, recurrent_dropout = 0.2, \r\n",
        "                   name = 'layer_lstm_2', return_sequences=False)(LSTM_w_1)\r\n",
        "\r\n",
        "    dense = Dense(32, activation='relu', name='dense')(LSTM_w_2)\r\n",
        "    nor = BatchNormalization()(dense)\r\n",
        "    drop = Dropout(0.3)(nor)\r\n",
        "    preds = Dense(1, activation='sigmoid', name='output')(drop)\r\n",
        "    model = Model(inputs=[input_perf, input_words], outputs=preds)\r\n",
        "    model._name = \"model_cnnlstm_2\"\r\n",
        "    model.summary()\r\n",
        "    \r\n",
        "    return model"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7G_3E_OX3uc0"
      },
      "source": [
        "def model_cnn_lstm_3(n1,n2,n3,T, perf, words, types ,filters = 32): #channel,\r\n",
        "    model = None\r\n",
        "    filters = 32\r\n",
        "    \r\n",
        "    input_perf = Input(shape=(T,perf), \\\r\n",
        "                      dtype='float32', name='input_perf')\r\n",
        "    \r\n",
        "    input_words = Input(shape=(T,words,types), \\\r\n",
        "                      dtype='float32', name='input_words')\r\n",
        "    \r\n",
        "\r\n",
        "    conv = Conv2D(filters = filters,\\\r\n",
        "                  kernel_size = (1,4),\\\r\n",
        "                  activation = 'relu')(input_words)  # Shape None x T x words x filters\r\n",
        "    print(\"conv shape 1:\", K.int_shape(conv))\r\n",
        "    conv = BatchNormalization()(conv)\r\n",
        "    conv = Activation(\"relu\") (conv)\r\n",
        "    pool = MaxPooling2D(pool_size= (1,4), \\\r\n",
        "                        strides=1)(conv)\r\n",
        "\r\n",
        "    conv = Conv2D(filters = filters,\\\r\n",
        "                  kernel_size = (1,4),\\\r\n",
        "                  activation = 'relu')(pool)  # Shape None x T x words x filters\r\n",
        "    print(\"conv shape 2:\", K.int_shape(conv))\r\n",
        "    conv = BatchNormalization()(conv)\r\n",
        "    conv = Activation(\"relu\") (conv)\r\n",
        "    pool = MaxPooling2D(pool_size= (1,4), \\\r\n",
        "                        strides=1)(conv)\r\n",
        "\r\n",
        "    conv = Conv2D(filters = filters,\\\r\n",
        "                  kernel_size = (1,4),\\\r\n",
        "                  activation = 'relu')(pool)  # Shape None x T x words x filters\r\n",
        "    print(\"conv shape 3:\", K.int_shape(conv))\r\n",
        "    conv = BatchNormalization()(conv)\r\n",
        "    conv = Activation(\"relu\") (conv)\r\n",
        "    \r\n",
        "    # conv = Conv2D(filters = filters,\\\r\n",
        "    #               kernel_size = (1,4),\\\r\n",
        "    #               activation = 'relu')(conv)  # Shape None x T x words x filters\r\n",
        "    # print(\"conv shape 4:\", K.int_shape(conv))\r\n",
        "    # conv = BatchNormalization()(conv)\r\n",
        "    # conv = Activation(\"relu\") (conv)\r\n",
        "    \r\n",
        "    pool = MaxPooling2D(pool_size= (1,5), \\\r\n",
        "                        strides=1)(conv) # None x T x filters\r\n",
        "    \r\n",
        "    print(\"pool_init shape:\", K.int_shape(pool))\r\n",
        "    pool = Reshape((T, filters))(pool)\r\n",
        "    print(\"pool shape:\", K.int_shape(pool))\r\n",
        "    \r\n",
        "    #drop = Dropout(0.3)(input_all)\r\n",
        "    # Now concatenate\r\n",
        "    perf_norm = BatchNormalization()(input_perf)\r\n",
        "    all_input = Concatenate(axis = -1)([perf_norm, pool ])\r\n",
        "    nor = BatchNormalization()(all_input)\r\n",
        "    #drop = Dropout(0.3)(nor)\r\n",
        "    \r\n",
        "    LSTM_w_1 =Bidirectional(LSTM(n1,  recurrent_dropout = 0.2,\r\n",
        "                    name = 'layer_lstm_1', return_sequences=True,\r\n",
        "                    kernel_regularizer = regularizers.l2(0.01),\r\n",
        "                    activity_regularizer = regularizers.l2(0.01),\r\n",
        "                    bias_regularizer = regularizers.l2(0.01)\r\n",
        "                    ))(nor)\r\n",
        "    LSTM_w_2 = LSTM(n2, recurrent_dropout = 0.2, \r\n",
        "                   name = 'layer_lstm_2', return_sequences=False)(LSTM_w_1)\r\n",
        "\r\n",
        "    dense = Dense(32, activation='relu', name='dense')(LSTM_w_2)\r\n",
        "    nor = BatchNormalization()(dense)\r\n",
        "    drop = Dropout(0.3)(nor)\r\n",
        "    preds = Dense(1, activation='sigmoid', name='output')(drop)\r\n",
        "    model = Model(inputs=[input_perf, input_words], outputs=preds)\r\n",
        "    model._name = \"model_cnnlstm_3\"\r\n",
        "    model.summary()\r\n",
        "    \r\n",
        "    return model"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWiCYABO24qC"
      },
      "source": [
        "def model_tcn(n1,n2,n3,T, perf, words, channel, filters = 24, dropout = 0):\r\n",
        "    model = None\r\n",
        "    \r\n",
        "    input_perf = Input(shape=(T,perf), \\\r\n",
        "                      dtype='float32', name='input_perf')\r\n",
        "    \r\n",
        "    input_words = Input(shape=(T,words,channel), \\\r\n",
        "                      dtype='float32', name='input_words') \r\n",
        "    \r\n",
        "    word_norm = BatchNormalization()(input_words)\r\n",
        "    padding = ZeroPadding2D(padding=((0,0),(words-1,0)))(word_norm)\r\n",
        "    \r\n",
        "    print(\"shape after padding:\", K.int_shape(padding))\r\n",
        "    \r\n",
        "    conv = Conv2D(filters = filters,\\\r\n",
        "                  kernel_size = (1,words),\\\r\n",
        "                  use_bias = False,\\\r\n",
        "                  activation = None)(padding)  # Shape None x T x words x filters\r\n",
        "    print(\"conv shape:\", K.int_shape(conv))\r\n",
        "    conv = BatchNormalization()(conv)\r\n",
        "    conv = Activation(\"relu\") (conv)\r\n",
        "    \r\n",
        "    pool = MaxPooling2D(pool_size=(1, words), \\\r\n",
        "                        strides=(1,1))(conv) # None x T x filters\r\n",
        "    pool = Reshape((T, filters))(pool)\r\n",
        "    print(\"pool shape:\", K.int_shape(pool))\r\n",
        "\r\n",
        "    #drop = Dropout(0.3)(input_all)\r\n",
        "    # Now concatenate\r\n",
        "    perf_norm = BatchNormalization()(input_perf)\r\n",
        "    all_input = Concatenate(axis = -1)([perf_norm, pool])\r\n",
        "    #all_rsp = Reshape((filters+15,))(all_input)\r\n",
        "    #nor = BatchNormalization()(all_input)\r\n",
        "    \r\n",
        "    LSTM_w_1 =Bidirectional(LSTM(n1,  recurrent_dropout = 0.2,\r\n",
        "                    name = 'layer_lstm_1', return_sequences=True,\r\n",
        "                    # kernel_regularizer = regularizers.l2(0.01),\r\n",
        "                    # activity_regularizer = regularizers.l2(0.01),\r\n",
        "                    # bias_regularizer = regularizers.l2(0.01)\r\n",
        "                    ))(all_input)\r\n",
        "    LSTM_w_2 = LSTM(n2, dropout= 0.3, recurrent_dropout = 0.3,\r\n",
        "                   name = 'layer_lstm_2', return_sequences=False)(LSTM_w_1)\r\n",
        "    \r\n",
        "    dense = Dense(n3, activation='relu', name='dense')(LSTM_w_2)\r\n",
        "    drop = Dropout(0.3)(dense)\r\n",
        "    \r\n",
        "    preds = Dense(1, activation='sigmoid', name='output')(drop)\r\n",
        "    model = Model(inputs=[input_perf, input_words], outputs=preds)\r\n",
        "    model._name = \"model_tcn\"\r\n",
        "    model.summary()\r\n",
        "    \r\n",
        "    return model\r\n",
        "    "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "744Oq8vYvbsF"
      },
      "source": [
        "def performance_measure(pred_yp, y):\r\n",
        "    '''\r\n",
        "    Given lists of predicted y probability and x, y, return a dataframe of AR, AUC, Brier, Decile Table\r\n",
        "    '''\r\n",
        "    \r\n",
        "    tenc_dat = pd.DataFrame({'y_true':y,'probability':pred_yp.flatten()})\r\n",
        "    tenc_dat.sort_values('probability',axis = 0,ascending=False, inplace = True)\r\n",
        "    tenc_dat.index = range(0,len(tenc_dat))\r\n",
        "    y = tenc_dat['y_true']\r\n",
        "    point = float(len(tenc_dat))/10\r\n",
        "    point = int(round(point))\r\n",
        "    tenc = []\r\n",
        "    for i in range(0,10):\r\n",
        "        tenc.append(y[(i*point):((i+1)*point)])\r\n",
        "    tenc[9]=tenc[9].append(y[10*point:])\r\n",
        "    total = sum(y)\r\n",
        "    num_of_bkr = []\r\n",
        "    for j in range(0,10):\r\n",
        "        num_of_bkr.append(sum(tenc[j]))\r\n",
        "    tencile_bkr = np.array(num_of_bkr)\r\n",
        "    rate = tencile_bkr.astype(float)/total\r\n",
        "\r\n",
        "    return rate"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1oy1Jcrvd1Y"
      },
      "source": [
        "class AUCEvaluation(Callback):\r\n",
        "    \"\"\" Show AUC after interval number of epoches \"\"\"\r\n",
        "    def __init__(self, validation_data=(), interval=1):\r\n",
        "        super(Callback, self).__init__()\r\n",
        "        self.interval = interval\r\n",
        "        self.X_val, self.y_val = validation_data\r\n",
        "\r\n",
        "    def on_epoch_end(self, epoch, logs={}):\r\n",
        "        if epoch % self.interval == 0:\r\n",
        "            y_pred = self.model.predict(self.X_val, verbose=0)\r\n",
        "            score = roc_auc_score(self.y_val, y_pred)\r\n",
        "            logs['auc'] = score\r\n",
        "            tencile=performance_measure(y_pred, self.y_val)\r\n",
        "            logs['tencile'] = tencile\r\n",
        "            print(\" epoch:{:d} auc: {:.4f}\".format(epoch, score))\r\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gmZEw24vv9R"
      },
      "source": [
        "def fit_model( model,x_train, y_train, x_val, y_val, x_test, y_test, model_name, verbose = 0):\r\n",
        "    \r\n",
        "    history = None\r\n",
        "    result = None\r\n",
        "    \r\n",
        "    model_df = model\r\n",
        "    print('in fit, val_y: ', sum(y_val), 'test_y',sum(y_test), 'train_y',sum(y_train))\r\n",
        "\r\n",
        "    #class weight for test \r\n",
        "    class_weights = class_weight.compute_class_weight('balanced',\r\n",
        "                              np.unique(y_train),\r\n",
        "                              y_train)\r\n",
        "    class_weights = {l:c for l,c in zip(np.unique(y_train), class_weights)}\r\n",
        "    # class weight for val\r\n",
        "    val_class_weights = class_weight.compute_class_weight('balanced',\r\n",
        "                                np.unique(y_val),\r\n",
        "                                y_val)\r\n",
        "    val_class_weights = {l:c for l,c in zip(np.unique(y_val), val_class_weights)}\r\n",
        "    val_sample_weights = []\r\n",
        "    for y in y_val:\r\n",
        "        if y == 1:\r\n",
        "          val_sample_weights.append(val_class_weights[1])\r\n",
        "        else: val_sample_weights.append(val_class_weights[0])\r\n",
        "    val_sample_weights = np.asarray(val_sample_weights)\r\n",
        "    #print('in fit val weights', val_sample_weights.shape)\r\n",
        "    \r\n",
        "    auc_eval = AUCEvaluation(validation_data=(x_val, y_val), interval=1)\r\n",
        "    # earlyStopping = EarlyStopping(monitor='val_loss',patience = 3, \r\n",
        "    #                   verbose =verbose, mode ='min')\r\n",
        "    # checkpoint = ModelCheckpoint(model_name,monitor='val_my_auc',verbose=verbose,\r\n",
        "    #           save_best_only=True, save_weights_only=True, mode ='max')\r\n",
        "\r\n",
        "    opt = optimizers.RMSprop(lr=0.0005)\r\n",
        "    model_df.compile(optimizer= opt,\r\n",
        "              loss='binary_crossentropy',\r\n",
        "              metrics=['accuracy', metrics.AUC(name='my_auc')])\r\n",
        "\r\n",
        "    history = model_df.fit(x_train,\r\n",
        "                y_train,\r\n",
        "                epochs=10,\r\n",
        "                batch_size=128,\r\n",
        "                verbose =verbose,\r\n",
        "                callbacks=[auc_eval],\\\r\n",
        "                #callbacks=[auc_eval, earlyStopping, checkpoint], #checkpoint\r\n",
        "                class_weight = class_weights, \\\r\n",
        "                validation_data=(x_val, y_val, val_sample_weights)) \r\n",
        "    \r\n",
        "    #model_df.load_weights(model_name)\r\n",
        "    y_pred = model_df.predict(x_test)\r\n",
        "    y_pred_1=np.reshape(y_pred, -1)\r\n",
        "    auc_score = roc_auc_score(y_test, y_pred_1)\r\n",
        "    #auc_score = roc_auc_score(y_test, y_pred_1)\r\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_1)\r\n",
        "    print(\"AUC: \" ,round(auc_score,4))\r\n",
        "    print([ round(h,4) for h in history.history['val_loss']])    \r\n",
        "    plt.plot(history.history['loss'])\r\n",
        "    plt.plot(history.history['val_loss'])\r\n",
        "    plt.title('loss')\r\n",
        "    plt.ylabel('loss')\r\n",
        "    plt.xlabel('epoch')\r\n",
        "    plt.legend(['train', 'val'], loc='upper left')\r\n",
        "    plt.show()\r\n",
        "\r\n",
        "        \r\n",
        "    return history, auc_score, fpr, tpr, thresholds, [y_test, y_pred_1]"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bo3ShzQyoSci"
      },
      "source": [
        "def cross_val(data, label, perf_cols, words_cols, name, w, filters = 24):\r\n",
        "    tprs = []\r\n",
        "    auc_list = []\r\n",
        "    mean_fpr = np.linspace(0,1,100)\r\n",
        "    predicted_res =[]\r\n",
        "    his_auc = []\r\n",
        "    \r\n",
        "    kf = StratifiedKFold(n_splits = 4, shuffle = True, random_state = 42)\r\n",
        "    c = 0\r\n",
        "\r\n",
        "    X_perf, X_word, Y = shift_data(df_fl, w, \\\r\n",
        "                    perf_cols, \\\r\n",
        "                    words_cols, \\\r\n",
        "                    'label')\r\n",
        "    \r\n",
        "    for train_index, test_index in kf.split(range(len(X_perf)),Y):\r\n",
        "        \r\n",
        "        c += 1\r\n",
        "        \r\n",
        "        l1 = X_perf.shape[-1]+ filters + 16\r\n",
        "        \r\n",
        "        model = model_tcn(l1,l1,32,\\\r\n",
        "                    X_perf.shape[1],\\\r\n",
        "                    X_perf.shape[2],\r\n",
        "                    X_word.shape[2], \\\r\n",
        "                    X_word.shape[3], \\\r\n",
        "                    filters = 24)\r\n",
        "    \r\n",
        "        #model = model_lstm(n1,n2,n,w)\r\n",
        "        train_x, train_val = train_test_split(train_index,test_size=0.2, \\\r\n",
        "                    random_state=42, stratify = Y[train_index])\r\n",
        "        train_perf_data = X_perf[train_x]\r\n",
        "        train_word_data = X_word[train_x]\r\n",
        "        train_perf_val = X_perf[train_val]\r\n",
        "        train_word_val = X_word[train_val]\r\n",
        "\r\n",
        "        train_label = Y[train_x]\r\n",
        "        val_label = Y[train_val]\r\n",
        "\r\n",
        "        test_perf_x = X_perf[test_index]\r\n",
        "        test_word_x = X_word[test_index]\r\n",
        "        test_y = Y[test_index] \r\n",
        "        \r\n",
        "        train_data = [train_perf_data, train_word_data]\r\n",
        "        val_data = [train_perf_val,train_word_val]\r\n",
        "        test_x = [test_perf_x, test_word_x]\r\n",
        "\r\n",
        "        mod_res = fit_model(model, train_data, train_label, val_data, val_label, test_x, test_y,\\\r\n",
        "                  name+'_'+str(c))\r\n",
        "        his_auc.append(mod_res[0].history['val_my_auc'])\r\n",
        "        \r\n",
        "        \r\n",
        "        \r\n",
        "        \r\n",
        "        auc_list.append(mod_res[1])\r\n",
        "        tprs.append(np.interp(mean_fpr, mod_res[2], mod_res[3]))\r\n",
        "        temp_pred_res = [mod_res[-1],test_index]\r\n",
        "        print(len(test_index))\r\n",
        "        predicted_res.append(temp_pred_res)\r\n",
        "        \r\n",
        "        \r\n",
        "    mean_tpr = np.mean(tprs, axis=0)\r\n",
        "    print('avg_AUC : ', np.mean(auc_list))\r\n",
        "    print('avg_AUC_2 : ', auc(mean_fpr, mean_tpr))\r\n",
        "    print(pd.DataFrame(his_auc))\r\n",
        "    print(pd.DataFrame(his_auc).mean())\r\n",
        "    \r\n",
        "    return np.average(auc_list), mean_tpr, predicted_res"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rfF_t6WWVcu"
      },
      "source": [
        "#a = np.arange(16).reshape((2,8#))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4FwTZ8JWZcJ"
      },
      "source": [
        "#a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooJMEa21WZem"
      },
      "source": [
        "#a.reshape((2,8), order = '')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3ub73u2WZhz"
      },
      "source": [
        "#a.reshape((2,4,2), order = 'C')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fSPkGEAWZjk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDLCeoltzOn6"
      },
      "source": [
        "def shift_data(data, step, perf_cols, words_cols, label):\r\n",
        "    A = []\r\n",
        "    \r\n",
        "    cols = perf_cols + words_cols\r\n",
        "    A.append(data[cols].values)\r\n",
        "    \r\n",
        "    for t in range(1, step):\r\n",
        "        d = data.groupby(\"cik\")[cols].shift(t)\r\n",
        "        A.append(d.values)\r\n",
        "    A = A[::-1]\r\n",
        "    A = np.concatenate(A, axis = 1)  # flatten shifted columns\r\n",
        "    A = np.concatenate([data[label].values[:,None], A], axis = 1)  # add target\r\n",
        "    #np.random.shuffle(A)\r\n",
        "    #print(A[3])\r\n",
        "    print('init A shape: ',A.shape)\r\n",
        "    #print(A[3,:])\r\n",
        "    #print(data[cols].iloc[4,:])\r\n",
        "\r\n",
        "\r\n",
        "    \r\n",
        "    A = A[~np.isnan(A).any(axis=1)]  # drop nan\r\n",
        "    \r\n",
        "\r\n",
        "    Y = A[:,0]  # get target\r\n",
        "    #A = np.reshape(A[:,1:], (len(A), step, len(cols))) # reshape\r\n",
        "\r\n",
        "    A = np.reshape(A[:,1:], (len(A), step, len(perf_cols) + len(words_cols)))\r\n",
        "    \r\n",
        "    A_perf = A[:, :, 0:len(perf_cols)]\r\n",
        "    # CNN_LSTM must be None x T x words x 4\r\n",
        "    A_words = A[:, :, len(perf_cols):]\r\n",
        "    #convert the shape to [[_p,_new][_dis,_n]]\r\n",
        "    A_words = A_words.reshape((len(A), step, int(len(words_cols)/2), 2), order = 'C')\r\n",
        "    \r\n",
        "    print(A_perf.shape, A_words.shape, Y.sum())\r\n",
        "    return A_perf, A_words, Y\r\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDR1cndI_xJF"
      },
      "source": [
        "#shift_perf,shit_wrd, _y = shift_data(df_fl, 3, v_perf + v_1+ v_2, selected_new_all_sorted, label='label')"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B42iqO2dZWQU"
      },
      "source": [
        "#shit_wrd[2]"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJJvwrMuANlK"
      },
      "source": [
        "# for k , fr in df_fl.groupby(\"cik\"):\r\n",
        "#   print(fr[selected_new_all_sorted])\r\n",
        "#   break"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaVhYNFbZJgE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fREeiK36ZJi7"
      },
      "source": [
        "import os, random\r\n",
        "\r\n",
        "seed_value = 43\r\n",
        "os.environ['PYTHONASHSEED'] = str(seed_value)\r\n",
        "\r\n",
        "random.seed(seed_value)\r\n",
        "\r\n",
        "from numpy.random import seed\r\n",
        "seed(seed_value)\r\n",
        "\r\n",
        "import tensorflow\r\n",
        "tensorflow.random.set_seed(seed_value)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xCGS_HCd2CiB",
        "cellView": "code",
        "outputId": "3596ef92-7e28-4c9f-b4ad-e8e8071752cc"
      },
      "source": [
        "\n",
        "print(\"\\n ======= Select columns for LSTM ALL OBS.=========\")\n",
        "\n",
        "result = []\n",
        "\n",
        "# First choose all varaibles\n",
        "#cols = v_perf + v_1+ v_2 + selected_new_all #must order like this\n",
        "w = 2\n",
        "perf_cols = v_perf + v_1\n",
        "words_cols = selected_new_all_sorted\n",
        "label = 'label'\n",
        "h = cross_val( df_fl, 'label', \\\n",
        "          perf_cols,\\\n",
        "          words_cols, \\\n",
        "          'model_tcn',w, \\\n",
        "          filters = 24)\n",
        "    \n",
        "#best_auc = h[0]\n",
        "\n",
        "# Next, remove one from the list each time\n",
        "\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " ======= Select columns for LSTM ALL OBS.=========\n",
            "init A shape:  (53635, 111)\n",
            "(45945, 2, 15) (45945, 2, 20, 2) 408.0\n",
            "shape after padding: (None, 2, 39, 2)\n",
            "conv shape: (None, 2, 20, 24)\n",
            "pool shape: (None, 2, 24)\n",
            "Model: \"model_tcn\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_words (InputLayer)        [(None, 2, 20, 2)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 2, 20, 2)     8           input_words[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_9 (ZeroPadding2D (None, 2, 39, 2)     0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 2, 20, 24)    960         zero_padding2d_9[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 2, 20, 24)    96          conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 2, 20, 24)    0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "input_perf (InputLayer)         [(None, 2, 15)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2D)  (None, 2, 1, 24)     0           activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 2, 15)        60          input_perf[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_9 (Reshape)             (None, 2, 24)        0           max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 2, 39)        0           batch_normalization_29[0][0]     \n",
            "                                                                 reshape_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_9 (Bidirectional) (None, 2, 110)       41800       concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "layer_lstm_2 (LSTM)             (None, 55)           36520       bidirectional_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 32)           1792        layer_lstm_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 32)           0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output (Dense)                  (None, 1)            33          dropout_9[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 81,269\n",
            "Trainable params: 81,187\n",
            "Non-trainable params: 82\n",
            "__________________________________________________________________________________________________\n",
            "in fit, val_y:  61.0 test_y 102.0 train_y 245.0\n",
            " epoch:0 auc: 0.6509\n",
            " epoch:1 auc: 0.6885\n",
            " epoch:2 auc: 0.7058\n",
            " epoch:3 auc: 0.7151\n",
            " epoch:4 auc: 0.7196\n",
            " epoch:5 auc: 0.7149\n",
            " epoch:6 auc: 0.7173\n",
            "AUC:  0.7331\n",
            "[0.683, 0.6478, 0.6602, 0.6325, 0.6602, 0.6554, 0.6846]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "11487\n",
            "shape after padding: (None, 2, 39, 2)\n",
            "conv shape: (None, 2, 20, 24)\n",
            "pool shape: (None, 2, 24)\n",
            "Model: \"model_tcn\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_words (InputLayer)        [(None, 2, 20, 2)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 2, 20, 2)     8           input_words[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_10 (ZeroPadding2 (None, 2, 39, 2)     0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 2, 20, 24)    960         zero_padding2d_10[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 2, 20, 24)    96          conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 2, 20, 24)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "input_perf (InputLayer)         [(None, 2, 15)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling2D) (None, 2, 1, 24)     0           activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 2, 15)        60          input_perf[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_10 (Reshape)            (None, 2, 24)        0           max_pooling2d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 2, 39)        0           batch_normalization_32[0][0]     \n",
            "                                                                 reshape_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_10 (Bidirectional (None, 2, 110)       41800       concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "layer_lstm_2 (LSTM)             (None, 55)           36520       bidirectional_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 32)           1792        layer_lstm_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 32)           0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output (Dense)                  (None, 1)            33          dropout_10[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 81,269\n",
            "Trainable params: 81,187\n",
            "Non-trainable params: 82\n",
            "__________________________________________________________________________________________________\n",
            "in fit, val_y:  61.0 test_y 102.0 train_y 245.0\n",
            " epoch:0 auc: 0.7078\n",
            " epoch:1 auc: 0.7155\n",
            " epoch:2 auc: 0.7228\n",
            " epoch:3 auc: 0.7323\n",
            " epoch:4 auc: 0.7330\n",
            " epoch:5 auc: 0.7224\n",
            " epoch:6 auc: 0.7253\n",
            " epoch:7 auc: 0.7305\n",
            "AUC:  0.7463\n",
            "[0.6716, 0.6233, 0.6147, 0.6212, 0.6126, 0.663, 0.6804, 0.676]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "11486\n",
            "shape after padding: (None, 2, 39, 2)\n",
            "conv shape: (None, 2, 20, 24)\n",
            "pool shape: (None, 2, 24)\n",
            "Model: \"model_tcn\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_words (InputLayer)        [(None, 2, 20, 2)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 2, 20, 2)     8           input_words[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_11 (ZeroPadding2 (None, 2, 39, 2)     0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 2, 20, 24)    960         zero_padding2d_11[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 2, 20, 24)    96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 2, 20, 24)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "input_perf (InputLayer)         [(None, 2, 15)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling2D) (None, 2, 1, 24)     0           activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 2, 15)        60          input_perf[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_11 (Reshape)            (None, 2, 24)        0           max_pooling2d_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 2, 39)        0           batch_normalization_35[0][0]     \n",
            "                                                                 reshape_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_11 (Bidirectional (None, 2, 110)       41800       concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "layer_lstm_2 (LSTM)             (None, 55)           36520       bidirectional_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 32)           1792        layer_lstm_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 32)           0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output (Dense)                  (None, 1)            33          dropout_11[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 81,269\n",
            "Trainable params: 81,187\n",
            "Non-trainable params: 82\n",
            "__________________________________________________________________________________________________\n",
            "in fit, val_y:  61.0 test_y 102.0 train_y 245.0\n",
            " epoch:0 auc: 0.6906\n",
            " epoch:1 auc: 0.7330\n",
            " epoch:2 auc: 0.7368\n",
            " epoch:3 auc: 0.7403\n",
            " epoch:4 auc: 0.7448\n",
            " epoch:5 auc: 0.7452\n",
            "AUC:  0.7614\n",
            "[0.6829, 0.6399, 0.611, 0.6181, 0.6134, 0.6277]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "11486\n",
            "shape after padding: (None, 2, 39, 2)\n",
            "conv shape: (None, 2, 20, 24)\n",
            "pool shape: (None, 2, 24)\n",
            "Model: \"model_tcn\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_words (InputLayer)        [(None, 2, 20, 2)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 2, 20, 2)     8           input_words[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_12 (ZeroPadding2 (None, 2, 39, 2)     0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 2, 20, 24)    960         zero_padding2d_12[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 2, 20, 24)    96          conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 2, 20, 24)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "input_perf (InputLayer)         [(None, 2, 15)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling2D) (None, 2, 1, 24)     0           activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 2, 15)        60          input_perf[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_12 (Reshape)            (None, 2, 24)        0           max_pooling2d_12[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 2, 39)        0           batch_normalization_38[0][0]     \n",
            "                                                                 reshape_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_12 (Bidirectional (None, 2, 110)       41800       concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "layer_lstm_2 (LSTM)             (None, 55)           36520       bidirectional_12[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 32)           1792        layer_lstm_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 32)           0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output (Dense)                  (None, 1)            33          dropout_12[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 81,269\n",
            "Trainable params: 81,187\n",
            "Non-trainable params: 82\n",
            "__________________________________________________________________________________________________\n",
            "in fit, val_y:  61.0 test_y 102.0 train_y 245.0\n",
            " epoch:0 auc: 0.6931\n",
            " epoch:1 auc: 0.7083\n",
            " epoch:2 auc: 0.7223\n",
            " epoch:3 auc: 0.7174\n",
            " epoch:4 auc: 0.7187\n",
            " epoch:5 auc: 0.7091\n",
            "AUC:  0.7425\n",
            "[0.6749, 0.6317, 0.6219, 0.6443, 0.6353, 0.6959]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "11486\n",
            "avg_AUC :  0.7457949077049891\n",
            "avg_AUC_2 :  0.74589027530204\n",
            "          0         1         2  ...         5         6         7\n",
            "0  0.648382  0.687197  0.705950  ...  0.715007  0.717244       NaN\n",
            "1  0.703512  0.715365  0.723121  ...  0.722418  0.725011  0.730731\n",
            "2  0.681475  0.732048  0.737037  ...  0.744848       NaN       NaN\n",
            "3  0.691323  0.708268  0.722684  ...  0.708934       NaN       NaN\n",
            "\n",
            "[4 rows x 8 columns]\n",
            "0    0.681173\n",
            "1    0.710720\n",
            "2    0.722198\n",
            "3    0.726311\n",
            "4    0.729272\n",
            "5    0.722802\n",
            "6    0.721127\n",
            "7    0.730731\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GazZJdEKg20L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cec7bcd-7629-4038-9138-fdd41f0de6a3"
      },
      "source": [
        "#best_auc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.752735165519567"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSUyWOb4BXMq"
      },
      "source": [
        "\r\n",
        "#all_cols = selected_new_all\r\n",
        "\r\n",
        "# selected_cols = selected_new_all + v_1 + v_2\r\n",
        "# random.shuffle(selected_cols)\r\n",
        "\r\n",
        "# for col in selected_cols:\r\n",
        "    \r\n",
        "#     print(\"\\n ===========Test {}============\\n\".format(col))\r\n",
        "    \r\n",
        "#     test_cols = [item for item in selected_cols if item !=col]\r\n",
        "#     #test_cols = v_perf + v_1+ v_2 + [col]\r\n",
        "    \r\n",
        "#     # n1 = 2*len(test_cols)\r\n",
        "#     # n2 = len(test_cols)\r\n",
        "#     label = 'label'\r\n",
        "#     h = cross_val( df_fl, label, test_cols + v_perf, 'lstm_wds', 2)\r\n",
        "\r\n",
        "#     gap = h[0] - best_auc\r\n",
        "#     print('****** gap: {0:.4f}'.format(gap))\r\n",
        "    \r\n",
        "#     result.append([col, h[0], best_auc, gap]) #gap\r\n",
        "    \r\n",
        "#     if h[0]>= best_auc:  # better to drop col\r\n",
        "        \r\n",
        "#         selected_cols = test_cols\r\n",
        "        \r\n",
        "#         best_auc = h[0]\r\n",
        "        \r\n",
        "#         print(\"*** {} removed ***\".format(col))\r\n",
        "    \r\n",
        "#     print(\"current auc: {0:.4f}\\tbest_auc: {1:.4f}\\tcolumn: {2}\".format(h[0], best_auc, col))\r\n",
        "#     print(\"selected columns: \", selected_cols)\r\n",
        "\r\n",
        "\r\n",
        "# pd.DataFrame(result, columns = [\"column\", \"auc\", \"prev_auc\",\"gap\"]).to_csv(\"var_selection_lstm_bi_2.csv\")   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DSUDXmCJjAM"
      },
      "source": [
        "print(random.shuffle(selected_new_all))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZtYwaE4J-zF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72c73139-ac7c-4e72-850f-22424b79fc8d"
      },
      "source": [
        "'Litigious_3_dis' in list(df_fl.columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tygu3EpmnZl7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}