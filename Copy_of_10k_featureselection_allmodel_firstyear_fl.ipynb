{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy_of_10k_featureselection_allmodel_firstyear.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "TE2BHZAjEPfc",
        "3tpLiMqNK9qj"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pepperamy/tenK_phase2/blob/main/Copy_of_10k_featureselection_allmodel_firstyear_fl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gFdXv30e4Zx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "010af5dc-b101-439d-b6c5-682b928c77f3"
      },
      "source": [
        "import pandas as pd\r\n",
        "import pickle\r\n",
        "import re\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\r\n",
        "from sklearn.metrics.pairwise import cosine_similarity\r\n",
        "\r\n",
        "from scipy.optimize import linear_sum_assignment\r\n",
        "import time\r\n",
        "\r\n",
        "from IPython.core.interactiveshell import InteractiveShell\r\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\r\n",
        "\r\n",
        "import statsmodels.api as sm\r\n",
        "import statsmodels.formula.api as smf\r\n",
        "\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')\r\n",
        "\r\n",
        "from scipy.stats import mstats\r\n",
        "import math\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPbGENVjzMx6"
      },
      "source": [
        "from sklearn.model_selection import KFold,StratifiedKFold"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovlMafoEj7fh"
      },
      "source": [
        "from keras import regularizers"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edodAjPPLihc"
      },
      "source": [
        "from keras import backend as K"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEyVpJiqfWh7"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, precision_recall_curve, classification_report,accuracy_score, auc, roc_curve, roc_auc_score, average_precision_score"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQoE_A26fcCN"
      },
      "source": [
        "from keras.models import Sequential\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "from keras.layers import Embedding, Dense, Conv2D, MaxPooling2D, Reshape, Conv1D, MaxPooling1D,\\\r\n",
        "Dropout, Activation, Input, Flatten, Concatenate, BatchNormalization, Lambda, LSTM, GRU, Bidirectional,\\\r\n",
        "ZeroPadding2D\r\n",
        "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\r\n",
        "from keras import regularizers\r\n",
        "from keras.models import Model\r\n",
        "from keras import optimizers\r\n",
        "from keras import metrics\r\n",
        "from keras import models\r\n",
        "from keras import layers"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOhMLRyIB5rG"
      },
      "source": [
        "from sklearn.utils import class_weight"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hU6Xry_KF88_"
      },
      "source": [
        "from sklearn import utils"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LTmS2gbJsCI"
      },
      "source": [
        "import random"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QGsL2oSKI0I"
      },
      "source": [
        "from sklearn.svm import LinearSVC,SVC\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\r\n",
        "#from sklearn import metrics\r\n",
        "from sklearn.model_selection import cross_validate\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dP4mF35eC3Gv"
      },
      "source": [
        "# data prepare"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGDo0BX3fdqF"
      },
      "source": [
        "df = pd.read_csv('data_performance_words_win1_03_firstyear.csv')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXrMxcpfdcof",
        "outputId": "c685f9bf-03f8-4102-ff14-475218bbd6e0"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(63305, 192)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTHf-QumI8Cd",
        "outputId": "2f2e83cd-1814-4d98-aa9f-64104f4a7632"
      },
      "source": [
        "sum(df.label)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "210.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "7uYp5m-amwON",
        "outputId": "bace551c-d402-4f65-f51b-58cf3dfa3929"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cik</th>\n",
              "      <th>y1</th>\n",
              "      <th>y2</th>\n",
              "      <th>s1</th>\n",
              "      <th>window</th>\n",
              "      <th>label</th>\n",
              "      <th>sic_class_x</th>\n",
              "      <th>rsst_acc</th>\n",
              "      <th>ch_rec</th>\n",
              "      <th>ch_inv</th>\n",
              "      <th>soft_asset</th>\n",
              "      <th>ch_cs</th>\n",
              "      <th>ch_roa</th>\n",
              "      <th>issue</th>\n",
              "      <th>aqi</th>\n",
              "      <th>asset_turnover</th>\n",
              "      <th>cfed</th>\n",
              "      <th>depi</th>\n",
              "      <th>gmi</th>\n",
              "      <th>ig</th>\n",
              "      <th>opm</th>\n",
              "      <th>rg</th>\n",
              "      <th>sg</th>\n",
              "      <th>sgee</th>\n",
              "      <th>pastavg5</th>\n",
              "      <th>pastavg3</th>\n",
              "      <th>pastavg1</th>\n",
              "      <th>cr5</th>\n",
              "      <th>cr3</th>\n",
              "      <th>cr1</th>\n",
              "      <th>WeakModal_3_avg</th>\n",
              "      <th>WeakModal_3_dis</th>\n",
              "      <th>WeakModal_3_n</th>\n",
              "      <th>WeakModal_3_new</th>\n",
              "      <th>WeakModal_3_p</th>\n",
              "      <th>WeakModal_3_u</th>\n",
              "      <th>Litigious_3_avg</th>\n",
              "      <th>Litigious_3_dis</th>\n",
              "      <th>Litigious_3_n</th>\n",
              "      <th>Litigious_3_new</th>\n",
              "      <th>...</th>\n",
              "      <th>Differ_3_n</th>\n",
              "      <th>Differ_3_new</th>\n",
              "      <th>Differ_3_p</th>\n",
              "      <th>Differ_3_u</th>\n",
              "      <th>Drives_3_avg</th>\n",
              "      <th>Drives_3_dis</th>\n",
              "      <th>Drives_3_n</th>\n",
              "      <th>Drives_3_new</th>\n",
              "      <th>Drives_3_p</th>\n",
              "      <th>Drives_3_u</th>\n",
              "      <th>Affiliation_3_avg</th>\n",
              "      <th>Affiliation_3_dis</th>\n",
              "      <th>Affiliation_3_n</th>\n",
              "      <th>Affiliation_3_new</th>\n",
              "      <th>Affiliation_3_p</th>\n",
              "      <th>Affiliation_3_u</th>\n",
              "      <th>Achieve_3_avg</th>\n",
              "      <th>Achieve_3_dis</th>\n",
              "      <th>Achieve_3_n</th>\n",
              "      <th>Achieve_3_new</th>\n",
              "      <th>Achieve_3_p</th>\n",
              "      <th>Achieve_3_u</th>\n",
              "      <th>Power_3_avg</th>\n",
              "      <th>Power_3_dis</th>\n",
              "      <th>Power_3_n</th>\n",
              "      <th>Power_3_new</th>\n",
              "      <th>Power_3_p</th>\n",
              "      <th>Power_3_u</th>\n",
              "      <th>Reward_3_avg</th>\n",
              "      <th>Reward_3_dis</th>\n",
              "      <th>Reward_3_n</th>\n",
              "      <th>Reward_3_new</th>\n",
              "      <th>Reward_3_p</th>\n",
              "      <th>Reward_3_u</th>\n",
              "      <th>Risk_3_avg</th>\n",
              "      <th>Risk_3_dis</th>\n",
              "      <th>Risk_3_n</th>\n",
              "      <th>Risk_3_new</th>\n",
              "      <th>Risk_3_p</th>\n",
              "      <th>Risk_3_u</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20.0</td>\n",
              "      <td>1995.0</td>\n",
              "      <td>1996.0</td>\n",
              "      <td>0.633505</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.063117</td>\n",
              "      <td>-0.072425</td>\n",
              "      <td>-0.067847</td>\n",
              "      <td>0.661974</td>\n",
              "      <td>-0.147079</td>\n",
              "      <td>0.198730</td>\n",
              "      <td>1</td>\n",
              "      <td>0.974056</td>\n",
              "      <td>1.624273</td>\n",
              "      <td>0.206066</td>\n",
              "      <td>1.226305</td>\n",
              "      <td>0.914198</td>\n",
              "      <td>0.715334</td>\n",
              "      <td>0.044798</td>\n",
              "      <td>0.783539</td>\n",
              "      <td>0.814093</td>\n",
              "      <td>1.013528</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.000071</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>0.004950</td>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>-0.002775</td>\n",
              "      <td>0.002801</td>\n",
              "      <td>0.190476</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.380952</td>\n",
              "      <td>0.004950</td>\n",
              "      <td>0.380952</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>-0.007085</td>\n",
              "      <td>0.051165</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.054325</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.190476</td>\n",
              "      <td>0.002484</td>\n",
              "      <td>0.017475</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>0.004950</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.523810</td>\n",
              "      <td>-0.003165</td>\n",
              "      <td>0.017510</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.013158</td>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>-0.004527</td>\n",
              "      <td>0.016180</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.029638</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.190476</td>\n",
              "      <td>-0.000009</td>\n",
              "      <td>0.002644</td>\n",
              "      <td>0.190476</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.190476</td>\n",
              "      <td>0.523810</td>\n",
              "      <td>-0.002433</td>\n",
              "      <td>0.002488</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.019737</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.0</td>\n",
              "      <td>1996.0</td>\n",
              "      <td>1997.0</td>\n",
              "      <td>0.803827</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.066126</td>\n",
              "      <td>-0.018252</td>\n",
              "      <td>-0.059281</td>\n",
              "      <td>0.620435</td>\n",
              "      <td>-0.066028</td>\n",
              "      <td>0.034753</td>\n",
              "      <td>1</td>\n",
              "      <td>1.248039</td>\n",
              "      <td>1.606518</td>\n",
              "      <td>0.025826</td>\n",
              "      <td>1.088859</td>\n",
              "      <td>0.978102</td>\n",
              "      <td>0.755016</td>\n",
              "      <td>0.062466</td>\n",
              "      <td>0.938786</td>\n",
              "      <td>0.969746</td>\n",
              "      <td>1.012432</td>\n",
              "      <td>0.633505</td>\n",
              "      <td>0.633505</td>\n",
              "      <td>0.633505</td>\n",
              "      <td>1.268856</td>\n",
              "      <td>1.268856</td>\n",
              "      <td>1.268856</td>\n",
              "      <td>-0.000034</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.028571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.866667</td>\n",
              "      <td>0.003234</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.028571</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>-0.004321</td>\n",
              "      <td>0.044777</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>-0.000118</td>\n",
              "      <td>0.004586</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.001261</td>\n",
              "      <td>0.008828</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>-0.003780</td>\n",
              "      <td>0.018289</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.000668</td>\n",
              "      <td>0.007947</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>-0.001054</td>\n",
              "      <td>0.013954</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20.0</td>\n",
              "      <td>1997.0</td>\n",
              "      <td>1998.0</td>\n",
              "      <td>0.462705</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.095900</td>\n",
              "      <td>0.066711</td>\n",
              "      <td>0.013223</td>\n",
              "      <td>0.656729</td>\n",
              "      <td>-0.030720</td>\n",
              "      <td>0.019574</td>\n",
              "      <td>1</td>\n",
              "      <td>0.840540</td>\n",
              "      <td>1.574474</td>\n",
              "      <td>0.020191</td>\n",
              "      <td>0.991780</td>\n",
              "      <td>0.991078</td>\n",
              "      <td>1.073227</td>\n",
              "      <td>0.073961</td>\n",
              "      <td>1.241132</td>\n",
              "      <td>1.022834</td>\n",
              "      <td>0.983269</td>\n",
              "      <td>0.718666</td>\n",
              "      <td>0.718666</td>\n",
              "      <td>0.803827</td>\n",
              "      <td>0.643838</td>\n",
              "      <td>0.643838</td>\n",
              "      <td>0.575627</td>\n",
              "      <td>0.002823</td>\n",
              "      <td>0.005714</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.007841</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>-0.001499</td>\n",
              "      <td>0.004000</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.004315</td>\n",
              "      <td>...</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.032995</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>-0.003528</td>\n",
              "      <td>0.048389</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.038724</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>-0.001334</td>\n",
              "      <td>0.007739</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.003683</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>-0.002187</td>\n",
              "      <td>0.011111</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.008254</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000062</td>\n",
              "      <td>0.028035</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.021889</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>-0.003310</td>\n",
              "      <td>0.001504</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.002960</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>-0.000069</td>\n",
              "      <td>0.011111</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.004688</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.533333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20.0</td>\n",
              "      <td>1998.0</td>\n",
              "      <td>1999.0</td>\n",
              "      <td>0.701689</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.054997</td>\n",
              "      <td>0.026323</td>\n",
              "      <td>-0.009875</td>\n",
              "      <td>0.676757</td>\n",
              "      <td>0.011434</td>\n",
              "      <td>0.002424</td>\n",
              "      <td>1</td>\n",
              "      <td>0.837833</td>\n",
              "      <td>1.604656</td>\n",
              "      <td>0.003715</td>\n",
              "      <td>1.025961</td>\n",
              "      <td>1.024634</td>\n",
              "      <td>0.948804</td>\n",
              "      <td>0.076906</td>\n",
              "      <td>1.077020</td>\n",
              "      <td>0.985921</td>\n",
              "      <td>0.983057</td>\n",
              "      <td>0.633346</td>\n",
              "      <td>0.633346</td>\n",
              "      <td>0.462705</td>\n",
              "      <td>1.107909</td>\n",
              "      <td>1.107909</td>\n",
              "      <td>1.516495</td>\n",
              "      <td>0.000590</td>\n",
              "      <td>0.006755</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>-0.000112</td>\n",
              "      <td>0.005460</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>0.011462</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.001771</td>\n",
              "      <td>0.051960</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.051891</td>\n",
              "      <td>0.227273</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.000279</td>\n",
              "      <td>0.003730</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.014010</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.590909</td>\n",
              "      <td>-0.000451</td>\n",
              "      <td>0.010119</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.010288</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.590909</td>\n",
              "      <td>0.001965</td>\n",
              "      <td>0.034894</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.019415</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000347</td>\n",
              "      <td>0.003575</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008179</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.681818</td>\n",
              "      <td>-0.000126</td>\n",
              "      <td>0.003620</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.545455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.0</td>\n",
              "      <td>1999.0</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>0.823023</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.024892</td>\n",
              "      <td>-0.024929</td>\n",
              "      <td>0.041267</td>\n",
              "      <td>0.705573</td>\n",
              "      <td>-0.001713</td>\n",
              "      <td>-0.014429</td>\n",
              "      <td>1</td>\n",
              "      <td>1.093648</td>\n",
              "      <td>1.560280</td>\n",
              "      <td>-0.015406</td>\n",
              "      <td>0.942174</td>\n",
              "      <td>0.995699</td>\n",
              "      <td>1.221034</td>\n",
              "      <td>0.068754</td>\n",
              "      <td>0.933610</td>\n",
              "      <td>0.966150</td>\n",
              "      <td>1.000184</td>\n",
              "      <td>0.650432</td>\n",
              "      <td>0.656074</td>\n",
              "      <td>0.701689</td>\n",
              "      <td>1.265350</td>\n",
              "      <td>1.254468</td>\n",
              "      <td>1.172917</td>\n",
              "      <td>-0.000791</td>\n",
              "      <td>0.002083</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.764706</td>\n",
              "      <td>-0.000278</td>\n",
              "      <td>0.003717</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.411765</td>\n",
              "      <td>0.030122</td>\n",
              "      <td>0.041638</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.076087</td>\n",
              "      <td>0.764706</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.030707</td>\n",
              "      <td>0.012943</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010870</td>\n",
              "      <td>0.823529</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>0.000766</td>\n",
              "      <td>0.011356</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>-0.001826</td>\n",
              "      <td>0.011784</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>0.054348</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.764706</td>\n",
              "      <td>0.001092</td>\n",
              "      <td>0.007639</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.764706</td>\n",
              "      <td>-0.000721</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.010870</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.764706</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 192 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    cik      y1      y2        s1  ...  Risk_3_n  Risk_3_new  Risk_3_p  Risk_3_u\n",
              "0  20.0  1995.0  1996.0  0.633505  ...  0.333333    0.019737  0.000000  0.571429\n",
              "1  20.0  1996.0  1997.0  0.803827  ...  0.066667    0.000000  0.066667  0.800000\n",
              "2  20.0  1997.0  1998.0  0.462705  ...  0.066667    0.004688  0.066667  0.533333\n",
              "3  20.0  1998.0  1999.0  0.701689  ...  0.090909    0.000000  0.090909  0.545455\n",
              "4  20.0  1999.0  2000.0  0.823023  ...  0.176471    0.010870  0.000000  0.764706\n",
              "\n",
              "[5 rows x 192 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFPQxWfzmxA5"
      },
      "source": [
        "df_fl = df[(df.y2 <= 2012) & (df.y2 >= 1995 ) ]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHk9KoNgdKnU",
        "outputId": "cabd86aa-56cb-4503-d410-6137fa0f45cb"
      },
      "source": [
        "df_fl.label.value_counts()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    52192\n",
              "1.0      210\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htklHIW9JDXK",
        "outputId": "beb17c13-8919-4e70-bc62-51adb9848b62"
      },
      "source": [
        "df_fl.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(52402, 192)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czKM_c73sGzE"
      },
      "source": [
        "selected_new = ['WeakModal','Negative', 'Compare', 'Discrep','Positive',\\\r\n",
        "         'Achieve',  'Reward', 'StrongModal','Uncertainty', 'Litigious']\r\n",
        "\r\n",
        "v_perf = ['aqi',\r\n",
        " 'asset_turnover',\r\n",
        " 'depi',\r\n",
        " 'gmi',\r\n",
        " #'ig',\r\n",
        " 'opm',\r\n",
        " 'rg',\r\n",
        " 'sg',\r\n",
        " 'sgee',\r\n",
        " 'ch_rec',\r\n",
        " 'ch_inv',\r\n",
        " 'soft_asset',\r\n",
        " 'ch_cs',\r\n",
        " 'ch_roa',\r\n",
        " 'issue']\r\n",
        "\r\n",
        "v_1 = ['s1']\r\n",
        "v_2 = ['pastavg3','cr3']"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqB8Sa2NDeFF"
      },
      "source": [
        "# selected_comb = []\r\n",
        "# for s in selected_new:\r\n",
        "#   selected_comb.append(s+'_up')\r\n",
        "#   selected_comb.append(s+'_down')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u09YX6QTsRjF"
      },
      "source": [
        "selected_new_all = []\r\n",
        "temp = []\r\n",
        "for s in selected_new:\r\n",
        "    wrd = s.split('_')[0]\r\n",
        "    if wrd not in temp:\r\n",
        "        #print(s,'\\n',temp)\r\n",
        "        #selected_new_all.append(wrd+'_3_avg')\r\n",
        "        selected_new_all.append(wrd+'_3_p')\r\n",
        "        selected_new_all.append(wrd+'_3_n')\r\n",
        "        #selected_new_all.append(wrd+'_3_u')\r\n",
        "        selected_new_all.append(wrd+'_3_new')\r\n",
        "        selected_new_all.append(wrd+'_3_dis')\r\n",
        "        temp.append(wrd)\r\n",
        "    else: \r\n",
        "        pass"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08oZ_gShupro"
      },
      "source": [
        "selected_new_all"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLPx7-Q37_ft"
      },
      "source": [
        "selected_new_all_sorted = []\r\n",
        "selected_new_all_p = []\r\n",
        "selected_new_all_n = []\r\n",
        "selected_new_all_new = []\r\n",
        "selected_new_all_dis = []\r\n",
        "for s in selected_new_all:\r\n",
        "  if 'new' in s.split('_'):\r\n",
        "    selected_new_all_new.append(s)\r\n",
        "  elif 'p' in s.split('_'):\r\n",
        "    selected_new_all_p.append(s)\r\n",
        "  elif 'n' in s.split('_'):\r\n",
        "    selected_new_all_n.append(s)\r\n",
        "  elif 'dis' in s.split('_'):\r\n",
        "    selected_new_all_dis.append(s)\r\n",
        "\r\n",
        "for i, w in enumerate(selected_new_all_p):\r\n",
        "  selected_new_all_sorted.append(selected_new_all_p[i])\r\n",
        "  selected_new_all_sorted.append(selected_new_all_new[i])\r\n",
        "  selected_new_all_sorted.append(selected_new_all_n[i])\r\n",
        "  \r\n",
        "  selected_new_all_sorted.append(selected_new_all_dis[i])  \r\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uuAH4EArW1P"
      },
      "source": [
        "selected_new_all_sorted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_jHGUWwCi3M"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TE2BHZAjEPfc"
      },
      "source": [
        "# SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWbZ3_n5Ci5x"
      },
      "source": [
        "def svm( data, vs, label = 'label'):\r\n",
        "    \r\n",
        "    columns_fl = vs[1] #+ [ 'sic_class_x']\r\n",
        "    \r\n",
        "    data_target = data.loc[:,columns_fl + [label]]\r\n",
        "    \r\n",
        "    tprs = []\r\n",
        "    auc_list = []\r\n",
        "    mean_fpr = np.linspace(0,1,100)\r\n",
        "    \r\n",
        "    class_report = []\r\n",
        "    sum_pred_list = []\r\n",
        "\r\n",
        "    kf = StratifiedKFold(n_splits = 4, shuffle = True)\r\n",
        "    c = 0\r\n",
        "    data_target = data[columns_fl + [label]]\r\n",
        "    data_target = data_target.dropna()\r\n",
        "    data_target = data_target.reset_index(drop = True)\r\n",
        "    print('dataset: ', data_target.shape, '/n', sum(data_target.label))\r\n",
        "     \r\n",
        "    for train_index, test_index in kf.split(data_target[columns_fl],data_target[label]):\r\n",
        "        \r\n",
        "        c += 1\r\n",
        "\r\n",
        "        train_x = data_target.loc[train_index,columns_fl]\r\n",
        "        train_y = data_target.loc[train_index,label]\r\n",
        "        test_x = data_target.loc[test_index,columns_fl]\r\n",
        "        test_y = data_target.loc[test_index,label] \r\n",
        "\r\n",
        "        print('iterate_num: ', c, '\\n','sum of test_y:', sum(test_y))\r\n",
        "    \r\n",
        "        svm = LinearSVC(class_weight = \"balanced\")\r\n",
        "        svm.fit(train_x, train_y )\r\n",
        "        pickle.dump(svm, open('svm_'+str(vs[0])+ '_'+str(c), 'wb'))\r\n",
        "        \r\n",
        "\r\n",
        "        pred = svm.predict(test_x)\r\n",
        "        sum_pred_list.append(pred)\r\n",
        "        print('sum of pred: ', sum(pred), '\\n')\r\n",
        "        # c_r = metrics.classification_report(test_y, pred, labels=[0,1], output_dict = True)\r\n",
        "        # class_report.append(c_r)\r\n",
        "        #print(metrics.classification_report(test_y, pred, labels=[0,1]))\r\n",
        "        \r\n",
        "        decision_values = svm.decision_function(test_x)\r\n",
        "        auc_score = roc_auc_score(test_y, decision_values)\r\n",
        "        print(auc_score)\r\n",
        "        auc_list.append(auc_score)\r\n",
        "        \r\n",
        "        fpr, tpr, thresholds = roc_curve(test_y, decision_values)\r\n",
        "        tprs.append(np.interp(mean_fpr, fpr, tpr))\r\n",
        "        \r\n",
        "#         mean_tpr = np.mean(tprs, axis=0)\r\n",
        "#         mean_auc = auc(mean_fpr, mean_tpr)\r\n",
        "        \r\n",
        "        \r\n",
        "    mean_tpr = np.mean(tprs, axis=0)\r\n",
        "    print('avg_AUC : ', np.mean(auc_list))\r\n",
        "    print('avg_AUC_2 : ', auc(mean_fpr, mean_tpr))\r\n",
        "    frauds_prec = []\r\n",
        "    fradus_recall = []\r\n",
        "    for d in class_report:\r\n",
        "        frauds_prec.append(d['1']['precision'])\r\n",
        "        fradus_recall.append(d['1']['recall'])\r\n",
        "    \r\n",
        "#     coef_s = 0\r\n",
        "#     for i in coef:\r\n",
        "#         coef_s += abs(i)\r\n",
        "#     coef_avg = coef_s / len(coef)\r\n",
        "#     coef_top = pd.DataFrame(coef_avg, index = columns_fl,columns = ['importance'])\r\n",
        "#     coef_top = coef_top.sort_values('importance',ascending=False)\r\n",
        "#     print(coef_top.iloc[0:10,:])\r\n",
        "        \r\n",
        "    print('frauds_prec : ', np.mean(frauds_prec))\r\n",
        "    print('fradus_recall : ', np.mean(fradus_recall))\r\n",
        "    print('\\n')\r\n",
        "    return np.mean(auc_list),mean_tpr"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrLJFpcI9rJR",
        "outputId": "5af55882-f49d-49dd-9c26-4c75c5c36ebe"
      },
      "source": [
        "vs_fl = {'perf':v_perf, 'perf+spc': v_perf +v_1, 'wrd+spc': selected_new_all +v_1,'perf+spc+wrd': v_perf +v_1 +selected_new_all}\r\n",
        "mean_tpr_dict_svm = dict()\r\n",
        "for fl in vs_fl.items():\r\n",
        "#    print(fl)\r\n",
        "    svm_model = svm( df_fl, fl,label = 'label')\r\n",
        "    print(fl)\r\n",
        "    print(svm_model[0])\r\n",
        "    mean_tpr_dict_svm[fl[0]] = svm_model[1]\r\n",
        "    print('============================')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataset:  (52402, 15) /n 210.0\n",
            "iterate_num:  1 \n",
            " sum of test_y: 53.0\n",
            "sum of pred:  653.0 \n",
            "\n",
            "0.703489582730817\n",
            "iterate_num:  2 \n",
            " sum of test_y: 53.0\n",
            "sum of pred:  819.0 \n",
            "\n",
            "0.6698069826359567\n",
            "iterate_num:  3 \n",
            " sum of test_y: 52.0\n",
            "sum of pred:  595.0 \n",
            "\n",
            "0.7312438098382303\n",
            "iterate_num:  4 \n",
            " sum of test_y: 52.0\n",
            "sum of pred:  659.0 \n",
            "\n",
            "0.7216623237277744\n",
            "avg_AUC :  0.7065506747331947\n",
            "avg_AUC_2 :  0.7062011625690872\n",
            "frauds_prec :  nan\n",
            "fradus_recall :  nan\n",
            "\n",
            "\n",
            "('perf', ['aqi', 'asset_turnover', 'depi', 'gmi', 'opm', 'rg', 'sg', 'sgee', 'ch_rec', 'ch_inv', 'soft_asset', 'ch_cs', 'ch_roa', 'issue'])\n",
            "0.7065506747331947\n",
            "============================\n",
            "dataset:  (52402, 16) /n 210.0\n",
            "iterate_num:  1 \n",
            " sum of test_y: 53.0\n",
            "sum of pred:  634.0 \n",
            "\n",
            "0.7075254792175191\n",
            "iterate_num:  2 \n",
            " sum of test_y: 53.0\n",
            "sum of pred:  724.0 \n",
            "\n",
            "0.7108745069005009\n",
            "iterate_num:  3 \n",
            " sum of test_y: 52.0\n",
            "sum of pred:  444.0 \n",
            "\n",
            "0.7379306583973966\n",
            "iterate_num:  4 \n",
            " sum of test_y: 52.0\n",
            "sum of pred:  760.0 \n",
            "\n",
            "0.672922169032684\n",
            "avg_AUC :  0.7073132033870252\n",
            "avg_AUC_2 :  0.7072438829514301\n",
            "frauds_prec :  nan\n",
            "fradus_recall :  nan\n",
            "\n",
            "\n",
            "('perf+spc', ['aqi', 'asset_turnover', 'depi', 'gmi', 'opm', 'rg', 'sg', 'sgee', 'ch_rec', 'ch_inv', 'soft_asset', 'ch_cs', 'ch_roa', 'issue', 's1'])\n",
            "0.7073132033870252\n",
            "============================\n",
            "dataset:  (52402, 42) /n 210.0\n",
            "iterate_num:  1 \n",
            " sum of test_y: 53.0\n",
            "sum of pred:  4257.0 \n",
            "\n",
            "0.539696678736277\n",
            "iterate_num:  2 \n",
            " sum of test_y: 53.0\n",
            "sum of pred:  4243.0 \n",
            "\n",
            "0.5907780271392709\n",
            "iterate_num:  3 \n",
            " sum of test_y: 52.0\n",
            "sum of pred:  4437.0 \n",
            "\n",
            "0.6177914092345423\n",
            "iterate_num:  4 \n",
            " sum of test_y: 52.0\n",
            "sum of pred:  4187.0 \n",
            "\n",
            "0.5909393717870113\n",
            "avg_AUC :  0.5848013717242753\n",
            "avg_AUC_2 :  0.584841521162276\n",
            "frauds_prec :  nan\n",
            "fradus_recall :  nan\n",
            "\n",
            "\n",
            "('wrd+spc', ['WeakModal_3_p', 'WeakModal_3_n', 'WeakModal_3_new', 'WeakModal_3_dis', 'Negative_3_p', 'Negative_3_n', 'Negative_3_new', 'Negative_3_dis', 'Compare_3_p', 'Compare_3_n', 'Compare_3_new', 'Compare_3_dis', 'Discrep_3_p', 'Discrep_3_n', 'Discrep_3_new', 'Discrep_3_dis', 'Positive_3_p', 'Positive_3_n', 'Positive_3_new', 'Positive_3_dis', 'Achieve_3_p', 'Achieve_3_n', 'Achieve_3_new', 'Achieve_3_dis', 'Reward_3_p', 'Reward_3_n', 'Reward_3_new', 'Reward_3_dis', 'StrongModal_3_p', 'StrongModal_3_n', 'StrongModal_3_new', 'StrongModal_3_dis', 'Uncertainty_3_p', 'Uncertainty_3_n', 'Uncertainty_3_new', 'Uncertainty_3_dis', 'Litigious_3_p', 'Litigious_3_n', 'Litigious_3_new', 'Litigious_3_dis', 's1'])\n",
            "0.5848013717242753\n",
            "============================\n",
            "dataset:  (52402, 56) /n 210.0\n",
            "iterate_num:  1 \n",
            " sum of test_y: 53.0\n",
            "sum of pred:  785.0 \n",
            "\n",
            "0.7568614578392698\n",
            "iterate_num:  2 \n",
            " sum of test_y: 53.0\n",
            "sum of pred:  952.0 \n",
            "\n",
            "0.705346297560242\n",
            "iterate_num:  3 \n",
            " sum of test_y: 52.0\n",
            "sum of pred:  867.0 \n",
            "\n",
            "0.6985612295429892\n",
            "iterate_num:  4 \n",
            " sum of test_y: 52.0\n",
            "sum of pred:  1115.0 \n",
            "\n",
            "0.6345240060368816\n",
            "avg_AUC :  0.6988232477448456\n",
            "avg_AUC_2 :  0.6990194030288369\n",
            "frauds_prec :  nan\n",
            "fradus_recall :  nan\n",
            "\n",
            "\n",
            "('perf+spc+wrd', ['aqi', 'asset_turnover', 'depi', 'gmi', 'opm', 'rg', 'sg', 'sgee', 'ch_rec', 'ch_inv', 'soft_asset', 'ch_cs', 'ch_roa', 'issue', 's1', 'WeakModal_3_p', 'WeakModal_3_n', 'WeakModal_3_new', 'WeakModal_3_dis', 'Negative_3_p', 'Negative_3_n', 'Negative_3_new', 'Negative_3_dis', 'Compare_3_p', 'Compare_3_n', 'Compare_3_new', 'Compare_3_dis', 'Discrep_3_p', 'Discrep_3_n', 'Discrep_3_new', 'Discrep_3_dis', 'Positive_3_p', 'Positive_3_n', 'Positive_3_new', 'Positive_3_dis', 'Achieve_3_p', 'Achieve_3_n', 'Achieve_3_new', 'Achieve_3_dis', 'Reward_3_p', 'Reward_3_n', 'Reward_3_new', 'Reward_3_dis', 'StrongModal_3_p', 'StrongModal_3_n', 'StrongModal_3_new', 'StrongModal_3_dis', 'Uncertainty_3_p', 'Uncertainty_3_n', 'Uncertainty_3_new', 'Uncertainty_3_dis', 'Litigious_3_p', 'Litigious_3_n', 'Litigious_3_new', 'Litigious_3_dis'])\n",
            "0.6988232477448456\n",
            "============================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAx--SZdCi8A"
      },
      "source": [
        "vs_fl = {'perf':v_perf, 'perf+spc': v_perf +v_1+v_2, 'wrd+spc': selected_new_all +v_1 +v_2,'perf+spc+wrd': v_perf +v_1 +v_2 +selected_new_all}\r\n",
        "mean_tpr_dict_svm = dict()\r\n",
        "for fl in vs_fl.items():\r\n",
        "#    print(fl)\r\n",
        "    svm_model = svm( df_fl, fl,label = 'label')\r\n",
        "    print(fl)\r\n",
        "    print(svm_model[0])\r\n",
        "    mean_tpr_dict_svm[fl[0]] = svm_model[1]\r\n",
        "    print('============================')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zESDM53TKweY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHiIenY9K8Lf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tpLiMqNK9qj"
      },
      "source": [
        "# LR\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q86DE7q6K8OH"
      },
      "source": [
        "def lg( data,vs, label = 'label'):\r\n",
        "    \r\n",
        "    \r\n",
        "    columns_fl = vs[1]# + [ 'sic_class_x']\r\n",
        "    data_target = data.loc[:,columns_fl + [label]]\r\n",
        "    \r\n",
        "        \r\n",
        "#     train_x, test_x, train_y, test_y = train_test_split(data_x, data_y,test_size=0.2, random_state=19, \r\n",
        "#                                                                         stratify = data_y) \r\n",
        "\r\n",
        "    tprs = []\r\n",
        "    auc_list = []\r\n",
        "    mean_fpr = np.linspace(0,1,100)\r\n",
        "    \r\n",
        "    class_report = []\r\n",
        "    sum_pred_list = []\r\n",
        "    kf = StratifiedKFold(n_splits = 4, shuffle = True)\r\n",
        "    c = 0\r\n",
        "    data_target = data[columns_fl + [label]]\r\n",
        "    data_target = data_target.dropna()\r\n",
        "    data_target = data_target.reset_index(drop = True)\r\n",
        "    for train_index, test_index in kf.split(data_target[columns_fl],data_target[label]):\r\n",
        "        \r\n",
        "        c += 1\r\n",
        "\r\n",
        "        train_x = data_target.loc[train_index,columns_fl]\r\n",
        "        train_y = data_target.loc[train_index,label]\r\n",
        "        test_x = data_target.loc[test_index,columns_fl]\r\n",
        "        test_y = data_target.loc[test_index,label] \r\n",
        "\r\n",
        "        print('iterate_num: ', c, '\\n','sum of test_y:', sum(test_y))\r\n",
        "    \r\n",
        "        lg = LogisticRegression(class_weight = 'balanced')\r\n",
        "        lg.fit(train_x, train_y )\r\n",
        "        #pickle.dump(lg, open('lg_'+str(vs[0])+ '_'+str(c), 'wb'))\r\n",
        "\r\n",
        "        pred = lg.predict(test_x)\r\n",
        "        sum_pred_list.append(pred)\r\n",
        "        print('sum of pred: ', sum(pred), '\\n')\r\n",
        "        # c_r = metrics.classification_report(test_y, pred, labels=[0,1], output_dict = True)\r\n",
        "        # class_report.append(c_r)\r\n",
        "        #print(metrics.classification_report(test_y, pred, labels=[0,1]))\r\n",
        "        \r\n",
        "        decision_values = lg.predict_proba(test_x)\r\n",
        "        auc_score = roc_auc_score(test_y, decision_values[:,1])\r\n",
        "        print(auc_score)\r\n",
        "        auc_list.append(auc_score)\r\n",
        "        fpr, tpr, thresholds = roc_curve(test_y, decision_values[:,1])\r\n",
        "        tprs.append(np.interp(mean_fpr, fpr, tpr))\r\n",
        "        \r\n",
        "        #print('AUC',auc_score)\r\n",
        "        \r\n",
        "    mean_tpr = np.mean(tprs, axis=0)\r\n",
        "    print('avg_AUC : ', np.mean(auc_list))\r\n",
        "    print('avg_AUC_2 : ', auc(mean_fpr, mean_tpr))\r\n",
        "    frauds_prec = []\r\n",
        "    fradus_recall = []\r\n",
        "    for d in class_report:\r\n",
        "        frauds_prec.append(d['1']['precision'])\r\n",
        "        fradus_recall.append(d['1']['recall'])\r\n",
        "        \r\n",
        "    print('frauds_prec : ', np.mean(frauds_prec))\r\n",
        "    print('fradus_recall : ', np.mean(fradus_recall))\r\n",
        "    print('\\n')\r\n",
        "    return np.mean(auc_list),mean_tpr"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgQ54FUiLAJt",
        "outputId": "b0ac1439-bb59-4139-ff70-fb566b972b87"
      },
      "source": [
        "#@title Default title text\n",
        "vs_fl = {'perf':v_perf, 'perf+spc': v_perf +v_1, 'wrd+spc': selected_new_all +v_1,'perf+spc+wrd': v_perf+v_1+selected_new_all}\n",
        "mean_tpr_dict_lg = dict()\n",
        "for fl in vs_fl.items():\n",
        "    lg_model = lg( df_fl, fl,label = 'label')\n",
        "    print(fl)\n",
        "    print(lg_model[0])\n",
        "    mean_tpr_dict_lg[fl[0]] = lg_model[1]\n",
        "    print('============================')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iterate_num:  1 \n",
            " sum of test_y: 53.0\n",
            "sum of pred:  4473.0 \n",
            "\n",
            "0.7118679360966187\n",
            "iterate_num:  2 \n",
            " sum of test_y: 53.0\n",
            "sum of pred:  4514.0 \n",
            "\n",
            "0.7510816376109113\n",
            "iterate_num:  3 \n",
            " sum of test_y: 52.0\n",
            "sum of pred:  4394.0 \n",
            "\n",
            "0.70360031599302\n",
            "iterate_num:  4 \n",
            " sum of test_y: 52.0\n",
            "sum of pred:  4235.0 \n",
            "\n",
            "0.6486139933028345\n",
            "avg_AUC :  0.7037909707508461\n",
            "avg_AUC_2 :  0.7038215976895222\n",
            "frauds_prec :  nan\n",
            "fradus_recall :  nan\n",
            "\n",
            "\n",
            "('perf', ['aqi', 'asset_turnover', 'depi', 'gmi', 'opm', 'rg', 'sg', 'sgee', 'ch_rec', 'ch_inv', 'soft_asset', 'ch_cs', 'ch_roa', 'issue'])\n",
            "0.7037909707508461\n",
            "============================\n",
            "iterate_num:  1 \n",
            " sum of test_y: 53.0\n",
            "sum of pred:  4302.0 \n",
            "\n",
            "0.7011686891940353\n",
            "iterate_num:  2 \n",
            " sum of test_y: 53.0\n",
            "sum of pred:  4073.0 \n",
            "\n",
            "0.7119257776800897\n",
            "iterate_num:  3 \n",
            " sum of test_y: 52.0\n",
            "sum of pred:  4270.0 \n",
            "\n",
            "0.7020380370702259\n",
            "iterate_num:  4 \n",
            " sum of test_y: 52.0\n",
            "sum of pred:  4144.0 \n",
            "\n",
            "0.720982879781163\n",
            "avg_AUC :  0.7090288459313785\n",
            "avg_AUC_2 :  0.7088730190145284\n",
            "frauds_prec :  nan\n",
            "fradus_recall :  nan\n",
            "\n",
            "\n",
            "('perf+spc', ['aqi', 'asset_turnover', 'depi', 'gmi', 'opm', 'rg', 'sg', 'sgee', 'ch_rec', 'ch_inv', 'soft_asset', 'ch_cs', 'ch_roa', 'issue', 's1'])\n",
            "0.7090288459313785\n",
            "============================\n",
            "iterate_num:  1 \n",
            " sum of test_y: 53.0\n",
            "sum of pred:  4594.0 \n",
            "\n",
            "0.5636792452830189\n",
            "iterate_num:  2 \n",
            " sum of test_y: 53.0\n",
            "sum of pred:  4514.0 \n",
            "\n",
            "0.5677165878093078\n",
            "iterate_num:  3 \n",
            " sum of test_y: 52.0\n",
            "sum of pred:  4925.0 \n",
            "\n",
            "0.6352211361599774\n",
            "iterate_num:  4 \n",
            " sum of test_y: 52.0\n",
            "sum of pred:  4667.0 \n",
            "\n",
            "0.596906982502476\n",
            "avg_AUC :  0.590880987938695\n",
            "avg_AUC_2 :  0.5910520297312749\n",
            "frauds_prec :  nan\n",
            "fradus_recall :  nan\n",
            "\n",
            "\n",
            "('wrd+spc', ['WeakModal_3_p', 'WeakModal_3_n', 'WeakModal_3_new', 'WeakModal_3_dis', 'Negative_3_p', 'Negative_3_n', 'Negative_3_new', 'Negative_3_dis', 'Compare_3_p', 'Compare_3_n', 'Compare_3_new', 'Compare_3_dis', 'Discrep_3_p', 'Discrep_3_n', 'Discrep_3_new', 'Discrep_3_dis', 'Positive_3_p', 'Positive_3_n', 'Positive_3_new', 'Positive_3_dis', 'Achieve_3_p', 'Achieve_3_n', 'Achieve_3_new', 'Achieve_3_dis', 'Reward_3_p', 'Reward_3_n', 'Reward_3_new', 'Reward_3_dis', 'StrongModal_3_p', 'StrongModal_3_n', 'StrongModal_3_new', 'StrongModal_3_dis', 'Uncertainty_3_p', 'Uncertainty_3_n', 'Uncertainty_3_new', 'Uncertainty_3_dis', 'Litigious_3_p', 'Litigious_3_n', 'Litigious_3_new', 'Litigious_3_dis', 's1'])\n",
            "0.590880987938695\n",
            "============================\n",
            "iterate_num:  1 \n",
            " sum of test_y: 53.0\n",
            "sum of pred:  3784.0 \n",
            "\n",
            "0.7146313177469547\n",
            "iterate_num:  2 \n",
            " sum of test_y: 53.0\n",
            "sum of pred:  3810.0 \n",
            "\n",
            "0.7024600025450297\n",
            "iterate_num:  3 \n",
            " sum of test_y: 52.0\n",
            "sum of pred:  3994.0 \n",
            "\n",
            "0.6937446941470546\n",
            "iterate_num:  4 \n",
            " sum of test_y: 52.0\n",
            "sum of pred:  3987.0 \n",
            "\n",
            "0.6878655143140121\n",
            "avg_AUC :  0.6996753821882629\n",
            "avg_AUC_2 :  0.7000135608626175\n",
            "frauds_prec :  nan\n",
            "fradus_recall :  nan\n",
            "\n",
            "\n",
            "('perf+spc+wrd', ['aqi', 'asset_turnover', 'depi', 'gmi', 'opm', 'rg', 'sg', 'sgee', 'ch_rec', 'ch_inv', 'soft_asset', 'ch_cs', 'ch_roa', 'issue', 's1', 'WeakModal_3_p', 'WeakModal_3_n', 'WeakModal_3_new', 'WeakModal_3_dis', 'Negative_3_p', 'Negative_3_n', 'Negative_3_new', 'Negative_3_dis', 'Compare_3_p', 'Compare_3_n', 'Compare_3_new', 'Compare_3_dis', 'Discrep_3_p', 'Discrep_3_n', 'Discrep_3_new', 'Discrep_3_dis', 'Positive_3_p', 'Positive_3_n', 'Positive_3_new', 'Positive_3_dis', 'Achieve_3_p', 'Achieve_3_n', 'Achieve_3_new', 'Achieve_3_dis', 'Reward_3_p', 'Reward_3_n', 'Reward_3_new', 'Reward_3_dis', 'StrongModal_3_p', 'StrongModal_3_n', 'StrongModal_3_new', 'StrongModal_3_dis', 'Uncertainty_3_p', 'Uncertainty_3_n', 'Uncertainty_3_new', 'Uncertainty_3_dis', 'Litigious_3_p', 'Litigious_3_n', 'Litigious_3_new', 'Litigious_3_dis'])\n",
            "0.6996753821882629\n",
            "============================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdVMNLDaLAMR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_R7MWNdnMexr"
      },
      "source": [
        "# NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZ9W1cJrNOuu"
      },
      "source": [
        "def model_M1(n1,n2):\r\n",
        "    model_m1 = Sequential(name = 'M1')\r\n",
        "    model_m1.add(BatchNormalization())\r\n",
        "    model_m1.add(layers.Dense(n1,name = 'layer_1',activation='relu'))\r\n",
        "    model_m1.add(layers.Dropout(0.3))\r\n",
        "    #model_m1.add(layers.Dense(64,name = 'layer_2'))\r\n",
        "    model_m1.add(layers.Dense(n2,name = 'layer_2',activation='relu'))\r\n",
        "    model_m1.add(layers.Dense(1,activation='sigmoid'))\r\n",
        "    #model_m1.summary()\r\n",
        "    return model_m1"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mapP-xQTNTMv"
      },
      "source": [
        "def performance_measure(pred_yp, y):\r\n",
        "    '''\r\n",
        "    Given lists of predicted y probability and x, y, return a dataframe of AR, AUC, Brier, Decile Table\r\n",
        "    '''\r\n",
        "    \r\n",
        "    tenc_dat = pd.DataFrame({'y_true':y,'probability':pred_yp.flatten()})\r\n",
        "    tenc_dat.sort_values('probability',axis = 0,ascending=False, inplace = True)\r\n",
        "    tenc_dat.index = range(0,len(tenc_dat))\r\n",
        "    y = tenc_dat['y_true']\r\n",
        "    point = float(len(tenc_dat))/10\r\n",
        "    point = int(round(point))\r\n",
        "    tenc = []\r\n",
        "    for i in range(0,10):\r\n",
        "        tenc.append(y[(i*point):((i+1)*point)])\r\n",
        "    tenc[9]=tenc[9].append(y[10*point:])\r\n",
        "    total = sum(y)\r\n",
        "    num_of_bkr = []\r\n",
        "    for j in range(0,10):\r\n",
        "        num_of_bkr.append(sum(tenc[j]))\r\n",
        "    tencile_bkr = np.array(num_of_bkr)\r\n",
        "    rate = tencile_bkr.astype(float)/total\r\n",
        "\r\n",
        "    return rate"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGDx2QzbNZcD"
      },
      "source": [
        "class AUCEvaluation(Callback):\r\n",
        "    \"\"\" Show AUC after interval number of epoches \"\"\"\r\n",
        "    def __init__(self, validation_data=(), interval=1):\r\n",
        "        super(Callback, self).__init__()\r\n",
        "        self.interval = interval\r\n",
        "        self.X_val, self.y_val = validation_data\r\n",
        "\r\n",
        "    def on_epoch_end(self, epoch, logs={}):\r\n",
        "        if epoch % self.interval == 0:\r\n",
        "            y_pred = self.model.predict(self.X_val, verbose=0)\r\n",
        "            score = roc_auc_score(self.y_val, y_pred)\r\n",
        "            logs['auc'] = score\r\n",
        "            tencile=performance_measure(y_pred, self.y_val)\r\n",
        "            logs['tencile'] = tencile\r\n",
        "            print(\" epoch:{:d} auc: {:.4f}\".format(epoch, score))"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XNsDIM5NdG0"
      },
      "source": [
        "def fit_model( model,x_train, y_train, x_val, y_val, x_test, y_test, model_name, verbose = 0):\r\n",
        "    \r\n",
        "    history = None\r\n",
        "    result = None\r\n",
        "    \r\n",
        "    model_df = model\r\n",
        "    \r\n",
        "    #class weight for test \r\n",
        "    class_weights = class_weight.compute_class_weight('balanced',\r\n",
        "                              np.unique(y_train),\r\n",
        "                              y_train)\r\n",
        "    class_weights = {l:c for l,c in zip(np.unique(y_train), class_weights)}\r\n",
        "    # class weight for val\r\n",
        "    val_class_weights = class_weight.compute_class_weight('balanced',\r\n",
        "                                np.unique(y_val),\r\n",
        "                                y_val)\r\n",
        "    val_class_weights = {l:c for l,c in zip(np.unique(y_val), val_class_weights)}\r\n",
        "    val_sample_weights = []\r\n",
        "    for y in y_val:\r\n",
        "        if y == 1:\r\n",
        "          val_sample_weights.append(val_class_weights[1])\r\n",
        "        else: val_sample_weights.append(val_class_weights[0])\r\n",
        "    val_sample_weights = np.asarray(val_sample_weights)\r\n",
        "    \r\n",
        "    \r\n",
        "    auc_eval = AUCEvaluation(validation_data=(x_val, y_val), interval=1)\r\n",
        "    earlyStopping = EarlyStopping(monitor='val_my_auc',patience = 3, \r\n",
        "                      verbose =verbose, mode ='max')\r\n",
        "    checkpoint = ModelCheckpoint(model_name,monitor='val_my_auc',verbose=verbose,\r\n",
        "              save_best_only=True, save_weights_only=True, mode ='max')\r\n",
        "\r\n",
        "    opt = optimizers.RMSprop(lr=0.0005)\r\n",
        "    model_df.compile(optimizer= opt,\r\n",
        "              loss='binary_crossentropy',\r\n",
        "              metrics=['accuracy', metrics.AUC(name='my_auc')])\r\n",
        "    \r\n",
        "    history = model_df.fit(x_train,\r\n",
        "                y_train,\r\n",
        "                epochs=30,\r\n",
        "                batch_size=512,\r\n",
        "                callbacks=[auc_eval, earlyStopping,checkpoint], #checkpoint\r\n",
        "                class_weight = class_weights, \\\r\n",
        "                validation_data=(x_val,y_val,val_sample_weights)) \r\n",
        "    model_df.load_weights(model_name)\r\n",
        "    y_pred = model_df.predict(x_test)\r\n",
        "    y_pred_1=np.reshape(y_pred, -1)\r\n",
        "    auc_score = roc_auc_score(y_test, y_pred_1)\r\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_1)\r\n",
        "    print(\"AUC: \" ,round(auc_score,4))\r\n",
        "        \r\n",
        "    return history, auc_score, fpr, tpr, thresholds, [y_test, y_pred_1]"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjXb2Su8OHwC"
      },
      "source": [
        "def cross_val(n1, n2, data,label,columns_fl,model_name):\r\n",
        "    tprs = []\r\n",
        "    auc_list = []\r\n",
        "    mean_fpr = np.linspace(0,1,100)\r\n",
        "    \r\n",
        "    kf = StratifiedKFold(n_splits = 4, shuffle = True)\r\n",
        "    c = 0\r\n",
        "    data_1 = data[columns_fl + [label]]\r\n",
        "    data_1 = data_1.dropna()\r\n",
        "    data_target = data_1.reset_index(drop = True)\r\n",
        "    \r\n",
        "    predicted_res =[]\r\n",
        "    print('dataset: ', data_target.shape, '/n', sum(data_target.label))\r\n",
        "    \r\n",
        "    \r\n",
        "    for train_index, test_index in kf.split(data_target[columns_fl],data_target[label]):\r\n",
        "        \r\n",
        "        c += 1\r\n",
        "\r\n",
        "        train_data = data_target.loc[train_index,columns_fl]\r\n",
        "        train_label = data_target.loc[train_index,label]\r\n",
        "        test_x = data_target.loc[test_index,columns_fl].to_numpy()\r\n",
        "        test_y = data_target.loc[test_index,label] \r\n",
        "\r\n",
        "        print('iterate_num: ', c, '\\n','sum of test_y:', sum(test_y))\r\n",
        "        train_x, val_x, train_y, val_y = train_test_split(train_data.to_numpy(), train_label.to_numpy(),test_size=0.2, \\\r\n",
        "                                                            random_state=42, stratify = train_label)\r\n",
        "        print('train_x_shape',train_x.shape)\r\n",
        "        model = model_M1(n1,n2)\r\n",
        "        mod_res = fit_model(model, train_x, train_y, val_x, val_y, test_x, test_y, model_name+'_'+str(c)+'_NN_model')\r\n",
        "        auc_list.append(mod_res[1])\r\n",
        "        tprs.append(np.interp(mean_fpr, mod_res[2], mod_res[3]))\r\n",
        "#         print(type(mod_res[-1]))\r\n",
        "#         print(len(mod_res[-1]))\r\n",
        "#         print(mod_res[-1])\r\n",
        "        temp_pred_res = [mod_res[-1],test_index]\r\n",
        "        #print(temp_pred_res)\r\n",
        "        predicted_res.append(temp_pred_res)\r\n",
        "        \r\n",
        "    mean_tpr = np.mean(tprs, axis=0)\r\n",
        "    print('avg_AUC : ', np.mean(auc_list))\r\n",
        "    print('avg_AUC_2 : ', auc(mean_fpr, mean_tpr))\r\n",
        "    \r\n",
        "    return np.mean(auc_list),mean_tpr, predicted_res"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dC6UwbsmOMOO",
        "outputId": "a9976558-10ca-4d7f-8b2a-fea78080a5dd"
      },
      "source": [
        "label = 'label'\r\n",
        "vs_fl = {'perf':v_perf, 'perf+spc': v_perf +v_1, 'wrd+spc': selected_new_all +v_1 ,'perf+spc+wrd': v_perf +v_1 +selected_new_all}\r\n",
        "#\r\n",
        "mean_tpr_dict_nn = dict()\r\n",
        "pred_res_nn = dict()\r\n",
        "for fl in vs_fl.items():\r\n",
        "    print(fl[1])\r\n",
        "    n1 = len(fl[1])*2\r\n",
        "    n2 = len(fl[1])\r\n",
        "    #M1 = model_M1(n1,n2)\r\n",
        "    NN = cross_val(n1, n2, df_fl, label, fl[1], fl[0])\r\n",
        "    print(fl)\r\n",
        "    print(NN[0])\r\n",
        "    mean_tpr_dict_nn[fl[0]] = NN[1]\r\n",
        "    pred_res_nn[fl[0]] = NN[2]"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['aqi', 'asset_turnover', 'depi', 'gmi', 'opm', 'rg', 'sg', 'sgee', 'ch_rec', 'ch_inv', 'soft_asset', 'ch_cs', 'ch_roa', 'issue']\n",
            "dataset:  (45213, 15) /n 179.0\n",
            "iterate_num:  1 \n",
            " sum of test_y: 45.0\n",
            "train_x_shape (27127, 14)\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 24ms/step - loss: 0.7354 - accuracy: 0.2818 - my_auc: 0.4466 - val_loss: 0.7080 - val_accuracy: 0.7889 - val_my_auc: 0.4424\n",
            " epoch:0 auc: 0.4449\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.7142 - accuracy: 0.4367 - my_auc: 0.5826 - val_loss: 0.7086 - val_accuracy: 0.6971 - val_my_auc: 0.4541\n",
            " epoch:1 auc: 0.4545\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.7226 - accuracy: 0.5690 - my_auc: 0.5726 - val_loss: 0.7037 - val_accuracy: 0.6124 - val_my_auc: 0.4952\n",
            " epoch:2 auc: 0.4957\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.5971 - accuracy: 0.6538 - my_auc: 0.6408 - val_loss: 0.6995 - val_accuracy: 0.6243 - val_my_auc: 0.5284\n",
            " epoch:3 auc: 0.5258\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6545 - accuracy: 0.6717 - my_auc: 0.6680 - val_loss: 0.6978 - val_accuracy: 0.6430 - val_my_auc: 0.5423\n",
            " epoch:4 auc: 0.5421\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6765 - accuracy: 0.6774 - my_auc: 0.6746 - val_loss: 0.6988 - val_accuracy: 0.6651 - val_my_auc: 0.5476\n",
            " epoch:5 auc: 0.5466\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6362 - accuracy: 0.6815 - my_auc: 0.7002 - val_loss: 0.6987 - val_accuracy: 0.6797 - val_my_auc: 0.5528\n",
            " epoch:6 auc: 0.5534\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6637 - accuracy: 0.6867 - my_auc: 0.6478 - val_loss: 0.7012 - val_accuracy: 0.6942 - val_my_auc: 0.5586\n",
            " epoch:7 auc: 0.5586\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6225 - accuracy: 0.6919 - my_auc: 0.6981 - val_loss: 0.6995 - val_accuracy: 0.7047 - val_my_auc: 0.5676\n",
            " epoch:8 auc: 0.5686\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6114 - accuracy: 0.7012 - my_auc: 0.7167 - val_loss: 0.6976 - val_accuracy: 0.7097 - val_my_auc: 0.5777\n",
            " epoch:9 auc: 0.5784\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.5956 - accuracy: 0.6948 - my_auc: 0.6788 - val_loss: 0.6968 - val_accuracy: 0.6973 - val_my_auc: 0.5858\n",
            " epoch:10 auc: 0.5849\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 0.6576 - accuracy: 0.6749 - my_auc: 0.6943 - val_loss: 0.6980 - val_accuracy: 0.7107 - val_my_auc: 0.5912\n",
            " epoch:11 auc: 0.5923\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6236 - accuracy: 0.6914 - my_auc: 0.7145 - val_loss: 0.6951 - val_accuracy: 0.7144 - val_my_auc: 0.6008\n",
            " epoch:12 auc: 0.6012\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.7025 - accuracy: 0.6895 - my_auc: 0.6999 - val_loss: 0.6929 - val_accuracy: 0.7175 - val_my_auc: 0.6059\n",
            " epoch:13 auc: 0.6065\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6508 - accuracy: 0.6932 - my_auc: 0.7379 - val_loss: 0.6894 - val_accuracy: 0.7153 - val_my_auc: 0.6124\n",
            " epoch:14 auc: 0.6118\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.5754 - accuracy: 0.6960 - my_auc: 0.7653 - val_loss: 0.6899 - val_accuracy: 0.7184 - val_my_auc: 0.6132\n",
            " epoch:15 auc: 0.6139\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.5936 - accuracy: 0.7034 - my_auc: 0.7039 - val_loss: 0.6888 - val_accuracy: 0.7154 - val_my_auc: 0.6187\n",
            " epoch:16 auc: 0.6187\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.5958 - accuracy: 0.6910 - my_auc: 0.7655 - val_loss: 0.6888 - val_accuracy: 0.7145 - val_my_auc: 0.6198\n",
            " epoch:17 auc: 0.6201\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6576 - accuracy: 0.6926 - my_auc: 0.7127 - val_loss: 0.6903 - val_accuracy: 0.7203 - val_my_auc: 0.6220\n",
            " epoch:18 auc: 0.6220\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 0.5768 - accuracy: 0.7004 - my_auc: 0.7408 - val_loss: 0.6868 - val_accuracy: 0.7157 - val_my_auc: 0.6283\n",
            " epoch:19 auc: 0.6282\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.5634 - accuracy: 0.6994 - my_auc: 0.7968 - val_loss: 0.6870 - val_accuracy: 0.7191 - val_my_auc: 0.6317\n",
            " epoch:20 auc: 0.6321\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.5872 - accuracy: 0.7028 - my_auc: 0.7103 - val_loss: 0.6871 - val_accuracy: 0.7225 - val_my_auc: 0.6329\n",
            " epoch:21 auc: 0.6332\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6388 - accuracy: 0.6958 - my_auc: 0.7126 - val_loss: 0.6858 - val_accuracy: 0.7137 - val_my_auc: 0.6345\n",
            " epoch:22 auc: 0.6340\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6182 - accuracy: 0.6962 - my_auc: 0.7314 - val_loss: 0.6843 - val_accuracy: 0.7159 - val_my_auc: 0.6355\n",
            " epoch:23 auc: 0.6360\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.5490 - accuracy: 0.7095 - my_auc: 0.7406 - val_loss: 0.6831 - val_accuracy: 0.7200 - val_my_auc: 0.6391\n",
            " epoch:24 auc: 0.6390\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.5598 - accuracy: 0.7047 - my_auc: 0.8027 - val_loss: 0.6837 - val_accuracy: 0.7235 - val_my_auc: 0.6393\n",
            " epoch:25 auc: 0.6390\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6768 - accuracy: 0.6980 - my_auc: 0.7527 - val_loss: 0.6860 - val_accuracy: 0.7383 - val_my_auc: 0.6399\n",
            " epoch:26 auc: 0.6401\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.5709 - accuracy: 0.7273 - my_auc: 0.7535 - val_loss: 0.6850 - val_accuracy: 0.7297 - val_my_auc: 0.6414\n",
            " epoch:27 auc: 0.6416\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6197 - accuracy: 0.7149 - my_auc: 0.7067 - val_loss: 0.6820 - val_accuracy: 0.7169 - val_my_auc: 0.6424\n",
            " epoch:28 auc: 0.6425\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.5494 - accuracy: 0.7096 - my_auc: 0.7602 - val_loss: 0.6847 - val_accuracy: 0.7243 - val_my_auc: 0.6405\n",
            " epoch:29 auc: 0.6409\n",
            "AUC:  0.661\n",
            "iterate_num:  2 \n",
            " sum of test_y: 44.0\n",
            "train_x_shape (27128, 14)\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 24ms/step - loss: 0.7366 - accuracy: 0.6556 - my_auc: 0.6069 - val_loss: 0.6874 - val_accuracy: 0.2586 - val_my_auc: 0.5989\n",
            " epoch:0 auc: 0.5984\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6046 - accuracy: 0.6993 - my_auc: 0.6216 - val_loss: 0.6816 - val_accuracy: 0.3391 - val_my_auc: 0.6449\n",
            " epoch:1 auc: 0.6447\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6687 - accuracy: 0.6872 - my_auc: 0.6845 - val_loss: 0.6762 - val_accuracy: 0.4477 - val_my_auc: 0.6373\n",
            " epoch:2 auc: 0.6413\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6310 - accuracy: 0.7139 - my_auc: 0.6524 - val_loss: 0.6704 - val_accuracy: 0.5466 - val_my_auc: 0.6475\n",
            " epoch:3 auc: 0.6465\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6597 - accuracy: 0.7063 - my_auc: 0.6795 - val_loss: 0.6638 - val_accuracy: 0.6098 - val_my_auc: 0.6523\n",
            " epoch:4 auc: 0.6530\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6294 - accuracy: 0.7150 - my_auc: 0.7172 - val_loss: 0.6551 - val_accuracy: 0.6436 - val_my_auc: 0.6671\n",
            " epoch:5 auc: 0.6667\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6047 - accuracy: 0.7146 - my_auc: 0.6915 - val_loss: 0.6483 - val_accuracy: 0.6566 - val_my_auc: 0.6760\n",
            " epoch:6 auc: 0.6760\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6224 - accuracy: 0.7127 - my_auc: 0.6669 - val_loss: 0.6428 - val_accuracy: 0.6651 - val_my_auc: 0.6833\n",
            " epoch:7 auc: 0.6832\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6057 - accuracy: 0.7077 - my_auc: 0.6833 - val_loss: 0.6378 - val_accuracy: 0.6634 - val_my_auc: 0.6873\n",
            " epoch:8 auc: 0.6874\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.5885 - accuracy: 0.7036 - my_auc: 0.7186 - val_loss: 0.6329 - val_accuracy: 0.6560 - val_my_auc: 0.6928\n",
            " epoch:9 auc: 0.6925\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6204 - accuracy: 0.6954 - my_auc: 0.7391 - val_loss: 0.6284 - val_accuracy: 0.6554 - val_my_auc: 0.6983\n",
            " epoch:10 auc: 0.6985\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.5916 - accuracy: 0.6965 - my_auc: 0.7490 - val_loss: 0.6243 - val_accuracy: 0.6653 - val_my_auc: 0.7045\n",
            " epoch:11 auc: 0.7034\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6336 - accuracy: 0.6932 - my_auc: 0.7211 - val_loss: 0.6196 - val_accuracy: 0.6671 - val_my_auc: 0.7077\n",
            " epoch:12 auc: 0.7081\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6781 - accuracy: 0.6883 - my_auc: 0.7004 - val_loss: 0.6161 - val_accuracy: 0.6616 - val_my_auc: 0.7111\n",
            " epoch:13 auc: 0.7114\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6152 - accuracy: 0.6859 - my_auc: 0.7337 - val_loss: 0.6125 - val_accuracy: 0.6578 - val_my_auc: 0.7149\n",
            " epoch:14 auc: 0.7147\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.5971 - accuracy: 0.6857 - my_auc: 0.7080 - val_loss: 0.6100 - val_accuracy: 0.6591 - val_my_auc: 0.7171\n",
            " epoch:15 auc: 0.7175\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.5424 - accuracy: 0.6950 - my_auc: 0.7445 - val_loss: 0.6084 - val_accuracy: 0.6486 - val_my_auc: 0.7183\n",
            " epoch:16 auc: 0.7181\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6208 - accuracy: 0.6734 - my_auc: 0.7108 - val_loss: 0.6064 - val_accuracy: 0.6393 - val_my_auc: 0.7198\n",
            " epoch:17 auc: 0.7196\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6420 - accuracy: 0.6609 - my_auc: 0.6913 - val_loss: 0.6026 - val_accuracy: 0.6370 - val_my_auc: 0.7237\n",
            " epoch:18 auc: 0.7228\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.5627 - accuracy: 0.6652 - my_auc: 0.7535 - val_loss: 0.6013 - val_accuracy: 0.6473 - val_my_auc: 0.7252\n",
            " epoch:19 auc: 0.7247\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6114 - accuracy: 0.6726 - my_auc: 0.7515 - val_loss: 0.6000 - val_accuracy: 0.6390 - val_my_auc: 0.7262\n",
            " epoch:20 auc: 0.7261\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6075 - accuracy: 0.6616 - my_auc: 0.6738 - val_loss: 0.5989 - val_accuracy: 0.6395 - val_my_auc: 0.7260\n",
            " epoch:21 auc: 0.7258\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6045 - accuracy: 0.6608 - my_auc: 0.6889 - val_loss: 0.5988 - val_accuracy: 0.6324 - val_my_auc: 0.7252\n",
            " epoch:22 auc: 0.7256\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6265 - accuracy: 0.6564 - my_auc: 0.7297 - val_loss: 0.5976 - val_accuracy: 0.6277 - val_my_auc: 0.7266\n",
            " epoch:23 auc: 0.7264\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.5879 - accuracy: 0.6588 - my_auc: 0.7409 - val_loss: 0.5974 - val_accuracy: 0.6262 - val_my_auc: 0.7254\n",
            " epoch:24 auc: 0.7258\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6213 - accuracy: 0.6474 - my_auc: 0.6871 - val_loss: 0.5973 - val_accuracy: 0.6250 - val_my_auc: 0.7255\n",
            " epoch:25 auc: 0.7257\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6025 - accuracy: 0.6502 - my_auc: 0.7091 - val_loss: 0.5967 - val_accuracy: 0.6258 - val_my_auc: 0.7244\n",
            " epoch:26 auc: 0.7240\n",
            "AUC:  0.6799\n",
            "iterate_num:  3 \n",
            " sum of test_y: 45.0\n",
            "train_x_shape (27128, 14)\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 23ms/step - loss: 0.7298 - accuracy: 0.2761 - my_auc: 0.5482 - val_loss: 0.6868 - val_accuracy: 0.3396 - val_my_auc: 0.5626\n",
            " epoch:0 auc: 0.5596\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.7017 - accuracy: 0.4134 - my_auc: 0.5832 - val_loss: 0.6854 - val_accuracy: 0.4572 - val_my_auc: 0.5767\n",
            " epoch:1 auc: 0.5780\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.7310 - accuracy: 0.4983 - my_auc: 0.5997 - val_loss: 0.6819 - val_accuracy: 0.5751 - val_my_auc: 0.5954\n",
            " epoch:2 auc: 0.5988\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6795 - accuracy: 0.5844 - my_auc: 0.6014 - val_loss: 0.6785 - val_accuracy: 0.6261 - val_my_auc: 0.6084\n",
            " epoch:3 auc: 0.6098\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6821 - accuracy: 0.6131 - my_auc: 0.6400 - val_loss: 0.6737 - val_accuracy: 0.6591 - val_my_auc: 0.6221\n",
            " epoch:4 auc: 0.6212\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6141 - accuracy: 0.6438 - my_auc: 0.6606 - val_loss: 0.6702 - val_accuracy: 0.6763 - val_my_auc: 0.6305\n",
            " epoch:5 auc: 0.6308\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6467 - accuracy: 0.6529 - my_auc: 0.6301 - val_loss: 0.6679 - val_accuracy: 0.6967 - val_my_auc: 0.6382\n",
            " epoch:6 auc: 0.6380\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6405 - accuracy: 0.6687 - my_auc: 0.6806 - val_loss: 0.6648 - val_accuracy: 0.6846 - val_my_auc: 0.6437\n",
            " epoch:7 auc: 0.6440\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6834 - accuracy: 0.6552 - my_auc: 0.6682 - val_loss: 0.6653 - val_accuracy: 0.7027 - val_my_auc: 0.6496\n",
            " epoch:8 auc: 0.6495\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6447 - accuracy: 0.6650 - my_auc: 0.6974 - val_loss: 0.6632 - val_accuracy: 0.6842 - val_my_auc: 0.6557\n",
            " epoch:9 auc: 0.6553\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6589 - accuracy: 0.6572 - my_auc: 0.6806 - val_loss: 0.6611 - val_accuracy: 0.6775 - val_my_auc: 0.6607\n",
            " epoch:10 auc: 0.6611\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 0.6365 - accuracy: 0.6487 - my_auc: 0.7158 - val_loss: 0.6620 - val_accuracy: 0.6775 - val_my_auc: 0.6598\n",
            " epoch:11 auc: 0.6599\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.5771 - accuracy: 0.6673 - my_auc: 0.7401 - val_loss: 0.6623 - val_accuracy: 0.6746 - val_my_auc: 0.6582\n",
            " epoch:12 auc: 0.6594\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6168 - accuracy: 0.6629 - my_auc: 0.6735 - val_loss: 0.6619 - val_accuracy: 0.6651 - val_my_auc: 0.6604\n",
            " epoch:13 auc: 0.6596\n",
            "AUC:  0.7041\n",
            "iterate_num:  4 \n",
            " sum of test_y: 45.0\n",
            "train_x_shape (27128, 14)\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 23ms/step - loss: 0.6814 - accuracy: 0.5017 - my_auc: 0.5675 - val_loss: 0.7032 - val_accuracy: 0.0587 - val_my_auc: 0.5596\n",
            " epoch:0 auc: 0.5613\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6671 - accuracy: 0.5696 - my_auc: 0.6112 - val_loss: 0.6918 - val_accuracy: 0.1685 - val_my_auc: 0.5560\n",
            " epoch:1 auc: 0.5547\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6045 - accuracy: 0.6009 - my_auc: 0.6146 - val_loss: 0.6893 - val_accuracy: 0.2931 - val_my_auc: 0.5287\n",
            " epoch:2 auc: 0.5289\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6664 - accuracy: 0.6006 - my_auc: 0.6765 - val_loss: 0.6842 - val_accuracy: 0.4301 - val_my_auc: 0.5488\n",
            " epoch:3 auc: 0.5463\n",
            "AUC:  0.579\n",
            "avg_AUC :  0.6560063678299805\n",
            "avg_AUC_2 :  0.6559081981430466\n",
            "('perf', ['aqi', 'asset_turnover', 'depi', 'gmi', 'opm', 'rg', 'sg', 'sgee', 'ch_rec', 'ch_inv', 'soft_asset', 'ch_cs', 'ch_roa', 'issue'])\n",
            "0.6560063678299805\n",
            "['aqi', 'asset_turnover', 'depi', 'gmi', 'opm', 'rg', 'sg', 'sgee', 'ch_rec', 'ch_inv', 'soft_asset', 'ch_cs', 'ch_roa', 'issue', 's1']\n",
            "dataset:  (45213, 16) /n 179.0\n",
            "iterate_num:  1 \n",
            " sum of test_y: 45.0\n",
            "train_x_shape (27127, 15)\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 4s 24ms/step - loss: 0.7434 - accuracy: 0.3507 - my_auc: 0.4625 - val_loss: 0.6924 - val_accuracy: 0.8406 - val_my_auc: 0.5461\n",
            " epoch:0 auc: 0.5418\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6880 - accuracy: 0.4914 - my_auc: 0.5725 - val_loss: 0.6836 - val_accuracy: 0.7598 - val_my_auc: 0.6137\n",
            " epoch:1 auc: 0.6141\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 0.6741 - accuracy: 0.5874 - my_auc: 0.6258 - val_loss: 0.6737 - val_accuracy: 0.7032 - val_my_auc: 0.6718\n",
            " epoch:2 auc: 0.6755\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.7404 - accuracy: 0.6187 - my_auc: 0.5697 - val_loss: 0.6643 - val_accuracy: 0.6989 - val_my_auc: 0.7120\n",
            " epoch:3 auc: 0.7116\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 0.6498 - accuracy: 0.6769 - my_auc: 0.6268 - val_loss: 0.6556 - val_accuracy: 0.6865 - val_my_auc: 0.7288\n",
            " epoch:4 auc: 0.7289\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6176 - accuracy: 0.7088 - my_auc: 0.6576 - val_loss: 0.6480 - val_accuracy: 0.7123 - val_my_auc: 0.7357\n",
            " epoch:5 auc: 0.7369\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6578 - accuracy: 0.7072 - my_auc: 0.6197 - val_loss: 0.6419 - val_accuracy: 0.7253 - val_my_auc: 0.7386\n",
            " epoch:6 auc: 0.7391\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6528 - accuracy: 0.7089 - my_auc: 0.7006 - val_loss: 0.6376 - val_accuracy: 0.7569 - val_my_auc: 0.7427\n",
            " epoch:7 auc: 0.7449\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6001 - accuracy: 0.7410 - my_auc: 0.6373 - val_loss: 0.6297 - val_accuracy: 0.7281 - val_my_auc: 0.7480\n",
            " epoch:8 auc: 0.7481\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6490 - accuracy: 0.7030 - my_auc: 0.7052 - val_loss: 0.6235 - val_accuracy: 0.7203 - val_my_auc: 0.7512\n",
            " epoch:9 auc: 0.7503\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6130 - accuracy: 0.7071 - my_auc: 0.7272 - val_loss: 0.6212 - val_accuracy: 0.7340 - val_my_auc: 0.7487\n",
            " epoch:10 auc: 0.7484\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 0.6205 - accuracy: 0.7145 - my_auc: 0.6290 - val_loss: 0.6160 - val_accuracy: 0.7252 - val_my_auc: 0.7516\n",
            " epoch:11 auc: 0.7511\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6811 - accuracy: 0.6986 - my_auc: 0.6866 - val_loss: 0.6115 - val_accuracy: 0.7188 - val_my_auc: 0.7522\n",
            " epoch:12 auc: 0.7520\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6178 - accuracy: 0.7091 - my_auc: 0.6963 - val_loss: 0.6092 - val_accuracy: 0.7272 - val_my_auc: 0.7521\n",
            " epoch:13 auc: 0.7528\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.5617 - accuracy: 0.7276 - my_auc: 0.7630 - val_loss: 0.6066 - val_accuracy: 0.7204 - val_my_auc: 0.7534\n",
            " epoch:14 auc: 0.7536\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6105 - accuracy: 0.7093 - my_auc: 0.7070 - val_loss: 0.6066 - val_accuracy: 0.7193 - val_my_auc: 0.7505\n",
            " epoch:15 auc: 0.7505\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6385 - accuracy: 0.7014 - my_auc: 0.7150 - val_loss: 0.6038 - val_accuracy: 0.7055 - val_my_auc: 0.7506\n",
            " epoch:16 auc: 0.7504\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6186 - accuracy: 0.6982 - my_auc: 0.7190 - val_loss: 0.6033 - val_accuracy: 0.6971 - val_my_auc: 0.7495\n",
            " epoch:17 auc: 0.7492\n",
            "AUC:  0.6686\n",
            "iterate_num:  2 \n",
            " sum of test_y: 44.0\n",
            "train_x_shape (27128, 15)\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 24ms/step - loss: 0.7265 - accuracy: 0.3833 - my_auc: 0.5094 - val_loss: 0.6923 - val_accuracy: 0.8297 - val_my_auc: 0.5488\n",
            " epoch:0 auc: 0.5542\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 0.6548 - accuracy: 0.5774 - my_auc: 0.5248 - val_loss: 0.6801 - val_accuracy: 0.7443 - val_my_auc: 0.6244\n",
            " epoch:1 auc: 0.6262\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6246 - accuracy: 0.6547 - my_auc: 0.6037 - val_loss: 0.6726 - val_accuracy: 0.6865 - val_my_auc: 0.6330\n",
            " epoch:2 auc: 0.6314\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6360 - accuracy: 0.6757 - my_auc: 0.6710 - val_loss: 0.6645 - val_accuracy: 0.6859 - val_my_auc: 0.6461\n",
            " epoch:3 auc: 0.6462\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.7065 - accuracy: 0.6666 - my_auc: 0.6859 - val_loss: 0.6593 - val_accuracy: 0.7193 - val_my_auc: 0.6503\n",
            " epoch:4 auc: 0.6502\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6392 - accuracy: 0.7080 - my_auc: 0.6907 - val_loss: 0.6491 - val_accuracy: 0.7336 - val_my_auc: 0.6713\n",
            " epoch:5 auc: 0.6711\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.5964 - accuracy: 0.7201 - my_auc: 0.7484 - val_loss: 0.6418 - val_accuracy: 0.7328 - val_my_auc: 0.6811\n",
            " epoch:6 auc: 0.6809\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6494 - accuracy: 0.7139 - my_auc: 0.7006 - val_loss: 0.6364 - val_accuracy: 0.7269 - val_my_auc: 0.6867\n",
            " epoch:7 auc: 0.6879\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6342 - accuracy: 0.6975 - my_auc: 0.6974 - val_loss: 0.6328 - val_accuracy: 0.7281 - val_my_auc: 0.6924\n",
            " epoch:8 auc: 0.6932\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.5817 - accuracy: 0.7088 - my_auc: 0.7395 - val_loss: 0.6284 - val_accuracy: 0.7200 - val_my_auc: 0.6997\n",
            " epoch:9 auc: 0.6995\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 0.6858 - accuracy: 0.6910 - my_auc: 0.6919 - val_loss: 0.6243 - val_accuracy: 0.7201 - val_my_auc: 0.7067\n",
            " epoch:10 auc: 0.7061\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6050 - accuracy: 0.7022 - my_auc: 0.7440 - val_loss: 0.6199 - val_accuracy: 0.7165 - val_my_auc: 0.7124\n",
            " epoch:11 auc: 0.7123\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6807 - accuracy: 0.6841 - my_auc: 0.6960 - val_loss: 0.6192 - val_accuracy: 0.7246 - val_my_auc: 0.7147\n",
            " epoch:12 auc: 0.7148\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 0.6213 - accuracy: 0.7065 - my_auc: 0.6920 - val_loss: 0.6178 - val_accuracy: 0.7240 - val_my_auc: 0.7180\n",
            " epoch:13 auc: 0.7172\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6691 - accuracy: 0.6958 - my_auc: 0.6934 - val_loss: 0.6167 - val_accuracy: 0.7157 - val_my_auc: 0.7189\n",
            " epoch:14 auc: 0.7187\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.5803 - accuracy: 0.6977 - my_auc: 0.7612 - val_loss: 0.6210 - val_accuracy: 0.7327 - val_my_auc: 0.7167\n",
            " epoch:15 auc: 0.7172\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 0.6088 - accuracy: 0.7139 - my_auc: 0.7522 - val_loss: 0.6196 - val_accuracy: 0.7291 - val_my_auc: 0.7193\n",
            " epoch:16 auc: 0.7188\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.5605 - accuracy: 0.7066 - my_auc: 0.7290 - val_loss: 0.6171 - val_accuracy: 0.7219 - val_my_auc: 0.7204\n",
            " epoch:17 auc: 0.7203\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6248 - accuracy: 0.6928 - my_auc: 0.7647 - val_loss: 0.6158 - val_accuracy: 0.7181 - val_my_auc: 0.7212\n",
            " epoch:18 auc: 0.7209\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.5810 - accuracy: 0.6976 - my_auc: 0.7234 - val_loss: 0.6162 - val_accuracy: 0.7216 - val_my_auc: 0.7206\n",
            " epoch:19 auc: 0.7208\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.5896 - accuracy: 0.6988 - my_auc: 0.7656 - val_loss: 0.6142 - val_accuracy: 0.7160 - val_my_auc: 0.7209\n",
            " epoch:20 auc: 0.7218\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.5246 - accuracy: 0.7075 - my_auc: 0.7540 - val_loss: 0.6130 - val_accuracy: 0.7111 - val_my_auc: 0.7236\n",
            " epoch:21 auc: 0.7235\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6032 - accuracy: 0.6905 - my_auc: 0.7734 - val_loss: 0.6142 - val_accuracy: 0.7235 - val_my_auc: 0.7235\n",
            " epoch:22 auc: 0.7237\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6178 - accuracy: 0.7027 - my_auc: 0.7426 - val_loss: 0.6115 - val_accuracy: 0.7145 - val_my_auc: 0.7256\n",
            " epoch:23 auc: 0.7256\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 0.6221 - accuracy: 0.6893 - my_auc: 0.7285 - val_loss: 0.6128 - val_accuracy: 0.7196 - val_my_auc: 0.7259\n",
            " epoch:24 auc: 0.7257\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.5752 - accuracy: 0.6996 - my_auc: 0.7858 - val_loss: 0.6112 - val_accuracy: 0.7184 - val_my_auc: 0.7262\n",
            " epoch:25 auc: 0.7268\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6020 - accuracy: 0.6977 - my_auc: 0.7455 - val_loss: 0.6094 - val_accuracy: 0.7128 - val_my_auc: 0.7289\n",
            " epoch:26 auc: 0.7276\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6056 - accuracy: 0.6918 - my_auc: 0.7085 - val_loss: 0.6098 - val_accuracy: 0.7142 - val_my_auc: 0.7274\n",
            " epoch:27 auc: 0.7275\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 0.5357 - accuracy: 0.7037 - my_auc: 0.7922 - val_loss: 0.6085 - val_accuracy: 0.7151 - val_my_auc: 0.7286\n",
            " epoch:28 auc: 0.7287\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6204 - accuracy: 0.6940 - my_auc: 0.7308 - val_loss: 0.6089 - val_accuracy: 0.7254 - val_my_auc: 0.7300\n",
            " epoch:29 auc: 0.7301\n",
            "AUC:  0.6715\n",
            "iterate_num:  3 \n",
            " sum of test_y: 45.0\n",
            "train_x_shape (27128, 15)\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 24ms/step - loss: 0.7074 - accuracy: 0.6133 - my_auc: 0.5977 - val_loss: 0.6992 - val_accuracy: 0.9317 - val_my_auc: 0.5528\n",
            " epoch:0 auc: 0.5544\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6736 - accuracy: 0.6419 - my_auc: 0.6147 - val_loss: 0.6886 - val_accuracy: 0.8241 - val_my_auc: 0.5891\n",
            " epoch:1 auc: 0.5858\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.7467 - accuracy: 0.6501 - my_auc: 0.5978 - val_loss: 0.6793 - val_accuracy: 0.7449 - val_my_auc: 0.6063\n",
            " epoch:2 auc: 0.6042\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.7500 - accuracy: 0.6581 - my_auc: 0.5950 - val_loss: 0.6703 - val_accuracy: 0.7240 - val_my_auc: 0.6225\n",
            " epoch:3 auc: 0.6219\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6779 - accuracy: 0.6757 - my_auc: 0.6585 - val_loss: 0.6616 - val_accuracy: 0.7247 - val_my_auc: 0.6360\n",
            " epoch:4 auc: 0.6370\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6401 - accuracy: 0.6873 - my_auc: 0.6644 - val_loss: 0.6530 - val_accuracy: 0.7249 - val_my_auc: 0.6518\n",
            " epoch:5 auc: 0.6530\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6590 - accuracy: 0.6853 - my_auc: 0.6651 - val_loss: 0.6476 - val_accuracy: 0.7271 - val_my_auc: 0.6620\n",
            " epoch:6 auc: 0.6607\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6672 - accuracy: 0.6900 - my_auc: 0.6666 - val_loss: 0.6421 - val_accuracy: 0.7221 - val_my_auc: 0.6676\n",
            " epoch:7 auc: 0.6681\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6531 - accuracy: 0.6991 - my_auc: 0.5989 - val_loss: 0.6354 - val_accuracy: 0.7085 - val_my_auc: 0.6776\n",
            " epoch:8 auc: 0.6782\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6333 - accuracy: 0.6960 - my_auc: 0.6705 - val_loss: 0.6309 - val_accuracy: 0.7047 - val_my_auc: 0.6837\n",
            " epoch:9 auc: 0.6828\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.5675 - accuracy: 0.6942 - my_auc: 0.7224 - val_loss: 0.6262 - val_accuracy: 0.7038 - val_my_auc: 0.6899\n",
            " epoch:10 auc: 0.6891\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6926 - accuracy: 0.6834 - my_auc: 0.7048 - val_loss: 0.6241 - val_accuracy: 0.7187 - val_my_auc: 0.6907\n",
            " epoch:11 auc: 0.6906\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 0.6155 - accuracy: 0.7083 - my_auc: 0.6724 - val_loss: 0.6213 - val_accuracy: 0.7200 - val_my_auc: 0.6938\n",
            " epoch:12 auc: 0.6936\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.5913 - accuracy: 0.7159 - my_auc: 0.7203 - val_loss: 0.6198 - val_accuracy: 0.7204 - val_my_auc: 0.6938\n",
            " epoch:13 auc: 0.6935\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.5977 - accuracy: 0.7069 - my_auc: 0.7498 - val_loss: 0.6174 - val_accuracy: 0.7126 - val_my_auc: 0.6950\n",
            " epoch:14 auc: 0.6960\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6379 - accuracy: 0.6971 - my_auc: 0.7435 - val_loss: 0.6190 - val_accuracy: 0.7134 - val_my_auc: 0.6946\n",
            " epoch:15 auc: 0.6931\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6015 - accuracy: 0.7009 - my_auc: 0.7002 - val_loss: 0.6189 - val_accuracy: 0.7188 - val_my_auc: 0.6913\n",
            " epoch:16 auc: 0.6914\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 0.6394 - accuracy: 0.7053 - my_auc: 0.6995 - val_loss: 0.6186 - val_accuracy: 0.7182 - val_my_auc: 0.6896\n",
            " epoch:17 auc: 0.6892\n",
            "AUC:  0.7151\n",
            "iterate_num:  4 \n",
            " sum of test_y: 45.0\n",
            "train_x_shape (27128, 15)\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 24ms/step - loss: 0.7041 - accuracy: 0.3331 - my_auc: 0.6088 - val_loss: 0.6896 - val_accuracy: 0.0616 - val_my_auc: 0.6158\n",
            " epoch:0 auc: 0.6192\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6862 - accuracy: 0.5232 - my_auc: 0.6459 - val_loss: 0.6845 - val_accuracy: 0.2511 - val_my_auc: 0.6034\n",
            " epoch:1 auc: 0.6021\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 0.6593 - accuracy: 0.6043 - my_auc: 0.6128 - val_loss: 0.6772 - val_accuracy: 0.4422 - val_my_auc: 0.6199\n",
            " epoch:2 auc: 0.6198\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.5894 - accuracy: 0.6614 - my_auc: 0.7077 - val_loss: 0.6714 - val_accuracy: 0.5736 - val_my_auc: 0.6292\n",
            " epoch:3 auc: 0.6278\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 0.6375 - accuracy: 0.6857 - my_auc: 0.6479 - val_loss: 0.6671 - val_accuracy: 0.6278 - val_my_auc: 0.6335\n",
            " epoch:4 auc: 0.6350\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6276 - accuracy: 0.6848 - my_auc: 0.6680 - val_loss: 0.6647 - val_accuracy: 0.6418 - val_my_auc: 0.6395\n",
            " epoch:5 auc: 0.6399\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 0.6259 - accuracy: 0.6714 - my_auc: 0.6639 - val_loss: 0.6640 - val_accuracy: 0.6582 - val_my_auc: 0.6432\n",
            " epoch:6 auc: 0.6433\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6599 - accuracy: 0.6702 - my_auc: 0.7132 - val_loss: 0.6740 - val_accuracy: 0.6912 - val_my_auc: 0.6363\n",
            " epoch:7 auc: 0.6367\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 0.6045 - accuracy: 0.6874 - my_auc: 0.7419 - val_loss: 0.6754 - val_accuracy: 0.6946 - val_my_auc: 0.6428\n",
            " epoch:8 auc: 0.6426\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6469 - accuracy: 0.6918 - my_auc: 0.6585 - val_loss: 0.6764 - val_accuracy: 0.6957 - val_my_auc: 0.6448\n",
            " epoch:9 auc: 0.6451\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.5806 - accuracy: 0.6917 - my_auc: 0.6885 - val_loss: 0.6773 - val_accuracy: 0.6982 - val_my_auc: 0.6494\n",
            " epoch:10 auc: 0.6493\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.5980 - accuracy: 0.6845 - my_auc: 0.7287 - val_loss: 0.6800 - val_accuracy: 0.7052 - val_my_auc: 0.6517\n",
            " epoch:11 auc: 0.6521\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6559 - accuracy: 0.6849 - my_auc: 0.6924 - val_loss: 0.6766 - val_accuracy: 0.7119 - val_my_auc: 0.6566\n",
            " epoch:12 auc: 0.6571\n",
            "Epoch 14/30\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 0.5860 - accuracy: 0.6965 - my_auc: 0.7194 - val_loss: 0.6764 - val_accuracy: 0.7073 - val_my_auc: 0.6607\n",
            " epoch:13 auc: 0.6604\n",
            "Epoch 15/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.5934 - accuracy: 0.6860 - my_auc: 0.7086 - val_loss: 0.6753 - val_accuracy: 0.7024 - val_my_auc: 0.6620\n",
            " epoch:14 auc: 0.6622\n",
            "Epoch 16/30\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 0.5930 - accuracy: 0.6791 - my_auc: 0.7478 - val_loss: 0.6810 - val_accuracy: 0.7064 - val_my_auc: 0.6618\n",
            " epoch:15 auc: 0.6619\n",
            "Epoch 17/30\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 0.5958 - accuracy: 0.6878 - my_auc: 0.7174 - val_loss: 0.6835 - val_accuracy: 0.7086 - val_my_auc: 0.6641\n",
            " epoch:16 auc: 0.6642\n",
            "Epoch 18/30\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 0.5491 - accuracy: 0.6940 - my_auc: 0.7706 - val_loss: 0.6858 - val_accuracy: 0.7126 - val_my_auc: 0.6659\n",
            " epoch:17 auc: 0.6665\n",
            "Epoch 19/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.5808 - accuracy: 0.6978 - my_auc: 0.7408 - val_loss: 0.6874 - val_accuracy: 0.7160 - val_my_auc: 0.6671\n",
            " epoch:18 auc: 0.6676\n",
            "Epoch 20/30\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 0.6410 - accuracy: 0.6930 - my_auc: 0.7381 - val_loss: 0.6860 - val_accuracy: 0.7185 - val_my_auc: 0.6694\n",
            " epoch:19 auc: 0.6694\n",
            "Epoch 21/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.5847 - accuracy: 0.7026 - my_auc: 0.7568 - val_loss: 0.6925 - val_accuracy: 0.7232 - val_my_auc: 0.6664\n",
            " epoch:20 auc: 0.6664\n",
            "Epoch 22/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6711 - accuracy: 0.7003 - my_auc: 0.7126 - val_loss: 0.6876 - val_accuracy: 0.7207 - val_my_auc: 0.6699\n",
            " epoch:21 auc: 0.6697\n",
            "Epoch 23/30\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 0.6209 - accuracy: 0.6961 - my_auc: 0.7493 - val_loss: 0.6921 - val_accuracy: 0.7241 - val_my_auc: 0.6698\n",
            " epoch:22 auc: 0.6696\n",
            "Epoch 24/30\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 0.5927 - accuracy: 0.7010 - my_auc: 0.7360 - val_loss: 0.6952 - val_accuracy: 0.7293 - val_my_auc: 0.6713\n",
            " epoch:23 auc: 0.6713\n",
            "Epoch 25/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.5898 - accuracy: 0.7059 - my_auc: 0.7740 - val_loss: 0.6947 - val_accuracy: 0.7266 - val_my_auc: 0.6722\n",
            " epoch:24 auc: 0.6717\n",
            "Epoch 26/30\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 0.5310 - accuracy: 0.7051 - my_auc: 0.7653 - val_loss: 0.6958 - val_accuracy: 0.7266 - val_my_auc: 0.6730\n",
            " epoch:25 auc: 0.6727\n",
            "Epoch 27/30\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.6940 - accuracy: 0.6847 - my_auc: 0.7467 - val_loss: 0.6972 - val_accuracy: 0.7374 - val_my_auc: 0.6741\n",
            " epoch:26 auc: 0.6741\n",
            "Epoch 28/30\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 0.5732 - accuracy: 0.7074 - my_auc: 0.7769 - val_loss: 0.6999 - val_accuracy: 0.7313 - val_my_auc: 0.6730\n",
            " epoch:27 auc: 0.6727\n",
            "Epoch 29/30\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 0.5543 - accuracy: 0.7160 - my_auc: 0.7697 - val_loss: 0.7027 - val_accuracy: 0.7283 - val_my_auc: 0.6706\n",
            " epoch:28 auc: 0.6709\n",
            "Epoch 30/30\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 0.5659 - accuracy: 0.7028 - my_auc: 0.7892 - val_loss: 0.7168 - val_accuracy: 0.7386 - val_my_auc: 0.6685\n",
            " epoch:29 auc: 0.6683\n",
            "AUC:  0.6718\n",
            "avg_AUC :  0.6817429786906708\n",
            "avg_AUC_2 :  0.6818717477808387\n",
            "('perf+spc', ['aqi', 'asset_turnover', 'depi', 'gmi', 'opm', 'rg', 'sg', 'sgee', 'ch_rec', 'ch_inv', 'soft_asset', 'ch_cs', 'ch_roa', 'issue', 's1'])\n",
            "0.6817429786906708\n",
            "['WeakModal_3_p', 'WeakModal_3_n', 'WeakModal_3_new', 'WeakModal_3_dis', 'Negative_3_p', 'Negative_3_n', 'Negative_3_new', 'Negative_3_dis', 'Compare_3_p', 'Compare_3_n', 'Compare_3_new', 'Compare_3_dis', 'Discrep_3_p', 'Discrep_3_n', 'Discrep_3_new', 'Discrep_3_dis', 'Positive_3_p', 'Positive_3_n', 'Positive_3_new', 'Positive_3_dis', 'Achieve_3_p', 'Achieve_3_n', 'Achieve_3_new', 'Achieve_3_dis', 'Reward_3_p', 'Reward_3_n', 'Reward_3_new', 'Reward_3_dis', 'StrongModal_3_p', 'StrongModal_3_n', 'StrongModal_3_new', 'StrongModal_3_dis', 'Uncertainty_3_p', 'Uncertainty_3_n', 'Uncertainty_3_new', 'Uncertainty_3_dis', 'Litigious_3_p', 'Litigious_3_n', 'Litigious_3_new', 'Litigious_3_dis', 's1']\n",
            "dataset:  (45212, 42) /n 179.0\n",
            "iterate_num:  1 \n",
            " sum of test_y: 44.0\n",
            "train_x_shape (27127, 41)\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 26ms/step - loss: 0.6868 - accuracy: 0.5047 - my_auc: 0.5188 - val_loss: 0.6949 - val_accuracy: 0.9938 - val_my_auc: 0.4582\n",
            " epoch:0 auc: 0.4651\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 0.7050 - accuracy: 0.6421 - my_auc: 0.5436 - val_loss: 0.6930 - val_accuracy: 0.9379 - val_my_auc: 0.5012\n",
            " epoch:1 auc: 0.5121\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 0.7010 - accuracy: 0.6920 - my_auc: 0.5163 - val_loss: 0.6918 - val_accuracy: 0.8680 - val_my_auc: 0.5302\n",
            " epoch:2 auc: 0.5317\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 0.6604 - accuracy: 0.7442 - my_auc: 0.6140 - val_loss: 0.6903 - val_accuracy: 0.8356 - val_my_auc: 0.5445\n",
            " epoch:3 auc: 0.5406\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 0.7026 - accuracy: 0.7542 - my_auc: 0.5527 - val_loss: 0.6884 - val_accuracy: 0.7181 - val_my_auc: 0.5639\n",
            " epoch:4 auc: 0.5632\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 0.6763 - accuracy: 0.7389 - my_auc: 0.5967 - val_loss: 0.6859 - val_accuracy: 0.7008 - val_my_auc: 0.5881\n",
            " epoch:5 auc: 0.5867\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 0.6403 - accuracy: 0.7515 - my_auc: 0.6432 - val_loss: 0.6834 - val_accuracy: 0.6628 - val_my_auc: 0.5967\n",
            " epoch:6 auc: 0.5988\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 0.6300 - accuracy: 0.7286 - my_auc: 0.6928 - val_loss: 0.6828 - val_accuracy: 0.7044 - val_my_auc: 0.5927\n",
            " epoch:7 auc: 0.5959\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 0.6422 - accuracy: 0.7418 - my_auc: 0.6577 - val_loss: 0.6809 - val_accuracy: 0.6996 - val_my_auc: 0.6020\n",
            " epoch:8 auc: 0.6035\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 0.6188 - accuracy: 0.7350 - my_auc: 0.6517 - val_loss: 0.6788 - val_accuracy: 0.6955 - val_my_auc: 0.6114\n",
            " epoch:9 auc: 0.6107\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 0.6414 - accuracy: 0.7228 - my_auc: 0.7054 - val_loss: 0.6848 - val_accuracy: 0.7552 - val_my_auc: 0.5939\n",
            " epoch:10 auc: 0.5949\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 0.6648 - accuracy: 0.7333 - my_auc: 0.6635 - val_loss: 0.6856 - val_accuracy: 0.7642 - val_my_auc: 0.6018\n",
            " epoch:11 auc: 0.6026\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 0.6637 - accuracy: 0.7236 - my_auc: 0.7031 - val_loss: 0.6944 - val_accuracy: 0.7978 - val_my_auc: 0.6015\n",
            " epoch:12 auc: 0.6012\n",
            "AUC:  0.5595\n",
            "iterate_num:  2 \n",
            " sum of test_y: 45.0\n",
            "train_x_shape (27127, 41)\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 26ms/step - loss: 0.6749 - accuracy: 0.5419 - my_auc: 0.5698 - val_loss: 0.6894 - val_accuracy: 0.9649 - val_my_auc: 0.6304\n",
            " epoch:0 auc: 0.6286\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 0.7146 - accuracy: 0.6289 - my_auc: 0.5344 - val_loss: 0.6891 - val_accuracy: 0.8556 - val_my_auc: 0.6081\n",
            " epoch:1 auc: 0.6182\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 0.7696 - accuracy: 0.6375 - my_auc: 0.5527 - val_loss: 0.6876 - val_accuracy: 0.8145 - val_my_auc: 0.6276\n",
            " epoch:2 auc: 0.6238\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 0.6866 - accuracy: 0.6972 - my_auc: 0.5957 - val_loss: 0.6856 - val_accuracy: 0.6998 - val_my_auc: 0.6207\n",
            " epoch:3 auc: 0.6156\n",
            "AUC:  0.6162\n",
            "iterate_num:  3 \n",
            " sum of test_y: 45.0\n",
            "train_x_shape (27127, 41)\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 25ms/step - loss: 0.6772 - accuracy: 0.6838 - my_auc: 0.5646 - val_loss: 0.6958 - val_accuracy: 0.3237 - val_my_auc: 0.3923\n",
            " epoch:0 auc: 0.3881\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 0.7180 - accuracy: 0.7110 - my_auc: 0.6340 - val_loss: 0.6961 - val_accuracy: 0.6103 - val_my_auc: 0.4036\n",
            " epoch:1 auc: 0.3937\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 0.7234 - accuracy: 0.7805 - my_auc: 0.5519 - val_loss: 0.6937 - val_accuracy: 0.5349 - val_my_auc: 0.4696\n",
            " epoch:2 auc: 0.4717\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 0.6359 - accuracy: 0.8074 - my_auc: 0.6555 - val_loss: 0.6917 - val_accuracy: 0.3816 - val_my_auc: 0.5163\n",
            " epoch:3 auc: 0.5172\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 0.6331 - accuracy: 0.7399 - my_auc: 0.6845 - val_loss: 0.6900 - val_accuracy: 0.4394 - val_my_auc: 0.5384\n",
            " epoch:4 auc: 0.5381\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 0.6173 - accuracy: 0.7419 - my_auc: 0.7049 - val_loss: 0.6864 - val_accuracy: 0.4690 - val_my_auc: 0.5612\n",
            " epoch:5 auc: 0.5605\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 0.6498 - accuracy: 0.6982 - my_auc: 0.6717 - val_loss: 0.6848 - val_accuracy: 0.5919 - val_my_auc: 0.5658\n",
            " epoch:6 auc: 0.5659\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 0.6310 - accuracy: 0.7282 - my_auc: 0.6849 - val_loss: 0.6844 - val_accuracy: 0.6143 - val_my_auc: 0.5656\n",
            " epoch:7 auc: 0.5666\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 0.6436 - accuracy: 0.7294 - my_auc: 0.7434 - val_loss: 0.6850 - val_accuracy: 0.6566 - val_my_auc: 0.5727\n",
            " epoch:8 auc: 0.5726\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 0.6134 - accuracy: 0.7320 - my_auc: 0.7143 - val_loss: 0.6886 - val_accuracy: 0.6845 - val_my_auc: 0.5787\n",
            " epoch:9 auc: 0.5768\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 0.5711 - accuracy: 0.7545 - my_auc: 0.7483 - val_loss: 0.6929 - val_accuracy: 0.6438 - val_my_auc: 0.5703\n",
            " epoch:10 auc: 0.5719\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 0.5643 - accuracy: 0.7125 - my_auc: 0.6885 - val_loss: 0.6985 - val_accuracy: 0.6486 - val_my_auc: 0.5665\n",
            " epoch:11 auc: 0.5666\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 0.5835 - accuracy: 0.6917 - my_auc: 0.7359 - val_loss: 0.7178 - val_accuracy: 0.6734 - val_my_auc: 0.5481\n",
            " epoch:12 auc: 0.5487\n",
            "AUC:  0.5125\n",
            "iterate_num:  4 \n",
            " sum of test_y: 45.0\n",
            "train_x_shape (27127, 41)\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 26ms/step - loss: 0.8134 - accuracy: 0.9207 - my_auc: 0.4346 - val_loss: 0.6888 - val_accuracy: 0.7650 - val_my_auc: 0.6730\n",
            " epoch:0 auc: 0.6687\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 0.7929 - accuracy: 0.8674 - my_auc: 0.5211 - val_loss: 0.6879 - val_accuracy: 0.4245 - val_my_auc: 0.6477\n",
            " epoch:1 auc: 0.6398\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 0.6555 - accuracy: 0.8651 - my_auc: 0.5328 - val_loss: 0.6871 - val_accuracy: 0.3216 - val_my_auc: 0.6054\n",
            " epoch:2 auc: 0.6167\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 0.6552 - accuracy: 0.8028 - my_auc: 0.6004 - val_loss: 0.6862 - val_accuracy: 0.3245 - val_my_auc: 0.6024\n",
            " epoch:3 auc: 0.6008\n",
            "AUC:  0.598\n",
            "avg_AUC :  0.5715502320495923\n",
            "avg_AUC_2 :  0.5716011121314152\n",
            "('wrd+spc', ['WeakModal_3_p', 'WeakModal_3_n', 'WeakModal_3_new', 'WeakModal_3_dis', 'Negative_3_p', 'Negative_3_n', 'Negative_3_new', 'Negative_3_dis', 'Compare_3_p', 'Compare_3_n', 'Compare_3_new', 'Compare_3_dis', 'Discrep_3_p', 'Discrep_3_n', 'Discrep_3_new', 'Discrep_3_dis', 'Positive_3_p', 'Positive_3_n', 'Positive_3_new', 'Positive_3_dis', 'Achieve_3_p', 'Achieve_3_n', 'Achieve_3_new', 'Achieve_3_dis', 'Reward_3_p', 'Reward_3_n', 'Reward_3_new', 'Reward_3_dis', 'StrongModal_3_p', 'StrongModal_3_n', 'StrongModal_3_new', 'StrongModal_3_dis', 'Uncertainty_3_p', 'Uncertainty_3_n', 'Uncertainty_3_new', 'Uncertainty_3_dis', 'Litigious_3_p', 'Litigious_3_n', 'Litigious_3_new', 'Litigious_3_dis', 's1'])\n",
            "0.5715502320495923\n",
            "['aqi', 'asset_turnover', 'depi', 'gmi', 'opm', 'rg', 'sg', 'sgee', 'ch_rec', 'ch_inv', 'soft_asset', 'ch_cs', 'ch_roa', 'issue', 's1', 'WeakModal_3_p', 'WeakModal_3_n', 'WeakModal_3_new', 'WeakModal_3_dis', 'Negative_3_p', 'Negative_3_n', 'Negative_3_new', 'Negative_3_dis', 'Compare_3_p', 'Compare_3_n', 'Compare_3_new', 'Compare_3_dis', 'Discrep_3_p', 'Discrep_3_n', 'Discrep_3_new', 'Discrep_3_dis', 'Positive_3_p', 'Positive_3_n', 'Positive_3_new', 'Positive_3_dis', 'Achieve_3_p', 'Achieve_3_n', 'Achieve_3_new', 'Achieve_3_dis', 'Reward_3_p', 'Reward_3_n', 'Reward_3_new', 'Reward_3_dis', 'StrongModal_3_p', 'StrongModal_3_n', 'StrongModal_3_new', 'StrongModal_3_dis', 'Uncertainty_3_p', 'Uncertainty_3_n', 'Uncertainty_3_new', 'Uncertainty_3_dis', 'Litigious_3_p', 'Litigious_3_n', 'Litigious_3_new', 'Litigious_3_dis']\n",
            "dataset:  (45212, 56) /n 179.0\n",
            "iterate_num:  1 \n",
            " sum of test_y: 44.0\n",
            "train_x_shape (27127, 55)\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 27ms/step - loss: 0.7297 - accuracy: 0.7751 - my_auc: 0.5537 - val_loss: 0.6898 - val_accuracy: 0.0534 - val_my_auc: 0.5955\n",
            " epoch:0 auc: 0.5976\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.6955 - accuracy: 0.7090 - my_auc: 0.6023 - val_loss: 0.6863 - val_accuracy: 0.0886 - val_my_auc: 0.6077\n",
            " epoch:1 auc: 0.6150\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.6548 - accuracy: 0.6953 - my_auc: 0.6682 - val_loss: 0.6740 - val_accuracy: 0.2129 - val_my_auc: 0.6343\n",
            " epoch:2 auc: 0.6344\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.6075 - accuracy: 0.7364 - my_auc: 0.7511 - val_loss: 0.6658 - val_accuracy: 0.2861 - val_my_auc: 0.6252\n",
            " epoch:3 auc: 0.6229\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.6194 - accuracy: 0.7093 - my_auc: 0.7406 - val_loss: 0.6585 - val_accuracy: 0.3816 - val_my_auc: 0.6188\n",
            " epoch:4 auc: 0.6200\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.6390 - accuracy: 0.7056 - my_auc: 0.7295 - val_loss: 0.6561 - val_accuracy: 0.5109 - val_my_auc: 0.6190\n",
            " epoch:5 auc: 0.6190\n",
            "AUC:  0.7474\n",
            "iterate_num:  2 \n",
            " sum of test_y: 45.0\n",
            "train_x_shape (27127, 55)\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 27ms/step - loss: 0.7078 - accuracy: 0.8162 - my_auc: 0.5107 - val_loss: 0.6838 - val_accuracy: 0.0991 - val_my_auc: 0.6322\n",
            " epoch:0 auc: 0.6329\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.6388 - accuracy: 0.7324 - my_auc: 0.6678 - val_loss: 0.6743 - val_accuracy: 0.1918 - val_my_auc: 0.6613\n",
            " epoch:1 auc: 0.6624\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.6196 - accuracy: 0.7435 - my_auc: 0.6973 - val_loss: 0.6631 - val_accuracy: 0.2866 - val_my_auc: 0.6715\n",
            " epoch:2 auc: 0.6717\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.5447 - accuracy: 0.7569 - my_auc: 0.7656 - val_loss: 0.6499 - val_accuracy: 0.3986 - val_my_auc: 0.6814\n",
            " epoch:3 auc: 0.6809\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.5669 - accuracy: 0.7630 - my_auc: 0.7565 - val_loss: 0.6381 - val_accuracy: 0.4804 - val_my_auc: 0.6930\n",
            " epoch:4 auc: 0.6919\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.5583 - accuracy: 0.7428 - my_auc: 0.8216 - val_loss: 0.6316 - val_accuracy: 0.5753 - val_my_auc: 0.6957\n",
            " epoch:5 auc: 0.6955\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.5350 - accuracy: 0.7663 - my_auc: 0.7828 - val_loss: 0.6326 - val_accuracy: 0.6032 - val_my_auc: 0.6941\n",
            " epoch:6 auc: 0.6935\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.5368 - accuracy: 0.7403 - my_auc: 0.8244 - val_loss: 0.6358 - val_accuracy: 0.6137 - val_my_auc: 0.6908\n",
            " epoch:7 auc: 0.6909\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.6040 - accuracy: 0.7126 - my_auc: 0.8000 - val_loss: 0.6511 - val_accuracy: 0.7291 - val_my_auc: 0.6902\n",
            " epoch:8 auc: 0.6905\n",
            "AUC:  0.6767\n",
            "iterate_num:  3 \n",
            " sum of test_y: 45.0\n",
            "train_x_shape (27127, 55)\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 2s 27ms/step - loss: 0.7430 - accuracy: 0.3269 - my_auc: 0.4857 - val_loss: 0.6882 - val_accuracy: 0.8096 - val_my_auc: 0.5926\n",
            " epoch:0 auc: 0.5912\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.7043 - accuracy: 0.6789 - my_auc: 0.6598 - val_loss: 0.6786 - val_accuracy: 0.6721 - val_my_auc: 0.6301\n",
            " epoch:1 auc: 0.6299\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.5989 - accuracy: 0.7810 - my_auc: 0.7373 - val_loss: 0.6655 - val_accuracy: 0.5055 - val_my_auc: 0.6608\n",
            " epoch:2 auc: 0.6595\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.5717 - accuracy: 0.7493 - my_auc: 0.7773 - val_loss: 0.6543 - val_accuracy: 0.5249 - val_my_auc: 0.6731\n",
            " epoch:3 auc: 0.6738\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.5832 - accuracy: 0.7285 - my_auc: 0.7673 - val_loss: 0.6439 - val_accuracy: 0.6103 - val_my_auc: 0.6838\n",
            " epoch:4 auc: 0.6843\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.5905 - accuracy: 0.7527 - my_auc: 0.7658 - val_loss: 0.6401 - val_accuracy: 0.6258 - val_my_auc: 0.6896\n",
            " epoch:5 auc: 0.6886\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.5744 - accuracy: 0.7380 - my_auc: 0.7969 - val_loss: 0.6387 - val_accuracy: 0.6805 - val_my_auc: 0.6915\n",
            " epoch:6 auc: 0.6915\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.5180 - accuracy: 0.7683 - my_auc: 0.7994 - val_loss: 0.6375 - val_accuracy: 0.6812 - val_my_auc: 0.6904\n",
            " epoch:7 auc: 0.6908\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.5101 - accuracy: 0.7627 - my_auc: 0.7950 - val_loss: 0.6447 - val_accuracy: 0.7312 - val_my_auc: 0.6846\n",
            " epoch:8 auc: 0.6854\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.4999 - accuracy: 0.7844 - my_auc: 0.8368 - val_loss: 0.6404 - val_accuracy: 0.7051 - val_my_auc: 0.6899\n",
            " epoch:9 auc: 0.6902\n",
            "AUC:  0.6674\n",
            "iterate_num:  4 \n",
            " sum of test_y: 45.0\n",
            "train_x_shape (27127, 55)\n",
            "Epoch 1/30\n",
            "53/53 [==============================] - 3s 28ms/step - loss: 0.6797 - accuracy: 0.8375 - my_auc: 0.4658 - val_loss: 0.6901 - val_accuracy: 0.2182 - val_my_auc: 0.5407\n",
            " epoch:0 auc: 0.5530\n",
            "Epoch 2/30\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.6504 - accuracy: 0.6847 - my_auc: 0.6038 - val_loss: 0.6773 - val_accuracy: 0.1769 - val_my_auc: 0.7107\n",
            " epoch:1 auc: 0.7133\n",
            "Epoch 3/30\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.6627 - accuracy: 0.6935 - my_auc: 0.6697 - val_loss: 0.6614 - val_accuracy: 0.2949 - val_my_auc: 0.7414\n",
            " epoch:2 auc: 0.7410\n",
            "Epoch 4/30\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.6152 - accuracy: 0.7128 - my_auc: 0.7528 - val_loss: 0.6436 - val_accuracy: 0.3885 - val_my_auc: 0.7501\n",
            " epoch:3 auc: 0.7508\n",
            "Epoch 5/30\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.6603 - accuracy: 0.6869 - my_auc: 0.6834 - val_loss: 0.6257 - val_accuracy: 0.5118 - val_my_auc: 0.7552\n",
            " epoch:4 auc: 0.7531\n",
            "Epoch 6/30\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.5971 - accuracy: 0.7213 - my_auc: 0.7790 - val_loss: 0.6103 - val_accuracy: 0.6032 - val_my_auc: 0.7545\n",
            " epoch:5 auc: 0.7538\n",
            "Epoch 7/30\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.5852 - accuracy: 0.7487 - my_auc: 0.7365 - val_loss: 0.5998 - val_accuracy: 0.5960 - val_my_auc: 0.7540\n",
            " epoch:6 auc: 0.7536\n",
            "Epoch 8/30\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.5402 - accuracy: 0.7232 - my_auc: 0.7738 - val_loss: 0.5881 - val_accuracy: 0.6234 - val_my_auc: 0.7581\n",
            " epoch:7 auc: 0.7575\n",
            "Epoch 9/30\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.5421 - accuracy: 0.7234 - my_auc: 0.7994 - val_loss: 0.5783 - val_accuracy: 0.6811 - val_my_auc: 0.7602\n",
            " epoch:8 auc: 0.7597\n",
            "Epoch 10/30\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.5195 - accuracy: 0.7528 - my_auc: 0.7751 - val_loss: 0.5680 - val_accuracy: 0.6439 - val_my_auc: 0.7669\n",
            " epoch:9 auc: 0.7667\n",
            "Epoch 11/30\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.5858 - accuracy: 0.6944 - my_auc: 0.7976 - val_loss: 0.5702 - val_accuracy: 0.7330 - val_my_auc: 0.7626\n",
            " epoch:10 auc: 0.7623\n",
            "Epoch 12/30\n",
            "53/53 [==============================] - 0s 9ms/step - loss: 0.5262 - accuracy: 0.7517 - my_auc: 0.8395 - val_loss: 0.5821 - val_accuracy: 0.7551 - val_my_auc: 0.7540\n",
            " epoch:11 auc: 0.7538\n",
            "Epoch 13/30\n",
            "53/53 [==============================] - 1s 9ms/step - loss: 0.5030 - accuracy: 0.7514 - my_auc: 0.8168 - val_loss: 0.5872 - val_accuracy: 0.7452 - val_my_auc: 0.7491\n",
            " epoch:12 auc: 0.7493\n",
            "AUC:  0.6608\n",
            "avg_AUC :  0.6880977798050145\n",
            "avg_AUC_2 :  0.6879655137230893\n",
            "('perf+spc+wrd', ['aqi', 'asset_turnover', 'depi', 'gmi', 'opm', 'rg', 'sg', 'sgee', 'ch_rec', 'ch_inv', 'soft_asset', 'ch_cs', 'ch_roa', 'issue', 's1', 'WeakModal_3_p', 'WeakModal_3_n', 'WeakModal_3_new', 'WeakModal_3_dis', 'Negative_3_p', 'Negative_3_n', 'Negative_3_new', 'Negative_3_dis', 'Compare_3_p', 'Compare_3_n', 'Compare_3_new', 'Compare_3_dis', 'Discrep_3_p', 'Discrep_3_n', 'Discrep_3_new', 'Discrep_3_dis', 'Positive_3_p', 'Positive_3_n', 'Positive_3_new', 'Positive_3_dis', 'Achieve_3_p', 'Achieve_3_n', 'Achieve_3_new', 'Achieve_3_dis', 'Reward_3_p', 'Reward_3_n', 'Reward_3_new', 'Reward_3_dis', 'StrongModal_3_p', 'StrongModal_3_n', 'StrongModal_3_new', 'StrongModal_3_dis', 'Uncertainty_3_p', 'Uncertainty_3_n', 'Uncertainty_3_new', 'Uncertainty_3_dis', 'Litigious_3_p', 'Litigious_3_n', 'Litigious_3_new', 'Litigious_3_dis'])\n",
            "0.6880977798050145\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk2YpCVFO6H4"
      },
      "source": [
        "\r\n",
        "\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G33fSIWstACz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HmrzGrstBcl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8AIKnmytCop"
      },
      "source": [
        "# LSTM\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCc1MXU1tA3G"
      },
      "source": [
        "def model_lstm(n1,n2,n,w,l):\r\n",
        "    model = None\r\n",
        "    \r\n",
        "    input_all = Input(shape=(w,l), \\\r\n",
        "               dtype='float32', name='input')\r\n",
        "    nor = BatchNormalization()(input_all)\r\n",
        "    LSTM_w_1 = Bidirectional(LSTM(n1, dropout = 0.3, recurrent_dropout = 0.3, \\\r\n",
        "              name = 'layer_lstm_1', return_sequences=True))(nor)\r\n",
        "    LSTM_w_2 = LSTM(n2, activation='relu', dropout = 0.3, recurrent_dropout = 0.3,\r\n",
        "                   name = 'layer_lstm_2', return_sequences=False)(LSTM_w_1)\r\n",
        "\r\n",
        "    dense = Dense(n, activation='relu', name='dense')(LSTM_w_2)\r\n",
        "    preds = Dense(1, activation='sigmoid', name='output')(dense)\r\n",
        "    model = Model(inputs=input_all, outputs=preds)\r\n",
        "    model._name = \"model_lstm\"\r\n",
        "    model.summary()\r\n",
        "    \r\n",
        "    return model"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Mz_0irVtHaA"
      },
      "source": [
        "def performance_measure(pred_yp, y):\r\n",
        "    '''\r\n",
        "    Given lists of predicted y probability and x, y, return a dataframe of AR, AUC, Brier, Decile Table\r\n",
        "    '''\r\n",
        "    \r\n",
        "    tenc_dat = pd.DataFrame({'y_true':y,'probability':pred_yp.flatten()})\r\n",
        "    tenc_dat.sort_values('probability',axis = 0,ascending=False, inplace = True)\r\n",
        "    tenc_dat.index = range(0,len(tenc_dat))\r\n",
        "    y = tenc_dat['y_true']\r\n",
        "    point = float(len(tenc_dat))/10\r\n",
        "    point = int(round(point))\r\n",
        "    tenc = []\r\n",
        "    for i in range(0,10):\r\n",
        "        tenc.append(y[(i*point):((i+1)*point)])\r\n",
        "    tenc[9]=tenc[9].append(y[10*point:])\r\n",
        "    total = sum(y)\r\n",
        "    num_of_bkr = []\r\n",
        "    for j in range(0,10):\r\n",
        "        num_of_bkr.append(sum(tenc[j]))\r\n",
        "    tencile_bkr = np.array(num_of_bkr)\r\n",
        "    rate = tencile_bkr.astype(float)/total\r\n",
        "\r\n",
        "    return rate"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvMQRg18tVc1"
      },
      "source": [
        "class AUCEvaluation(Callback):\r\n",
        "    \"\"\" Show AUC after interval number of epoches \"\"\"\r\n",
        "    def __init__(self, validation_data=(), interval=1):\r\n",
        "        super(Callback, self).__init__()\r\n",
        "        self.interval = interval\r\n",
        "        self.X_val, self.y_val = validation_data\r\n",
        "\r\n",
        "    def on_epoch_end(self, epoch, logs={}):\r\n",
        "        if epoch % self.interval == 0:\r\n",
        "            y_pred = self.model.predict(self.X_val, verbose=0)\r\n",
        "            score = roc_auc_score(self.y_val, y_pred)\r\n",
        "            logs['auc'] = score\r\n",
        "            tencile=performance_measure(y_pred, self.y_val)\r\n",
        "            logs['tencile'] = tencile\r\n",
        "            print(\" epoch:{:d} auc: {:.4f}\".format(epoch, score))"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "falc_CdgtVep"
      },
      "source": [
        "def fit_model( model,x_train, y_train, x_val, y_val, x_test, y_test, model_name, verbose = 0):\r\n",
        "    \r\n",
        "    history = None\r\n",
        "    result = None\r\n",
        "    \r\n",
        "    model_df = model\r\n",
        "    \r\n",
        "    #class weight for test \r\n",
        "    class_weights = class_weight.compute_class_weight('balanced',\r\n",
        "                              np.unique(y_train),\r\n",
        "                              y_train)\r\n",
        "    class_weights = {l:c for l,c in zip(np.unique(y_train), class_weights)}\r\n",
        "    print(class_weights)\r\n",
        "    # class weight for val\r\n",
        "    val_class_weights = class_weight.compute_class_weight('balanced',\r\n",
        "                                np.unique(y_val),\r\n",
        "                                y_val)\r\n",
        "    val_class_weights = {l:c for l,c in zip(np.unique(y_val), val_class_weights)}\r\n",
        "    val_sample_weights = []\r\n",
        "    for y in y_val:\r\n",
        "        if y == 1:\r\n",
        "          val_sample_weights.append(val_class_weights[1])\r\n",
        "        else: val_sample_weights.append(val_class_weights[0])\r\n",
        "    val_sample_weights = np.asarray(val_sample_weights)\r\n",
        "    \r\n",
        "    \r\n",
        "    auc_eval = AUCEvaluation(validation_data=(x_val, y_val), interval=1)\r\n",
        "    earlyStopping = EarlyStopping(monitor='val_my_auc',patience = 3, \r\n",
        "                      verbose =verbose, mode ='max')\r\n",
        "    checkpoint = ModelCheckpoint(model_name,monitor='val_my_auc',verbose=verbose,\r\n",
        "              save_best_only=True, save_weights_only=True, mode ='max')\r\n",
        "\r\n",
        "    opt = optimizers.RMSprop(lr=0.0005)\r\n",
        "    model_df.compile(optimizer= opt,\r\n",
        "              loss='binary_crossentropy',\r\n",
        "              metrics=['accuracy', metrics.AUC(name='my_auc')])\r\n",
        "    \r\n",
        "    history = model_df.fit(x_train,\r\n",
        "                y_train,\r\n",
        "                epochs=30,\r\n",
        "                batch_size=512,\r\n",
        "                callbacks=[auc_eval, earlyStopping,checkpoint], #checkpoint\r\n",
        "                class_weight = class_weights, \\\r\n",
        "                validation_data=(x_val,y_val,val_sample_weights)) \r\n",
        "    model_df.load_weights(model_name)\r\n",
        "    y_pred = model_df.predict(x_test)\r\n",
        "    y_pred_1=np.reshape(y_pred, -1)\r\n",
        "    auc_score = roc_auc_score(y_test, y_pred_1)\r\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_1)\r\n",
        "    print(\"AUC: \" ,round(auc_score,4))\r\n",
        "        \r\n",
        "    return history, auc_score, fpr, tpr, thresholds, [y_test, y_pred_1]"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7ihwXRbtVgF"
      },
      "source": [
        "def cross_val(data, label, perf_cols, name, w):\r\n",
        "    tprs = []\r\n",
        "    auc_list = []\r\n",
        "    mean_fpr = np.linspace(0,1,100)\r\n",
        "    predicted_res =[]\r\n",
        "    his_auc = []\r\n",
        "    \r\n",
        "    kf = StratifiedKFold(n_splits = 4, shuffle = True, random_state = 42)\r\n",
        "    c = 0\r\n",
        "\r\n",
        "    X_perf,  Y = shift_data(df_fl, w, \\\r\n",
        "                    perf_cols, \\\r\n",
        "                    'label')\r\n",
        "    \r\n",
        "    for train_index, test_index in kf.split(range(len(X_perf)),Y):\r\n",
        "        \r\n",
        "        c += 1\r\n",
        "        \r\n",
        "        l1 = X_perf.shape[-1] + 16\r\n",
        "        \r\n",
        "        model = model_lstm(l1,l1,32,\\\r\n",
        "                    X_perf.shape[1],X_perf.shape[2])\r\n",
        "    \r\n",
        "        #model = model_lstm(n1,n2,n,w)\r\n",
        "        # train_x, train_val = train_test_split(train_index,test_size=0.2, \\\r\n",
        "        #             random_state=42, stratify = Y[train_index])\r\n",
        "        train_perf_data = X_perf[train_index]\r\n",
        "        #train_word_data = X_word[train_x]\r\n",
        "        #train_perf_val = X_perf[train_val]\r\n",
        "        #train_word_val = X_word[train_val]\r\n",
        "\r\n",
        "        train_label = Y[train_index]\r\n",
        "        #val_label = Y[train_val]\r\n",
        "\r\n",
        "        test_perf_x = X_perf[test_index]\r\n",
        "        #test_word_x = X_word[test_index]\r\n",
        "        test_y = Y[test_index] \r\n",
        "        \r\n",
        "        # train_data = [train_perf_data, train_word_data]\r\n",
        "        # val_data = [train_perf_val,train_word_val]       \r\n",
        "        # test_x = [test_perf_x, test_word_x]\r\n",
        "\r\n",
        "        mod_res = fit_model(model, train_perf_data, train_label, test_perf_x, test_y, test_perf_x, test_y,\\\r\n",
        "                  name+'_'+str(c))\r\n",
        "        his_auc.append(mod_res[0].history['val_my_auc'])\r\n",
        "        \r\n",
        "        \r\n",
        "        \r\n",
        "        \r\n",
        "        auc_list.append(mod_res[1])\r\n",
        "        tprs.append(np.interp(mean_fpr, mod_res[2], mod_res[3]))\r\n",
        "        temp_pred_res = [mod_res[-1],test_index]\r\n",
        "        print(len(test_index))\r\n",
        "        predicted_res.append(temp_pred_res)\r\n",
        "        \r\n",
        "        \r\n",
        "    mean_tpr = np.mean(tprs, axis=0)\r\n",
        "    print('avg_AUC : ', np.mean(auc_list))\r\n",
        "    print('avg_AUC_2 : ', auc(mean_fpr, mean_tpr))\r\n",
        "    print(pd.DataFrame(his_auc))\r\n",
        "    print(pd.DataFrame(his_auc).mean())\r\n",
        "    \r\n",
        "    return np.average(auc_list), mean_tpr, predicted_res"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYHUoqz-tVif"
      },
      "source": [
        "def shift_data(data, step, perf_cols, label):\r\n",
        "    A = []\r\n",
        "    \r\n",
        "    cols = perf_cols #+ words_cols\r\n",
        "    A.append(data[cols].values)\r\n",
        "    \r\n",
        "    for t in range(1, step):\r\n",
        "        d = data.groupby(\"cik\")[cols].shift(t)\r\n",
        "        A.append(d.values)\r\n",
        "    A = A[::-1]\r\n",
        "    A = np.concatenate(A, axis = 1)  # flatten shifted columns\r\n",
        "    A = np.concatenate([data[label].values[:,None], A], axis = 1)  # add target\r\n",
        "    #np.random.shuffle(A)\r\n",
        "    #print(A[3])\r\n",
        "    print('init A shape: ',A.shape)\r\n",
        "    #print(A[3,:])\r\n",
        "    #print(data[cols].iloc[4,:])\r\n",
        "\r\n",
        "\r\n",
        "    \r\n",
        "    A = A[~np.isnan(A).any(axis=1)]  # drop nan\r\n",
        "    \r\n",
        "\r\n",
        "    Y = A[:,0]  # get target\r\n",
        "    #A = np.reshape(A[:,1:], (len(A), step, len(cols))) # reshape\r\n",
        "\r\n",
        "    A = np.reshape(A[:,1:], (len(A), step, len(perf_cols)))\r\n",
        "    \r\n",
        "    A_perf = A[:, :, 0:len(perf_cols)]\r\n",
        "    # # CNN_LSTM must be None x T x words x 4\r\n",
        "    # A_words = A[:, :, len(perf_cols):]\r\n",
        "    # #convert the shape to [[_p,_new][_dis,_n]]\r\n",
        "    # A_words = A_words.reshape((len(A), step, int(len(words_cols)/2), 2), order = 'C')\r\n",
        "    \r\n",
        "    print(A_perf.shape, Y.sum())\r\n",
        "    return A_perf, Y\r\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFlhj7-xzTES",
        "outputId": "a97c2167-f580-4573-c9b1-177ca2140411"
      },
      "source": [
        "# financial performance + overall change timestep = 3\r\n",
        "cross_val(df_fl, 'label', v_perf , 'lstm_perf', 3)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "init A shape:  (45213, 43)\n",
            "(33527, 3, 14) 95.0\n",
            "Model: \"model_lstm\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 3, 14)]           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_31 (Batc (None, 3, 14)             56        \n",
            "_________________________________________________________________\n",
            "bidirectional_15 (Bidirectio (None, 3, 60)             10800     \n",
            "_________________________________________________________________\n",
            "layer_lstm_2 (LSTM)          (None, 30)                10920     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                992       \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 22,801\n",
            "Trainable params: 22,773\n",
            "Non-trainable params: 28\n",
            "_________________________________________________________________\n",
            "{0.0: 0.5014158092047539, 1.0: 177.07746478873239}\n",
            "Epoch 1/30\n",
            "50/50 [==============================] - 14s 79ms/step - loss: 0.7196 - accuracy: 0.1794 - my_auc: 0.5787 - val_loss: 0.6903 - val_accuracy: 0.1092 - val_my_auc: 0.5868\n",
            " epoch:0 auc: 0.6106\n",
            "Epoch 2/30\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.6575 - accuracy: 0.6426 - my_auc: 0.6660 - val_loss: 0.6868 - val_accuracy: 0.1655 - val_my_auc: 0.6176\n",
            " epoch:1 auc: 0.6200\n",
            "Epoch 3/30\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.6291 - accuracy: 0.6610 - my_auc: 0.7588 - val_loss: 0.6800 - val_accuracy: 0.2866 - val_my_auc: 0.6210\n",
            " epoch:2 auc: 0.6229\n",
            "Epoch 4/30\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.6570 - accuracy: 0.6599 - my_auc: 0.6929 - val_loss: 0.6702 - val_accuracy: 0.3923 - val_my_auc: 0.6306\n",
            " epoch:3 auc: 0.6268\n",
            "Epoch 5/30\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.6584 - accuracy: 0.6553 - my_auc: 0.7372 - val_loss: 0.6598 - val_accuracy: 0.4630 - val_my_auc: 0.6278\n",
            " epoch:4 auc: 0.6297\n",
            "Epoch 6/30\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.6313 - accuracy: 0.6427 - my_auc: 0.7173 - val_loss: 0.6587 - val_accuracy: 0.5348 - val_my_auc: 0.6280\n",
            " epoch:5 auc: 0.6286\n",
            "Epoch 7/30\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.5677 - accuracy: 0.6592 - my_auc: 0.7289 - val_loss: 0.6605 - val_accuracy: 0.5431 - val_my_auc: 0.6307\n",
            " epoch:6 auc: 0.6303\n",
            "Epoch 8/30\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.5859 - accuracy: 0.6458 - my_auc: 0.7683 - val_loss: 0.6703 - val_accuracy: 0.5682 - val_my_auc: 0.6286\n",
            " epoch:7 auc: 0.6286\n",
            "Epoch 9/30\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.5006 - accuracy: 0.6628 - my_auc: 0.6990 - val_loss: 0.6830 - val_accuracy: 0.5846 - val_my_auc: 0.6289\n",
            " epoch:8 auc: 0.6288\n",
            "Epoch 10/30\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.6597 - accuracy: 0.6288 - my_auc: 0.7389 - val_loss: 0.6887 - val_accuracy: 0.6104 - val_my_auc: 0.6279\n",
            " epoch:9 auc: 0.6273\n",
            "AUC:  0.6303\n",
            "8382\n",
            "Model: \"model_lstm\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 3, 14)]           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_32 (Batc (None, 3, 14)             56        \n",
            "_________________________________________________________________\n",
            "bidirectional_16 (Bidirectio (None, 3, 60)             10800     \n",
            "_________________________________________________________________\n",
            "layer_lstm_2 (LSTM)          (None, 30)                10920     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                992       \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 22,801\n",
            "Trainable params: 22,773\n",
            "Non-trainable params: 28\n",
            "_________________________________________________________________\n",
            "{0.0: 0.5014158092047539, 1.0: 177.07746478873239}\n",
            "Epoch 1/30\n",
            "50/50 [==============================] - 13s 76ms/step - loss: 0.7212 - accuracy: 0.3145 - my_auc: 0.5954 - val_loss: 0.6906 - val_accuracy: 0.0033 - val_my_auc: 0.7021\n",
            " epoch:0 auc: 0.7288\n",
            "Epoch 2/30\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.6582 - accuracy: 0.5617 - my_auc: 0.5903 - val_loss: 0.6859 - val_accuracy: 0.0364 - val_my_auc: 0.7299\n",
            " epoch:1 auc: 0.7462\n",
            "Epoch 3/30\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.6141 - accuracy: 0.6026 - my_auc: 0.7355 - val_loss: 0.6793 - val_accuracy: 0.1280 - val_my_auc: 0.7395\n",
            " epoch:2 auc: 0.7365\n",
            "Epoch 4/30\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.6657 - accuracy: 0.5645 - my_auc: 0.6730 - val_loss: 0.6676 - val_accuracy: 0.2732 - val_my_auc: 0.7277\n",
            " epoch:3 auc: 0.7270\n",
            "Epoch 5/30\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.6203 - accuracy: 0.6178 - my_auc: 0.6427 - val_loss: 0.6534 - val_accuracy: 0.3726 - val_my_auc: 0.7261\n",
            " epoch:4 auc: 0.7267\n",
            "Epoch 6/30\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.6353 - accuracy: 0.6138 - my_auc: 0.6408 - val_loss: 0.6352 - val_accuracy: 0.4667 - val_my_auc: 0.7236\n",
            " epoch:5 auc: 0.7243\n",
            "AUC:  0.7365\n",
            "8382\n",
            "Model: \"model_lstm\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 3, 14)]           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_33 (Batc (None, 3, 14)             56        \n",
            "_________________________________________________________________\n",
            "bidirectional_17 (Bidirectio (None, 3, 60)             10800     \n",
            "_________________________________________________________________\n",
            "layer_lstm_2 (LSTM)          (None, 30)                10920     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                992       \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 22,801\n",
            "Trainable params: 22,773\n",
            "Non-trainable params: 28\n",
            "_________________________________________________________________\n",
            "{0.0: 0.5014158092047539, 1.0: 177.07746478873239}\n",
            "Epoch 1/30\n",
            "50/50 [==============================] - 13s 76ms/step - loss: 0.6889 - accuracy: 0.6303 - my_auc: 0.5479 - val_loss: 0.6917 - val_accuracy: 0.1314 - val_my_auc: 0.5931\n",
            " epoch:0 auc: 0.6337\n",
            "Epoch 2/30\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.7393 - accuracy: 0.8123 - my_auc: 0.6380 - val_loss: 0.6896 - val_accuracy: 0.1488 - val_my_auc: 0.6566\n",
            " epoch:1 auc: 0.6623\n",
            "Epoch 3/30\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.6276 - accuracy: 0.8194 - my_auc: 0.7008 - val_loss: 0.6841 - val_accuracy: 0.2041 - val_my_auc: 0.6918\n",
            " epoch:2 auc: 0.6881\n",
            "Epoch 4/30\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.6287 - accuracy: 0.7175 - my_auc: 0.7311 - val_loss: 0.6741 - val_accuracy: 0.3008 - val_my_auc: 0.7077\n",
            " epoch:3 auc: 0.7028\n",
            "Epoch 5/30\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.5849 - accuracy: 0.6608 - my_auc: 0.6330 - val_loss: 0.6596 - val_accuracy: 0.4009 - val_my_auc: 0.7074\n",
            " epoch:4 auc: 0.7130\n",
            "Epoch 6/30\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.7175 - accuracy: 0.6234 - my_auc: 0.6327 - val_loss: 0.6508 - val_accuracy: 0.4742 - val_my_auc: 0.7181\n",
            " epoch:5 auc: 0.7214\n",
            "Epoch 7/30\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.5993 - accuracy: 0.6461 - my_auc: 0.6607 - val_loss: 0.6532 - val_accuracy: 0.4755 - val_my_auc: 0.7208\n",
            " epoch:6 auc: 0.7210\n",
            "Epoch 8/30\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.5946 - accuracy: 0.5943 - my_auc: 0.6890 - val_loss: 0.6683 - val_accuracy: 0.4871 - val_my_auc: 0.7208\n",
            " epoch:7 auc: 0.7233\n",
            "Epoch 9/30\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.6612 - accuracy: 0.5656 - my_auc: 0.6850 - val_loss: 0.6795 - val_accuracy: 0.4961 - val_my_auc: 0.7261\n",
            " epoch:8 auc: 0.7262\n",
            "Epoch 10/30\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.6922 - accuracy: 0.5514 - my_auc: 0.6842 - val_loss: 0.6972 - val_accuracy: 0.5116 - val_my_auc: 0.7279\n",
            " epoch:9 auc: 0.7279\n",
            "Epoch 11/30\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.5887 - accuracy: 0.5537 - my_auc: 0.6625 - val_loss: 0.7233 - val_accuracy: 0.5103 - val_my_auc: 0.7268\n",
            " epoch:10 auc: 0.7276\n",
            "Epoch 12/30\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.6100 - accuracy: 0.5445 - my_auc: 0.7078 - val_loss: 0.7375 - val_accuracy: 0.5098 - val_my_auc: 0.7295\n",
            " epoch:11 auc: 0.7298\n",
            "Epoch 13/30\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.6080 - accuracy: 0.5325 - my_auc: 0.7009 - val_loss: 0.7385 - val_accuracy: 0.5082 - val_my_auc: 0.7321\n",
            " epoch:12 auc: 0.7308\n",
            "Epoch 14/30\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.5944 - accuracy: 0.5282 - my_auc: 0.6468 - val_loss: 0.7397 - val_accuracy: 0.4980 - val_my_auc: 0.7302\n",
            " epoch:13 auc: 0.7306\n",
            "Epoch 15/30\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.5718 - accuracy: 0.5170 - my_auc: 0.6900 - val_loss: 0.7528 - val_accuracy: 0.4871 - val_my_auc: 0.7267\n",
            " epoch:14 auc: 0.7321\n",
            "Epoch 16/30\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.5695 - accuracy: 0.5027 - my_auc: 0.7028 - val_loss: 0.8477 - val_accuracy: 0.5093 - val_my_auc: 0.7287\n",
            " epoch:15 auc: 0.7318\n",
            "AUC:  0.7308\n",
            "8382\n",
            "Model: \"model_lstm\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 3, 14)]           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_34 (Batc (None, 3, 14)             56        \n",
            "_________________________________________________________________\n",
            "bidirectional_18 (Bidirectio (None, 3, 60)             10800     \n",
            "_________________________________________________________________\n",
            "layer_lstm_2 (LSTM)          (None, 30)                10920     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                992       \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 22,801\n",
            "Trainable params: 22,773\n",
            "Non-trainable params: 28\n",
            "_________________________________________________________________\n",
            "{0.0: 0.5014357501794687, 1.0: 174.625}\n",
            "Epoch 1/30\n",
            "50/50 [==============================] - 13s 76ms/step - loss: 0.7225 - accuracy: 0.0400 - my_auc: 0.5795 - val_loss: 0.6894 - val_accuracy: 0.0042 - val_my_auc: 0.6985\n",
            " epoch:0 auc: 0.6947\n",
            "Epoch 2/30\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.7482 - accuracy: 0.3087 - my_auc: 0.6437 - val_loss: 0.6851 - val_accuracy: 0.0385 - val_my_auc: 0.7081\n",
            " epoch:1 auc: 0.6974\n",
            "Epoch 3/30\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.7009 - accuracy: 0.4549 - my_auc: 0.7045 - val_loss: 0.6776 - val_accuracy: 0.1358 - val_my_auc: 0.6959\n",
            " epoch:2 auc: 0.7014\n",
            "Epoch 4/30\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.6477 - accuracy: 0.5352 - my_auc: 0.6688 - val_loss: 0.6686 - val_accuracy: 0.2645 - val_my_auc: 0.6894\n",
            " epoch:3 auc: 0.6898\n",
            "Epoch 5/30\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.6449 - accuracy: 0.5644 - my_auc: 0.7181 - val_loss: 0.6584 - val_accuracy: 0.3809 - val_my_auc: 0.6610\n",
            " epoch:4 auc: 0.6633\n",
            "AUC:  0.6974\n",
            "8381\n",
            "avg_AUC :  0.6987649167160856\n",
            "avg_AUC_2 :  0.6990329014785537\n",
            "         0         1         2   ...        13        14        15\n",
            "0  0.586758  0.617587  0.620969  ...       NaN       NaN       NaN\n",
            "1  0.702134  0.729860  0.739451  ...       NaN       NaN       NaN\n",
            "2  0.593139  0.656589  0.691800  ...  0.730216  0.726734  0.728661\n",
            "3  0.698500  0.708132  0.695923  ...       NaN       NaN       NaN\n",
            "\n",
            "[4 rows x 16 columns]\n",
            "0     0.645133\n",
            "1     0.678042\n",
            "2     0.687036\n",
            "3     0.688854\n",
            "4     0.680576\n",
            "5     0.689932\n",
            "6     0.675765\n",
            "7     0.674715\n",
            "8     0.677464\n",
            "9     0.677901\n",
            "10    0.726831\n",
            "11    0.729508\n",
            "12    0.732128\n",
            "13    0.730216\n",
            "14    0.726734\n",
            "15    0.728661\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6987649167160856,\n",
              " array([0.        , 0.04257246, 0.08514493, 0.13768116, 0.14809783,\n",
              "        0.15851449, 0.16893116, 0.22101449, 0.25226449, 0.27309783,\n",
              "        0.29393116, 0.30480072, 0.31567029, 0.33695652, 0.33695652,\n",
              "        0.36820652, 0.38903986, 0.40987319, 0.40987319, 0.43070652,\n",
              "        0.45153986, 0.45153986, 0.47237319, 0.47237319, 0.47237319,\n",
              "        0.50407609, 0.50407609, 0.52536232, 0.54619565, 0.55706522,\n",
              "        0.55706522, 0.55706522, 0.56793478, 0.57835145, 0.59918478,\n",
              "        0.59918478, 0.62047101, 0.62047101, 0.62047101, 0.63088768,\n",
              "        0.63088768, 0.63088768, 0.64130435, 0.69519928, 0.72644928,\n",
              "        0.73686594, 0.73686594, 0.75815217, 0.77898551, 0.78940217,\n",
              "        0.78940217, 0.78940217, 0.79981884, 0.81068841, 0.82110507,\n",
              "        0.83152174, 0.8423913 , 0.85280797, 0.8745471 , 0.8745471 ,\n",
              "        0.8745471 , 0.89583333, 0.90625   , 0.90625   , 0.91666667,\n",
              "        0.91666667, 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
              "        0.92708333, 0.92708333, 0.92708333, 0.92708333, 0.92708333,\n",
              "        0.9375    , 0.95833333, 0.95833333, 0.95833333, 0.95833333,\n",
              "        0.96875   , 0.96875   , 0.96875   , 0.97916667, 0.97916667,\n",
              "        0.97916667, 0.97916667, 0.98958333, 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ]),\n",
              " [[[array([0., 0., 0., ..., 0., 0., 0.]),\n",
              "    array([0.6541683 , 0.5071074 , 0.6076111 , ..., 0.53890944, 0.28767592,\n",
              "           0.27464575], dtype=float32)],\n",
              "   array([   10,    13,    14, ..., 33519, 33523, 33525])],\n",
              "  [[array([0., 0., 0., ..., 0., 0., 0.]),\n",
              "    array([0.52685577, 0.54055256, 0.55448866, ..., 0.5032621 , 0.5290214 ,\n",
              "           0.49625987], dtype=float32)],\n",
              "   array([    3,     5,     9, ..., 33520, 33524, 33526])],\n",
              "  [[array([0., 0., 0., ..., 0., 0., 0.]),\n",
              "    array([0.5814493 , 0.5380955 , 0.63379437, ..., 0.6032916 , 0.0043495 ,\n",
              "           0.00150985], dtype=float32)],\n",
              "   array([    1,     4,     6, ..., 33515, 33521, 33522])],\n",
              "  [[array([0., 0., 0., ..., 0., 0., 0.]),\n",
              "    array([0.535789  , 0.53856117, 0.5403354 , ..., 0.5313338 , 0.5380308 ,\n",
              "           0.5146116 ], dtype=float32)],\n",
              "   array([    0,     2,     7, ..., 33510, 33511, 33513])]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "UDTUnVbkt3yz",
        "outputId": "9e3516e0-8fa2-493d-df3b-f1689a099ff1"
      },
      "source": [
        "# financial performance + overall change timestep = 3\r\n",
        "cross_val(df_fl, 'label', v_perf + v_1, 'lstm_perf', 3)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-f86838609e9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# financial performance + overall change timestep = 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcross_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_fl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'label'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_perf\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mv_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lstm_perf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: cross_val() missing 1 required positional argument: 'model_name'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjtyBoxG0bb9",
        "outputId": "a8279977-5d65-4806-c63f-d65cff18758a"
      },
      "source": [
        "cross_val(df_fl, 'label', v_perf, 'lstm_perf', 2)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "init A shape:  (45213, 29)\n",
            "(39010, 2, 14) 114.0\n",
            "Model: \"model_lstm\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 2, 14)]           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_35 (Batc (None, 2, 14)             56        \n",
            "_________________________________________________________________\n",
            "bidirectional_19 (Bidirectio (None, 2, 60)             10800     \n",
            "_________________________________________________________________\n",
            "layer_lstm_2 (LSTM)          (None, 30)                10920     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                992       \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 22,801\n",
            "Trainable params: 22,773\n",
            "Non-trainable params: 28\n",
            "_________________________________________________________________\n",
            "{0.0: 0.5014568764568764, 1.0: 172.1}\n",
            "Epoch 1/30\n",
            "58/58 [==============================] - 13s 62ms/step - loss: 0.6900 - accuracy: 0.5101 - my_auc: 0.5494 - val_loss: 0.6914 - val_accuracy: 0.5493 - val_my_auc: 0.6381\n",
            " epoch:0 auc: 0.6813\n",
            "Epoch 2/30\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.7006 - accuracy: 0.6068 - my_auc: 0.6987 - val_loss: 0.6875 - val_accuracy: 0.3975 - val_my_auc: 0.6903\n",
            " epoch:1 auc: 0.6853\n",
            "Epoch 3/30\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.6719 - accuracy: 0.6355 - my_auc: 0.6691 - val_loss: 0.6788 - val_accuracy: 0.4479 - val_my_auc: 0.6867\n",
            " epoch:2 auc: 0.6824\n",
            "Epoch 4/30\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.6693 - accuracy: 0.6373 - my_auc: 0.7013 - val_loss: 0.6635 - val_accuracy: 0.4774 - val_my_auc: 0.6873\n",
            " epoch:3 auc: 0.6861\n",
            "Epoch 5/30\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.6561 - accuracy: 0.6071 - my_auc: 0.6828 - val_loss: 0.6481 - val_accuracy: 0.5148 - val_my_auc: 0.6886\n",
            " epoch:4 auc: 0.6887\n",
            "AUC:  0.6853\n",
            "9753\n",
            "Model: \"model_lstm\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 2, 14)]           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_36 (Batc (None, 2, 14)             56        \n",
            "_________________________________________________________________\n",
            "bidirectional_20 (Bidirectio (None, 2, 60)             10800     \n",
            "_________________________________________________________________\n",
            "layer_lstm_2 (LSTM)          (None, 30)                10920     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                992       \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 22,801\n",
            "Trainable params: 22,773\n",
            "Non-trainable params: 28\n",
            "_________________________________________________________________\n",
            "{0.0: 0.5014568764568764, 1.0: 172.1}\n",
            "Epoch 1/30\n",
            "58/58 [==============================] - 12s 62ms/step - loss: 0.7145 - accuracy: 0.1254 - my_auc: 0.5350 - val_loss: 0.6913 - val_accuracy: 0.0050 - val_my_auc: 0.6499\n",
            " epoch:0 auc: 0.6271\n",
            "Epoch 2/30\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.6388 - accuracy: 0.5490 - my_auc: 0.6128 - val_loss: 0.6871 - val_accuracy: 0.0663 - val_my_auc: 0.6634\n",
            " epoch:1 auc: 0.6662\n",
            "Epoch 3/30\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.6735 - accuracy: 0.5434 - my_auc: 0.6277 - val_loss: 0.6769 - val_accuracy: 0.2230 - val_my_auc: 0.7072\n",
            " epoch:2 auc: 0.7098\n",
            "Epoch 4/30\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.6717 - accuracy: 0.5724 - my_auc: 0.7069 - val_loss: 0.6620 - val_accuracy: 0.4103 - val_my_auc: 0.7305\n",
            " epoch:3 auc: 0.7325\n",
            "Epoch 5/30\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.6459 - accuracy: 0.6287 - my_auc: 0.6941 - val_loss: 0.6396 - val_accuracy: 0.4933 - val_my_auc: 0.7442\n",
            " epoch:4 auc: 0.7459\n",
            "Epoch 6/30\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.5603 - accuracy: 0.6453 - my_auc: 0.7393 - val_loss: 0.6168 - val_accuracy: 0.5419 - val_my_auc: 0.7509\n",
            " epoch:5 auc: 0.7503\n",
            "Epoch 7/30\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.6409 - accuracy: 0.6183 - my_auc: 0.7122 - val_loss: 0.6004 - val_accuracy: 0.5973 - val_my_auc: 0.7491\n",
            " epoch:6 auc: 0.7502\n",
            "Epoch 8/30\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.5985 - accuracy: 0.6412 - my_auc: 0.7209 - val_loss: 0.5945 - val_accuracy: 0.5983 - val_my_auc: 0.7465\n",
            " epoch:7 auc: 0.7471\n",
            "Epoch 9/30\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.6252 - accuracy: 0.6288 - my_auc: 0.7166 - val_loss: 0.5913 - val_accuracy: 0.5980 - val_my_auc: 0.7456\n",
            " epoch:8 auc: 0.7461\n",
            "AUC:  0.7503\n",
            "9753\n",
            "Model: \"model_lstm\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 2, 14)]           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_37 (Batc (None, 2, 14)             56        \n",
            "_________________________________________________________________\n",
            "bidirectional_21 (Bidirectio (None, 2, 60)             10800     \n",
            "_________________________________________________________________\n",
            "layer_lstm_2 (LSTM)          (None, 30)                10920     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                992       \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 22,801\n",
            "Trainable params: 22,773\n",
            "Non-trainable params: 28\n",
            "_________________________________________________________________\n",
            "{0.0: 0.5014740161798985, 1.0: 170.1046511627907}\n",
            "Epoch 1/30\n",
            "58/58 [==============================] - 13s 63ms/step - loss: 0.7577 - accuracy: 0.3792 - my_auc: 0.5240 - val_loss: 0.6923 - val_accuracy: 0.0338 - val_my_auc: 0.5660\n",
            " epoch:0 auc: 0.5752\n",
            "Epoch 2/30\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.7333 - accuracy: 0.6142 - my_auc: 0.6338 - val_loss: 0.6897 - val_accuracy: 0.2093 - val_my_auc: 0.5832\n",
            " epoch:1 auc: 0.5946\n",
            "Epoch 3/30\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.6951 - accuracy: 0.6574 - my_auc: 0.6529 - val_loss: 0.6821 - val_accuracy: 0.3215 - val_my_auc: 0.6048\n",
            " epoch:2 auc: 0.6059\n",
            "Epoch 4/30\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.6464 - accuracy: 0.6531 - my_auc: 0.7147 - val_loss: 0.6692 - val_accuracy: 0.4606 - val_my_auc: 0.6196\n",
            " epoch:3 auc: 0.6180\n",
            "Epoch 5/30\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.6176 - accuracy: 0.6615 - my_auc: 0.7171 - val_loss: 0.6562 - val_accuracy: 0.5470 - val_my_auc: 0.6198\n",
            " epoch:4 auc: 0.6195\n",
            "Epoch 6/30\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.6011 - accuracy: 0.6589 - my_auc: 0.7122 - val_loss: 0.6536 - val_accuracy: 0.5711 - val_my_auc: 0.6177\n",
            " epoch:5 auc: 0.6179\n",
            "Epoch 7/30\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.6014 - accuracy: 0.6343 - my_auc: 0.7431 - val_loss: 0.6626 - val_accuracy: 0.5932 - val_my_auc: 0.6150\n",
            " epoch:6 auc: 0.6152\n",
            "Epoch 8/30\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.5584 - accuracy: 0.6392 - my_auc: 0.7683 - val_loss: 0.6756 - val_accuracy: 0.5877 - val_my_auc: 0.6116\n",
            " epoch:7 auc: 0.6119\n",
            "AUC:  0.6195\n",
            "9752\n",
            "Model: \"model_lstm\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 2, 14)]           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_38 (Batc (None, 2, 14)             56        \n",
            "_________________________________________________________________\n",
            "bidirectional_22 (Bidirectio (None, 2, 60)             10800     \n",
            "_________________________________________________________________\n",
            "layer_lstm_2 (LSTM)          (None, 30)                10920     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                992       \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 22,801\n",
            "Trainable params: 22,773\n",
            "Non-trainable params: 28\n",
            "_________________________________________________________________\n",
            "{0.0: 0.5014740161798985, 1.0: 170.1046511627907}\n",
            "Epoch 1/30\n",
            "58/58 [==============================] - 13s 63ms/step - loss: 0.6378 - accuracy: 0.7820 - my_auc: 0.5099 - val_loss: 0.6908 - val_accuracy: 0.2379 - val_my_auc: 0.6214\n",
            " epoch:0 auc: 0.6549\n",
            "Epoch 2/30\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.6563 - accuracy: 0.7695 - my_auc: 0.6636 - val_loss: 0.6871 - val_accuracy: 0.2534 - val_my_auc: 0.6458\n",
            " epoch:1 auc: 0.6571\n",
            "Epoch 3/30\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.6698 - accuracy: 0.6612 - my_auc: 0.6655 - val_loss: 0.6806 - val_accuracy: 0.4269 - val_my_auc: 0.6604\n",
            " epoch:2 auc: 0.6581\n",
            "Epoch 4/30\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.6456 - accuracy: 0.6839 - my_auc: 0.7409 - val_loss: 0.6686 - val_accuracy: 0.4920 - val_my_auc: 0.6640\n",
            " epoch:3 auc: 0.6621\n",
            "Epoch 5/30\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.6240 - accuracy: 0.6670 - my_auc: 0.7318 - val_loss: 0.6606 - val_accuracy: 0.5550 - val_my_auc: 0.6626\n",
            " epoch:4 auc: 0.6625\n",
            "Epoch 6/30\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.5884 - accuracy: 0.6526 - my_auc: 0.7215 - val_loss: 0.6691 - val_accuracy: 0.5865 - val_my_auc: 0.6641\n",
            " epoch:5 auc: 0.6645\n",
            "Epoch 7/30\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.6084 - accuracy: 0.6383 - my_auc: 0.7103 - val_loss: 0.6837 - val_accuracy: 0.5954 - val_my_auc: 0.6660\n",
            " epoch:6 auc: 0.6671\n",
            "Epoch 8/30\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.6079 - accuracy: 0.6145 - my_auc: 0.7007 - val_loss: 0.7069 - val_accuracy: 0.5946 - val_my_auc: 0.6705\n",
            " epoch:7 auc: 0.6703\n",
            "Epoch 9/30\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.6264 - accuracy: 0.5972 - my_auc: 0.7392 - val_loss: 0.7343 - val_accuracy: 0.5990 - val_my_auc: 0.6708\n",
            " epoch:8 auc: 0.6716\n",
            "Epoch 10/30\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.5279 - accuracy: 0.6193 - my_auc: 0.7539 - val_loss: 0.7646 - val_accuracy: 0.6097 - val_my_auc: 0.6722\n",
            " epoch:9 auc: 0.6725\n",
            "Epoch 11/30\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.5665 - accuracy: 0.6082 - my_auc: 0.6734 - val_loss: 0.7621 - val_accuracy: 0.6097 - val_my_auc: 0.6744\n",
            " epoch:10 auc: 0.6746\n",
            "Epoch 12/30\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.6624 - accuracy: 0.5982 - my_auc: 0.7235 - val_loss: 0.8020 - val_accuracy: 0.6246 - val_my_auc: 0.6773\n",
            " epoch:11 auc: 0.6778\n",
            "Epoch 13/30\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.5732 - accuracy: 0.6202 - my_auc: 0.7770 - val_loss: 0.8133 - val_accuracy: 0.6193 - val_my_auc: 0.6776\n",
            " epoch:12 auc: 0.6776\n",
            "Epoch 14/30\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.5586 - accuracy: 0.6142 - my_auc: 0.7223 - val_loss: 0.8030 - val_accuracy: 0.6013 - val_my_auc: 0.6761\n",
            " epoch:13 auc: 0.6765\n",
            "Epoch 15/30\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.6045 - accuracy: 0.5936 - my_auc: 0.7394 - val_loss: 0.8019 - val_accuracy: 0.6024 - val_my_auc: 0.6774\n",
            " epoch:14 auc: 0.6772\n",
            "Epoch 16/30\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.5934 - accuracy: 0.5888 - my_auc: 0.7784 - val_loss: 0.8154 - val_accuracy: 0.6152 - val_my_auc: 0.6780\n",
            " epoch:15 auc: 0.6784\n",
            "Epoch 17/30\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.6250 - accuracy: 0.6034 - my_auc: 0.7232 - val_loss: 0.8309 - val_accuracy: 0.6141 - val_my_auc: 0.6785\n",
            " epoch:16 auc: 0.6782\n",
            "Epoch 18/30\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.5458 - accuracy: 0.6145 - my_auc: 0.7838 - val_loss: 0.8158 - val_accuracy: 0.6019 - val_my_auc: 0.6792\n",
            " epoch:17 auc: 0.6790\n",
            "Epoch 19/30\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.5378 - accuracy: 0.5946 - my_auc: 0.7644 - val_loss: 0.8504 - val_accuracy: 0.6154 - val_my_auc: 0.6781\n",
            " epoch:18 auc: 0.6801\n",
            "Epoch 20/30\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.6044 - accuracy: 0.6069 - my_auc: 0.7648 - val_loss: 0.8541 - val_accuracy: 0.6271 - val_my_auc: 0.6792\n",
            " epoch:19 auc: 0.6807\n",
            "Epoch 21/30\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.4943 - accuracy: 0.6319 - my_auc: 0.8073 - val_loss: 0.8864 - val_accuracy: 0.6253 - val_my_auc: 0.6783\n",
            " epoch:20 auc: 0.6787\n",
            "Epoch 22/30\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.5839 - accuracy: 0.6157 - my_auc: 0.7656 - val_loss: 0.8798 - val_accuracy: 0.6259 - val_my_auc: 0.6775\n",
            " epoch:21 auc: 0.6788\n",
            "Epoch 23/30\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.6127 - accuracy: 0.6168 - my_auc: 0.7290 - val_loss: 0.8687 - val_accuracy: 0.6176 - val_my_auc: 0.6782\n",
            " epoch:22 auc: 0.6789\n",
            "AUC:  0.6807\n",
            "9752\n",
            "avg_AUC :  0.6839280141764928\n",
            "avg_AUC_2 :  0.6837059013783151\n",
            "         0         1         2   ...       20        21        22\n",
            "0  0.638114  0.690315  0.686699  ...      NaN       NaN       NaN\n",
            "1  0.649937  0.663353  0.707210  ...      NaN       NaN       NaN\n",
            "2  0.565976  0.583235  0.604816  ...      NaN       NaN       NaN\n",
            "3  0.621432  0.645834  0.660411  ...  0.67827  0.677534  0.678239\n",
            "\n",
            "[4 rows x 23 columns]\n",
            "0     0.618865\n",
            "1     0.645684\n",
            "2     0.664784\n",
            "3     0.675355\n",
            "4     0.678802\n",
            "5     0.677596\n",
            "6     0.676710\n",
            "7     0.676186\n",
            "8     0.708227\n",
            "9     0.672177\n",
            "10    0.674417\n",
            "11    0.677312\n",
            "12    0.677640\n",
            "13    0.676147\n",
            "14    0.677383\n",
            "15    0.677971\n",
            "16    0.678537\n",
            "17    0.679192\n",
            "18    0.678127\n",
            "19    0.679245\n",
            "20    0.678270\n",
            "21    0.677534\n",
            "22    0.678239\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6839280141764928,\n",
              " array([0.        , 0.06126847, 0.10498768, 0.1317734 , 0.15763547,\n",
              "        0.17549261, 0.19334975, 0.20197044, 0.21921182, 0.22814039,\n",
              "        0.24568966, 0.25431034, 0.26293103, 0.29772167, 0.29772167,\n",
              "        0.34174877, 0.35036946, 0.35899015, 0.36791872, 0.3851601 ,\n",
              "        0.44673645, 0.44673645, 0.46428571, 0.46428571, 0.4729064 ,\n",
              "        0.4729064 , 0.48152709, 0.50769704, 0.50769704, 0.52524631,\n",
              "        0.533867  , 0.54279557, 0.56034483, 0.5692734 , 0.5692734 ,\n",
              "        0.5692734 , 0.58682266, 0.59575123, 0.62222906, 0.63084975,\n",
              "        0.63084975, 0.64839901, 0.66564039, 0.68288177, 0.69150246,\n",
              "        0.70905172, 0.72660099, 0.73552956, 0.74445813, 0.74445813,\n",
              "        0.77093596, 0.80634236, 0.82389163, 0.83251232, 0.83251232,\n",
              "        0.84144089, 0.85006158, 0.85868227, 0.85868227, 0.86761084,\n",
              "        0.87653941, 0.87653941, 0.87653941, 0.87653941, 0.8851601 ,\n",
              "        0.8851601 , 0.8851601 , 0.8851601 , 0.89378079, 0.89378079,\n",
              "        0.89378079, 0.90270936, 0.90270936, 0.90270936, 0.90270936,\n",
              "        0.91163793, 0.91163793, 0.9205665 , 0.9205665 , 0.92918719,\n",
              "        0.92918719, 0.94673645, 0.9645936 , 0.9645936 , 0.97352217,\n",
              "        0.98245074, 0.99107143, 0.99107143, 0.99107143, 0.99107143,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ]),\n",
              " [[[array([0., 0., 0., ..., 0., 0., 0.]),\n",
              "    array([0.50268584, 0.50594896, 0.5095366 , ..., 0.5076364 , 0.49592113,\n",
              "           0.49382403], dtype=float32)],\n",
              "   array([   14,    15,    19, ..., 39000, 39005, 39008])],\n",
              "  [[array([0., 0., 0., ..., 0., 0., 0.]),\n",
              "    array([0.46991518, 0.514995  , 0.52383083, ..., 0.31883612, 0.5050349 ,\n",
              "           0.3472849 ], dtype=float32)],\n",
              "   array([    0,     1,     2, ..., 39004, 39006, 39009])],\n",
              "  [[array([0., 0., 0., ..., 0., 0., 0.]),\n",
              "    array([0.51859105, 0.56436455, 0.3264888 , ..., 0.4390683 , 0.4028842 ,\n",
              "           0.38534138], dtype=float32)],\n",
              "   array([    3,     7,    13, ..., 38993, 38994, 39002])],\n",
              "  [[array([0., 0., 0., ..., 0., 0., 0.]),\n",
              "    array([0.14546111, 0.660306  , 0.6060114 , ..., 0.6665233 , 0.0046927 ,\n",
              "           0.06009653], dtype=float32)],\n",
              "   array([    5,     6,     8, ..., 38996, 39003, 39007])]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTvqq2ZMt31U",
        "outputId": "887ee663-54dd-4a59-b5a0-84e7399f7df2"
      },
      "source": [
        "cross_val(df_fl, 'label', v_perf + v_1, 'lstm_perf', 2)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "init A shape:  (45213, 31)\n",
            "(39010, 2, 15) 114.0\n",
            "Model: \"model_lstm\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 2, 15)]           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 2, 15)             60        \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, 2, 62)             11656     \n",
            "_________________________________________________________________\n",
            "layer_lstm_2 (LSTM)          (None, 31)                11656     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                1024      \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 24,429\n",
            "Trainable params: 24,399\n",
            "Non-trainable params: 30\n",
            "_________________________________________________________________\n",
            "{0.0: 0.5014568764568764, 1.0: 172.1}\n",
            "Epoch 1/30\n",
            "58/58 [==============================] - 13s 63ms/step - loss: 0.7489 - accuracy: 0.4965 - my_auc: 0.4682 - val_loss: 0.6921 - val_accuracy: 0.7721 - val_my_auc: 0.5874\n",
            " epoch:0 auc: 0.6835\n",
            "Epoch 2/30\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.7241 - accuracy: 0.7547 - my_auc: 0.6337 - val_loss: 0.6901 - val_accuracy: 0.5828 - val_my_auc: 0.6471\n",
            " epoch:1 auc: 0.6685\n",
            "Epoch 3/30\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.7154 - accuracy: 0.7853 - my_auc: 0.6905 - val_loss: 0.6847 - val_accuracy: 0.6131 - val_my_auc: 0.6641\n",
            " epoch:2 auc: 0.6709\n",
            "Epoch 4/30\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.6756 - accuracy: 0.7902 - my_auc: 0.7104 - val_loss: 0.6735 - val_accuracy: 0.6569 - val_my_auc: 0.6737\n",
            " epoch:3 auc: 0.6748\n",
            "Epoch 5/30\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.6326 - accuracy: 0.7665 - my_auc: 0.7431 - val_loss: 0.6567 - val_accuracy: 0.6654 - val_my_auc: 0.6788\n",
            " epoch:4 auc: 0.6775\n",
            "Epoch 6/30\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.5757 - accuracy: 0.7491 - my_auc: 0.7343 - val_loss: 0.6422 - val_accuracy: 0.6249 - val_my_auc: 0.6821\n",
            " epoch:5 auc: 0.6816\n",
            "Epoch 7/30\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.6274 - accuracy: 0.6878 - my_auc: 0.7540 - val_loss: 0.6359 - val_accuracy: 0.6173 - val_my_auc: 0.6798\n",
            " epoch:6 auc: 0.6802\n",
            "Epoch 8/30\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.6359 - accuracy: 0.6579 - my_auc: 0.7217 - val_loss: 0.6323 - val_accuracy: 0.6129 - val_my_auc: 0.6815\n",
            " epoch:7 auc: 0.6817\n",
            "Epoch 9/30\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.6228 - accuracy: 0.6502 - my_auc: 0.7327 - val_loss: 0.6237 - val_accuracy: 0.5983 - val_my_auc: 0.6913\n",
            " epoch:8 auc: 0.6911\n",
            "Epoch 10/30\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.6502 - accuracy: 0.6255 - my_auc: 0.7248 - val_loss: 0.6201 - val_accuracy: 0.5921 - val_my_auc: 0.6959\n",
            " epoch:9 auc: 0.6954\n",
            "Epoch 11/30\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.6264 - accuracy: 0.6207 - my_auc: 0.6833 - val_loss: 0.6190 - val_accuracy: 0.5952 - val_my_auc: 0.6960\n",
            " epoch:10 auc: 0.6962\n",
            "Epoch 12/30\n",
            "58/58 [==============================] - 2s 32ms/step - loss: 0.5626 - accuracy: 0.6305 - my_auc: 0.7239 - val_loss: 0.6214 - val_accuracy: 0.6000 - val_my_auc: 0.6943\n",
            " epoch:11 auc: 0.6944\n",
            "Epoch 13/30\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.6376 - accuracy: 0.6171 - my_auc: 0.7430 - val_loss: 0.6185 - val_accuracy: 0.6035 - val_my_auc: 0.6972\n",
            " epoch:12 auc: 0.6970\n",
            "Epoch 14/30\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.6174 - accuracy: 0.6328 - my_auc: 0.7342 - val_loss: 0.6220 - val_accuracy: 0.6123 - val_my_auc: 0.6945\n",
            " epoch:13 auc: 0.6947\n",
            "Epoch 15/30\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.5473 - accuracy: 0.6527 - my_auc: 0.7648 - val_loss: 0.6273 - val_accuracy: 0.6144 - val_my_auc: 0.6932\n",
            " epoch:14 auc: 0.6930\n",
            "Epoch 16/30\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.5221 - accuracy: 0.6550 - my_auc: 0.8011 - val_loss: 0.6361 - val_accuracy: 0.6315 - val_my_auc: 0.6899\n",
            " epoch:15 auc: 0.6897\n",
            "AUC:  0.697\n",
            "9753\n",
            "Model: \"model_lstm\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 2, 15)]           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 2, 15)             60        \n",
            "_________________________________________________________________\n",
            "bidirectional_5 (Bidirection (None, 2, 62)             11656     \n",
            "_________________________________________________________________\n",
            "layer_lstm_2 (LSTM)          (None, 31)                11656     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                1024      \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 24,429\n",
            "Trainable params: 24,399\n",
            "Non-trainable params: 30\n",
            "_________________________________________________________________\n",
            "{0.0: 0.5014568764568764, 1.0: 172.1}\n",
            "Epoch 1/30\n",
            "58/58 [==============================] - 12s 63ms/step - loss: 0.7219 - accuracy: 0.3577 - my_auc: 0.4886 - val_loss: 0.6912 - val_accuracy: 0.4189 - val_my_auc: 0.6208\n",
            " epoch:0 auc: 0.6409\n",
            "Epoch 2/30\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.6731 - accuracy: 0.6460 - my_auc: 0.6660 - val_loss: 0.6853 - val_accuracy: 0.4970 - val_my_auc: 0.7073\n",
            " epoch:1 auc: 0.7085\n",
            "Epoch 3/30\n",
            "58/58 [==============================] - 2s 32ms/step - loss: 0.6992 - accuracy: 0.6354 - my_auc: 0.6863 - val_loss: 0.6758 - val_accuracy: 0.6017 - val_my_auc: 0.7080\n",
            " epoch:2 auc: 0.7069\n",
            "Epoch 4/30\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.6858 - accuracy: 0.6514 - my_auc: 0.7166 - val_loss: 0.6618 - val_accuracy: 0.6459 - val_my_auc: 0.7180\n",
            " epoch:3 auc: 0.7202\n",
            "Epoch 5/30\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.6769 - accuracy: 0.6751 - my_auc: 0.6903 - val_loss: 0.6427 - val_accuracy: 0.6587 - val_my_auc: 0.7350\n",
            " epoch:4 auc: 0.7347\n",
            "Epoch 6/30\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.6390 - accuracy: 0.6718 - my_auc: 0.7059 - val_loss: 0.6251 - val_accuracy: 0.6627 - val_my_auc: 0.7377\n",
            " epoch:5 auc: 0.7387\n",
            "Epoch 7/30\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.6441 - accuracy: 0.6620 - my_auc: 0.7156 - val_loss: 0.6094 - val_accuracy: 0.6666 - val_my_auc: 0.7460\n",
            " epoch:6 auc: 0.7462\n",
            "Epoch 8/30\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.6682 - accuracy: 0.6579 - my_auc: 0.7363 - val_loss: 0.6001 - val_accuracy: 0.6736 - val_my_auc: 0.7534\n",
            " epoch:7 auc: 0.7530\n",
            "Epoch 9/30\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.7500 - accuracy: 0.6608 - my_auc: 0.6901 - val_loss: 0.5981 - val_accuracy: 0.6989 - val_my_auc: 0.7533\n",
            " epoch:8 auc: 0.7530\n",
            "Epoch 10/30\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.6509 - accuracy: 0.6896 - my_auc: 0.6876 - val_loss: 0.5942 - val_accuracy: 0.6856 - val_my_auc: 0.7567\n",
            " epoch:9 auc: 0.7564\n",
            "Epoch 11/30\n",
            "58/58 [==============================] - 2s 32ms/step - loss: 0.5907 - accuracy: 0.6903 - my_auc: 0.7240 - val_loss: 0.5969 - val_accuracy: 0.6821 - val_my_auc: 0.7585\n",
            " epoch:10 auc: 0.7584\n",
            "Epoch 12/30\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.6122 - accuracy: 0.6825 - my_auc: 0.7230 - val_loss: 0.5969 - val_accuracy: 0.6539 - val_my_auc: 0.7605\n",
            " epoch:11 auc: 0.7603\n",
            "Epoch 13/30\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.5930 - accuracy: 0.6610 - my_auc: 0.7299 - val_loss: 0.6004 - val_accuracy: 0.6798 - val_my_auc: 0.7597\n",
            " epoch:12 auc: 0.7598\n",
            "Epoch 14/30\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.6068 - accuracy: 0.6836 - my_auc: 0.7125 - val_loss: 0.6079 - val_accuracy: 0.7056 - val_my_auc: 0.7610\n",
            " epoch:13 auc: 0.7604\n",
            "Epoch 15/30\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.6133 - accuracy: 0.6985 - my_auc: 0.7435 - val_loss: 0.6087 - val_accuracy: 0.6960 - val_my_auc: 0.7576\n",
            " epoch:14 auc: 0.7576\n",
            "Epoch 16/30\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.5615 - accuracy: 0.7014 - my_auc: 0.7645 - val_loss: 0.6118 - val_accuracy: 0.6857 - val_my_auc: 0.7525\n",
            " epoch:15 auc: 0.7517\n",
            "Epoch 17/30\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.5723 - accuracy: 0.6888 - my_auc: 0.7658 - val_loss: 0.6194 - val_accuracy: 0.7110 - val_my_auc: 0.7527\n",
            " epoch:16 auc: 0.7520\n",
            "AUC:  0.7604\n",
            "9753\n",
            "Model: \"model_lstm\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 2, 15)]           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 2, 15)             60        \n",
            "_________________________________________________________________\n",
            "bidirectional_6 (Bidirection (None, 2, 62)             11656     \n",
            "_________________________________________________________________\n",
            "layer_lstm_2 (LSTM)          (None, 31)                11656     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                1024      \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 24,429\n",
            "Trainable params: 24,399\n",
            "Non-trainable params: 30\n",
            "_________________________________________________________________\n",
            "{0.0: 0.5014740161798985, 1.0: 170.1046511627907}\n",
            "Epoch 1/30\n",
            "58/58 [==============================] - 13s 75ms/step - loss: 0.6892 - accuracy: 0.5966 - my_auc: 0.5679 - val_loss: 0.6915 - val_accuracy: 0.6087 - val_my_auc: 0.6298\n",
            " epoch:0 auc: 0.6207\n",
            "Epoch 2/30\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.6765 - accuracy: 0.8536 - my_auc: 0.6303 - val_loss: 0.6881 - val_accuracy: 0.8074 - val_my_auc: 0.6656\n",
            " epoch:1 auc: 0.6691\n",
            "Epoch 3/30\n",
            "58/58 [==============================] - 2s 32ms/step - loss: 0.6594 - accuracy: 0.8631 - my_auc: 0.7187 - val_loss: 0.6807 - val_accuracy: 0.7554 - val_my_auc: 0.6645\n",
            " epoch:2 auc: 0.6646\n",
            "Epoch 4/30\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.7142 - accuracy: 0.7935 - my_auc: 0.7246 - val_loss: 0.6699 - val_accuracy: 0.7298 - val_my_auc: 0.6647\n",
            " epoch:3 auc: 0.6618\n",
            "Epoch 5/30\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.6488 - accuracy: 0.7962 - my_auc: 0.7588 - val_loss: 0.6575 - val_accuracy: 0.6959 - val_my_auc: 0.6635\n",
            " epoch:4 auc: 0.6631\n",
            "AUC:  0.6691\n",
            "9752\n",
            "Model: \"model_lstm\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 2, 15)]           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 2, 15)             60        \n",
            "_________________________________________________________________\n",
            "bidirectional_7 (Bidirection (None, 2, 62)             11656     \n",
            "_________________________________________________________________\n",
            "layer_lstm_2 (LSTM)          (None, 31)                11656     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                1024      \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 24,429\n",
            "Trainable params: 24,399\n",
            "Non-trainable params: 30\n",
            "_________________________________________________________________\n",
            "{0.0: 0.5014740161798985, 1.0: 170.1046511627907}\n",
            "Epoch 1/30\n",
            "58/58 [==============================] - 13s 75ms/step - loss: 0.6928 - accuracy: 0.6089 - my_auc: 0.5769 - val_loss: 0.6911 - val_accuracy: 0.4080 - val_my_auc: 0.5771\n",
            " epoch:0 auc: 0.6154\n",
            "Epoch 2/30\n",
            "58/58 [==============================] - 2s 32ms/step - loss: 0.6525 - accuracy: 0.7909 - my_auc: 0.6292 - val_loss: 0.6872 - val_accuracy: 0.3939 - val_my_auc: 0.6456\n",
            " epoch:1 auc: 0.6390\n",
            "Epoch 3/30\n",
            "58/58 [==============================] - 2s 32ms/step - loss: 0.7178 - accuracy: 0.6885 - my_auc: 0.6879 - val_loss: 0.6787 - val_accuracy: 0.5836 - val_my_auc: 0.6570\n",
            " epoch:2 auc: 0.6558\n",
            "Epoch 4/30\n",
            "58/58 [==============================] - 2s 32ms/step - loss: 0.6272 - accuracy: 0.7695 - my_auc: 0.7680 - val_loss: 0.6674 - val_accuracy: 0.6113 - val_my_auc: 0.6661\n",
            " epoch:3 auc: 0.6662\n",
            "Epoch 5/30\n",
            "58/58 [==============================] - 2s 33ms/step - loss: 0.6762 - accuracy: 0.6947 - my_auc: 0.7408 - val_loss: 0.6608 - val_accuracy: 0.6178 - val_my_auc: 0.6744\n",
            " epoch:4 auc: 0.6743\n",
            "Epoch 6/30\n",
            "58/58 [==============================] - 2s 32ms/step - loss: 0.6311 - accuracy: 0.6790 - my_auc: 0.7409 - val_loss: 0.6634 - val_accuracy: 0.6021 - val_my_auc: 0.6807\n",
            " epoch:5 auc: 0.6806\n",
            "Epoch 7/30\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.5469 - accuracy: 0.6672 - my_auc: 0.7112 - val_loss: 0.6649 - val_accuracy: 0.5842 - val_my_auc: 0.6842\n",
            " epoch:6 auc: 0.6854\n",
            "Epoch 8/30\n",
            "58/58 [==============================] - 2s 32ms/step - loss: 0.5342 - accuracy: 0.6302 - my_auc: 0.7647 - val_loss: 0.6703 - val_accuracy: 0.5819 - val_my_auc: 0.6897\n",
            " epoch:7 auc: 0.6890\n",
            "Epoch 9/30\n",
            "58/58 [==============================] - 2s 32ms/step - loss: 0.5255 - accuracy: 0.6225 - my_auc: 0.7930 - val_loss: 0.6896 - val_accuracy: 0.6029 - val_my_auc: 0.6947\n",
            " epoch:8 auc: 0.6946\n",
            "Epoch 10/30\n",
            "58/58 [==============================] - 2s 32ms/step - loss: 0.5841 - accuracy: 0.6189 - my_auc: 0.7735 - val_loss: 0.7022 - val_accuracy: 0.6056 - val_my_auc: 0.6977\n",
            " epoch:9 auc: 0.6970\n",
            "Epoch 11/30\n",
            "58/58 [==============================] - 2s 32ms/step - loss: 0.6528 - accuracy: 0.6029 - my_auc: 0.7555 - val_loss: 0.7065 - val_accuracy: 0.6122 - val_my_auc: 0.6985\n",
            " epoch:10 auc: 0.6989\n",
            "Epoch 12/30\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.5789 - accuracy: 0.6099 - my_auc: 0.7443 - val_loss: 0.7196 - val_accuracy: 0.6141 - val_my_auc: 0.6997\n",
            " epoch:11 auc: 0.6998\n",
            "Epoch 13/30\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.6050 - accuracy: 0.6097 - my_auc: 0.7332 - val_loss: 0.7237 - val_accuracy: 0.6086 - val_my_auc: 0.6993\n",
            " epoch:12 auc: 0.6992\n",
            "Epoch 14/30\n",
            "58/58 [==============================] - 2s 32ms/step - loss: 0.6046 - accuracy: 0.6026 - my_auc: 0.7443 - val_loss: 0.7392 - val_accuracy: 0.6155 - val_my_auc: 0.6986\n",
            " epoch:13 auc: 0.6993\n",
            "Epoch 15/30\n",
            "58/58 [==============================] - 2s 32ms/step - loss: 0.5502 - accuracy: 0.6156 - my_auc: 0.7786 - val_loss: 0.7651 - val_accuracy: 0.6180 - val_my_auc: 0.7002\n",
            " epoch:14 auc: 0.7005\n",
            "Epoch 16/30\n",
            "58/58 [==============================] - 2s 32ms/step - loss: 0.5724 - accuracy: 0.6174 - my_auc: 0.7187 - val_loss: 0.7507 - val_accuracy: 0.6160 - val_my_auc: 0.7011\n",
            " epoch:15 auc: 0.7007\n",
            "Epoch 17/30\n",
            "58/58 [==============================] - 2s 32ms/step - loss: 0.5479 - accuracy: 0.6181 - my_auc: 0.7686 - val_loss: 0.7473 - val_accuracy: 0.6135 - val_my_auc: 0.6997\n",
            " epoch:16 auc: 0.7003\n",
            "Epoch 18/30\n",
            "58/58 [==============================] - 2s 32ms/step - loss: 0.6063 - accuracy: 0.6001 - my_auc: 0.7512 - val_loss: 0.7364 - val_accuracy: 0.6130 - val_my_auc: 0.7006\n",
            " epoch:17 auc: 0.7008\n",
            "Epoch 19/30\n",
            "58/58 [==============================] - 2s 32ms/step - loss: 0.5577 - accuracy: 0.6154 - my_auc: 0.8095 - val_loss: 0.7587 - val_accuracy: 0.6303 - val_my_auc: 0.7005\n",
            " epoch:18 auc: 0.7011\n",
            "AUC:  0.7007\n",
            "9752\n",
            "avg_AUC :  0.7068131855467048\n",
            "avg_AUC_2 :  0.7064207344379758\n",
            "         0         1         2   ...        16        17        18\n",
            "0  0.587379  0.647105  0.664139  ...       NaN       NaN       NaN\n",
            "1  0.620768  0.707301  0.708030  ...  0.752725       NaN       NaN\n",
            "2  0.629797  0.665597  0.664519  ...       NaN       NaN       NaN\n",
            "3  0.577092  0.645645  0.657036  ...  0.699677  0.700628  0.700454\n",
            "\n",
            "[4 rows x 19 columns]\n",
            "0     0.603759\n",
            "1     0.666412\n",
            "2     0.673431\n",
            "3     0.680626\n",
            "4     0.687917\n",
            "5     0.700166\n",
            "6     0.703348\n",
            "7     0.708206\n",
            "8     0.713084\n",
            "9     0.716763\n",
            "10    0.717690\n",
            "11    0.718177\n",
            "12    0.718772\n",
            "13    0.718016\n",
            "14    0.717017\n",
            "15    0.714501\n",
            "16    0.726201\n",
            "17    0.700628\n",
            "18    0.700454\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7068131855467048,\n",
              " array([0.        , 0.07081281, 0.08805419, 0.13208128, 0.15825123,\n",
              "        0.19334975, 0.23676108, 0.27155172, 0.30665025, 0.32419951,\n",
              "        0.34174877, 0.34174877, 0.36761084, 0.39439655, 0.39439655,\n",
              "        0.39439655, 0.42025862, 0.42025862, 0.42025862, 0.43780788,\n",
              "        0.46397783, 0.48183498, 0.48183498, 0.50800493, 0.50800493,\n",
              "        0.53479064, 0.53479064, 0.54341133, 0.5523399 , 0.56988916,\n",
              "        0.58743842, 0.60529557, 0.60529557, 0.63115764, 0.63977833,\n",
              "        0.6487069 , 0.65763547, 0.65763547, 0.66625616, 0.68380542,\n",
              "        0.68380542, 0.68380542, 0.69242611, 0.7010468 , 0.71859606,\n",
              "        0.71859606, 0.72721675, 0.75369458, 0.77124384, 0.78017241,\n",
              "        0.7887931 , 0.79772167, 0.79772167, 0.79772167, 0.83251232,\n",
              "        0.83251232, 0.83251232, 0.84144089, 0.84144089, 0.84144089,\n",
              "        0.84144089, 0.84144089, 0.85929803, 0.85929803, 0.85929803,\n",
              "        0.88546798, 0.89408867, 0.89408867, 0.91163793, 0.91163793,\n",
              "        0.91163793, 0.91163793, 0.91163793, 0.92918719, 0.92918719,\n",
              "        0.93811576, 0.93811576, 0.94704433, 0.94704433, 0.94704433,\n",
              "        0.94704433, 0.94704433, 0.95597291, 0.95597291, 0.96490148,\n",
              "        0.96490148, 0.96490148, 0.98245074, 0.99107143, 0.99107143,\n",
              "        0.99107143, 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ]),\n",
              " [[[array([0., 0., 0., ..., 0., 0., 0.]),\n",
              "    array([0.42087275, 0.5536633 , 0.6055979 , ..., 0.48724842, 0.465036  ,\n",
              "           0.11957189], dtype=float32)],\n",
              "   array([   14,    15,    19, ..., 39000, 39005, 39008])],\n",
              "  [[array([0., 0., 0., ..., 0., 0., 0.]),\n",
              "    array([0.30877963, 0.5259157 , 0.55774236, ..., 0.14053157, 0.40415514,\n",
              "           0.05034238], dtype=float32)],\n",
              "   array([    0,     1,     2, ..., 39004, 39006, 39009])],\n",
              "  [[array([0., 0., 0., ..., 0., 0., 0.]),\n",
              "    array([0.49642098, 0.50365573, 0.49342918, ..., 0.48504075, 0.4854276 ,\n",
              "           0.48131058], dtype=float32)],\n",
              "   array([    3,     7,    13, ..., 38993, 38994, 39002])],\n",
              "  [[array([0., 0., 0., ..., 0., 0., 0.]),\n",
              "    array([0.33117354, 0.61027956, 0.56279093, ..., 0.6803953 , 0.0111877 ,\n",
              "           0.12130514], dtype=float32)],\n",
              "   array([    5,     6,     8, ..., 38996, 39003, 39007])]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DR61cb4Rt33i",
        "outputId": "f1d3eb75-636c-4ee6-8883-daed7d7c1459"
      },
      "source": [
        "cross_val(df_fl, 'label', v_perf + v_1, 'lstm_perf', 1)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "init A shape:  (45213, 16)\n",
            "(45213, 1, 15) 179.0\n",
            "Model: \"model_lstm\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 1, 15)]           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 1, 15)             60        \n",
            "_________________________________________________________________\n",
            "bidirectional_11 (Bidirectio (None, 1, 62)             11656     \n",
            "_________________________________________________________________\n",
            "layer_lstm_2 (LSTM)          (None, 31)                11656     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                1024      \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 24,429\n",
            "Trainable params: 24,399\n",
            "Non-trainable params: 30\n",
            "_________________________________________________________________\n",
            "{0.0: 0.5019837157660992, 1.0: 126.52611940298507}\n",
            "Epoch 1/30\n",
            "67/67 [==============================] - 12s 48ms/step - loss: 0.7166 - accuracy: 0.3538 - my_auc: 0.5282 - val_loss: 0.6919 - val_accuracy: 0.3207 - val_my_auc: 0.5699\n",
            " epoch:0 auc: 0.6891\n",
            "Epoch 2/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.7512 - accuracy: 0.5758 - my_auc: 0.5578 - val_loss: 0.6898 - val_accuracy: 0.5266 - val_my_auc: 0.6646\n",
            " epoch:1 auc: 0.7068\n",
            "Epoch 3/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.6523 - accuracy: 0.7981 - my_auc: 0.6612 - val_loss: 0.6847 - val_accuracy: 0.4928 - val_my_auc: 0.7206\n",
            " epoch:2 auc: 0.7277\n",
            "Epoch 4/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.6613 - accuracy: 0.6837 - my_auc: 0.6338 - val_loss: 0.6754 - val_accuracy: 0.5289 - val_my_auc: 0.7281\n",
            " epoch:3 auc: 0.7292\n",
            "Epoch 5/30\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 0.6486 - accuracy: 0.6487 - my_auc: 0.6787 - val_loss: 0.6621 - val_accuracy: 0.5823 - val_my_auc: 0.7320\n",
            " epoch:4 auc: 0.7345\n",
            "Epoch 6/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.6901 - accuracy: 0.6245 - my_auc: 0.6164 - val_loss: 0.6488 - val_accuracy: 0.5967 - val_my_auc: 0.7418\n",
            " epoch:5 auc: 0.7424\n",
            "Epoch 7/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.6714 - accuracy: 0.6133 - my_auc: 0.6905 - val_loss: 0.6333 - val_accuracy: 0.6246 - val_my_auc: 0.7436\n",
            " epoch:6 auc: 0.7442\n",
            "Epoch 8/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.6964 - accuracy: 0.6076 - my_auc: 0.6777 - val_loss: 0.6213 - val_accuracy: 0.6537 - val_my_auc: 0.7483\n",
            " epoch:7 auc: 0.7492\n",
            "Epoch 9/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.6579 - accuracy: 0.6399 - my_auc: 0.7056 - val_loss: 0.6122 - val_accuracy: 0.6531 - val_my_auc: 0.7520\n",
            " epoch:8 auc: 0.7523\n",
            "Epoch 10/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.6079 - accuracy: 0.6554 - my_auc: 0.6837 - val_loss: 0.6024 - val_accuracy: 0.6419 - val_my_auc: 0.7547\n",
            " epoch:9 auc: 0.7547\n",
            "Epoch 11/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.6118 - accuracy: 0.6382 - my_auc: 0.7412 - val_loss: 0.5992 - val_accuracy: 0.6474 - val_my_auc: 0.7534\n",
            " epoch:10 auc: 0.7538\n",
            "Epoch 12/30\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 0.6758 - accuracy: 0.6321 - my_auc: 0.6765 - val_loss: 0.5966 - val_accuracy: 0.6624 - val_my_auc: 0.7551\n",
            " epoch:11 auc: 0.7550\n",
            "Epoch 13/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.6281 - accuracy: 0.6531 - my_auc: 0.7109 - val_loss: 0.5917 - val_accuracy: 0.6594 - val_my_auc: 0.7594\n",
            " epoch:12 auc: 0.7590\n",
            "Epoch 14/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.6140 - accuracy: 0.6585 - my_auc: 0.6870 - val_loss: 0.5886 - val_accuracy: 0.6538 - val_my_auc: 0.7603\n",
            " epoch:13 auc: 0.7601\n",
            "Epoch 15/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.6112 - accuracy: 0.6493 - my_auc: 0.7169 - val_loss: 0.5883 - val_accuracy: 0.6579 - val_my_auc: 0.7602\n",
            " epoch:14 auc: 0.7601\n",
            "Epoch 16/30\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 0.6029 - accuracy: 0.6588 - my_auc: 0.7464 - val_loss: 0.5880 - val_accuracy: 0.6569 - val_my_auc: 0.7581\n",
            " epoch:15 auc: 0.7585\n",
            "Epoch 17/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.6862 - accuracy: 0.6396 - my_auc: 0.6976 - val_loss: 0.5892 - val_accuracy: 0.6699 - val_my_auc: 0.7556\n",
            " epoch:16 auc: 0.7554\n",
            "AUC:  0.7601\n",
            "11304\n",
            "Model: \"model_lstm\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 1, 15)]           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 1, 15)             60        \n",
            "_________________________________________________________________\n",
            "bidirectional_12 (Bidirectio (None, 1, 62)             11656     \n",
            "_________________________________________________________________\n",
            "layer_lstm_2 (LSTM)          (None, 31)                11656     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                1024      \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 24,429\n",
            "Trainable params: 24,399\n",
            "Non-trainable params: 30\n",
            "_________________________________________________________________\n",
            "{0.0: 0.5019985196150999, 1.0: 125.5925925925926}\n",
            "Epoch 1/30\n",
            "67/67 [==============================] - 12s 48ms/step - loss: 0.7194 - accuracy: 0.7208 - my_auc: 0.5668 - val_loss: 0.6921 - val_accuracy: 0.5948 - val_my_auc: 0.5458\n",
            " epoch:0 auc: 0.6619\n",
            "Epoch 2/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.6315 - accuracy: 0.9230 - my_auc: 0.6298 - val_loss: 0.6889 - val_accuracy: 0.3625 - val_my_auc: 0.6575\n",
            " epoch:1 auc: 0.6859\n",
            "Epoch 3/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.6314 - accuracy: 0.7773 - my_auc: 0.6931 - val_loss: 0.6823 - val_accuracy: 0.5125 - val_my_auc: 0.6894\n",
            " epoch:2 auc: 0.6897\n",
            "Epoch 4/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.6564 - accuracy: 0.7049 - my_auc: 0.6897 - val_loss: 0.6720 - val_accuracy: 0.5384 - val_my_auc: 0.6893\n",
            " epoch:3 auc: 0.6895\n",
            "Epoch 5/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.6172 - accuracy: 0.6837 - my_auc: 0.7237 - val_loss: 0.6582 - val_accuracy: 0.5905 - val_my_auc: 0.6948\n",
            " epoch:4 auc: 0.6932\n",
            "Epoch 6/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.6589 - accuracy: 0.6416 - my_auc: 0.7000 - val_loss: 0.6479 - val_accuracy: 0.6150 - val_my_auc: 0.6979\n",
            " epoch:5 auc: 0.6991\n",
            "Epoch 7/30\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 0.6564 - accuracy: 0.6434 - my_auc: 0.7164 - val_loss: 0.6394 - val_accuracy: 0.6241 - val_my_auc: 0.7053\n",
            " epoch:6 auc: 0.7057\n",
            "Epoch 8/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.6064 - accuracy: 0.6436 - my_auc: 0.7069 - val_loss: 0.6345 - val_accuracy: 0.6335 - val_my_auc: 0.7092\n",
            " epoch:7 auc: 0.7092\n",
            "Epoch 9/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.6842 - accuracy: 0.6253 - my_auc: 0.7023 - val_loss: 0.6330 - val_accuracy: 0.6418 - val_my_auc: 0.7124\n",
            " epoch:8 auc: 0.7131\n",
            "Epoch 10/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.6266 - accuracy: 0.6433 - my_auc: 0.6786 - val_loss: 0.6296 - val_accuracy: 0.6210 - val_my_auc: 0.7179\n",
            " epoch:9 auc: 0.7180\n",
            "Epoch 11/30\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 0.6323 - accuracy: 0.6140 - my_auc: 0.7094 - val_loss: 0.6283 - val_accuracy: 0.6213 - val_my_auc: 0.7201\n",
            " epoch:10 auc: 0.7204\n",
            "Epoch 12/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.6026 - accuracy: 0.6181 - my_auc: 0.7007 - val_loss: 0.6279 - val_accuracy: 0.6297 - val_my_auc: 0.7229\n",
            " epoch:11 auc: 0.7229\n",
            "Epoch 13/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.5892 - accuracy: 0.6308 - my_auc: 0.7195 - val_loss: 0.6295 - val_accuracy: 0.6276 - val_my_auc: 0.7231\n",
            " epoch:12 auc: 0.7232\n",
            "Epoch 14/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.6067 - accuracy: 0.6227 - my_auc: 0.7319 - val_loss: 0.6318 - val_accuracy: 0.6380 - val_my_auc: 0.7247\n",
            " epoch:13 auc: 0.7246\n",
            "Epoch 15/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.6175 - accuracy: 0.6271 - my_auc: 0.7033 - val_loss: 0.6361 - val_accuracy: 0.6492 - val_my_auc: 0.7252\n",
            " epoch:14 auc: 0.7252\n",
            "Epoch 16/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.6152 - accuracy: 0.6492 - my_auc: 0.7250 - val_loss: 0.6349 - val_accuracy: 0.6400 - val_my_auc: 0.7248\n",
            " epoch:15 auc: 0.7252\n",
            "Epoch 17/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.5531 - accuracy: 0.6446 - my_auc: 0.7767 - val_loss: 0.6389 - val_accuracy: 0.6340 - val_my_auc: 0.7250\n",
            " epoch:16 auc: 0.7252\n",
            "Epoch 18/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.6222 - accuracy: 0.6222 - my_auc: 0.7206 - val_loss: 0.6384 - val_accuracy: 0.6447 - val_my_auc: 0.7264\n",
            " epoch:17 auc: 0.7263\n",
            "Epoch 19/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.5965 - accuracy: 0.6401 - my_auc: 0.7502 - val_loss: 0.6380 - val_accuracy: 0.6458 - val_my_auc: 0.7263\n",
            " epoch:18 auc: 0.7261\n",
            "Epoch 20/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.6659 - accuracy: 0.6279 - my_auc: 0.6783 - val_loss: 0.6417 - val_accuracy: 0.6579 - val_my_auc: 0.7255\n",
            " epoch:19 auc: 0.7254\n",
            "Epoch 21/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.6562 - accuracy: 0.6411 - my_auc: 0.7207 - val_loss: 0.6341 - val_accuracy: 0.6403 - val_my_auc: 0.7261\n",
            " epoch:20 auc: 0.7264\n",
            "AUC:  0.7263\n",
            "11303\n",
            "Model: \"model_lstm\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 1, 15)]           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 1, 15)             60        \n",
            "_________________________________________________________________\n",
            "bidirectional_13 (Bidirectio (None, 1, 62)             11656     \n",
            "_________________________________________________________________\n",
            "layer_lstm_2 (LSTM)          (None, 31)                11656     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                1024      \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 24,429\n",
            "Trainable params: 24,399\n",
            "Non-trainable params: 30\n",
            "_________________________________________________________________\n",
            "{0.0: 0.5019836570345808, 1.0: 126.52985074626865}\n",
            "Epoch 1/30\n",
            "67/67 [==============================] - 12s 49ms/step - loss: 0.7301 - accuracy: 0.2549 - my_auc: 0.5741 - val_loss: 0.6921 - val_accuracy: 0.2928 - val_my_auc: 0.5701\n",
            " epoch:0 auc: 0.6137\n",
            "Epoch 2/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.7162 - accuracy: 0.5704 - my_auc: 0.6679 - val_loss: 0.6895 - val_accuracy: 0.7073 - val_my_auc: 0.6407\n",
            " epoch:1 auc: 0.6457\n",
            "Epoch 3/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.6682 - accuracy: 0.7506 - my_auc: 0.7374 - val_loss: 0.6832 - val_accuracy: 0.6469 - val_my_auc: 0.6487\n",
            " epoch:2 auc: 0.6507\n",
            "Epoch 4/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.6813 - accuracy: 0.6936 - my_auc: 0.6758 - val_loss: 0.6743 - val_accuracy: 0.6701 - val_my_auc: 0.6505\n",
            " epoch:3 auc: 0.6511\n",
            "Epoch 5/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.6789 - accuracy: 0.6719 - my_auc: 0.7195 - val_loss: 0.6666 - val_accuracy: 0.6768 - val_my_auc: 0.6526\n",
            " epoch:4 auc: 0.6516\n",
            "Epoch 6/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.6484 - accuracy: 0.6644 - my_auc: 0.7336 - val_loss: 0.6614 - val_accuracy: 0.6689 - val_my_auc: 0.6581\n",
            " epoch:5 auc: 0.6576\n",
            "Epoch 7/30\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 0.6208 - accuracy: 0.6499 - my_auc: 0.7343 - val_loss: 0.6637 - val_accuracy: 0.6635 - val_my_auc: 0.6605\n",
            " epoch:6 auc: 0.6602\n",
            "Epoch 8/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.6051 - accuracy: 0.6488 - my_auc: 0.7428 - val_loss: 0.6731 - val_accuracy: 0.6511 - val_my_auc: 0.6605\n",
            " epoch:7 auc: 0.6605\n",
            "Epoch 9/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.6065 - accuracy: 0.6330 - my_auc: 0.6951 - val_loss: 0.6857 - val_accuracy: 0.6392 - val_my_auc: 0.6612\n",
            " epoch:8 auc: 0.6614\n",
            "Epoch 10/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.6149 - accuracy: 0.6191 - my_auc: 0.7288 - val_loss: 0.6914 - val_accuracy: 0.6451 - val_my_auc: 0.6619\n",
            " epoch:9 auc: 0.6620\n",
            "Epoch 11/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.5653 - accuracy: 0.6372 - my_auc: 0.7187 - val_loss: 0.6932 - val_accuracy: 0.6447 - val_my_auc: 0.6639\n",
            " epoch:10 auc: 0.6637\n",
            "Epoch 12/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.5912 - accuracy: 0.6298 - my_auc: 0.7534 - val_loss: 0.6945 - val_accuracy: 0.6513 - val_my_auc: 0.6674\n",
            " epoch:11 auc: 0.6674\n",
            "Epoch 13/30\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 0.6528 - accuracy: 0.6278 - my_auc: 0.7084 - val_loss: 0.6988 - val_accuracy: 0.6624 - val_my_auc: 0.6685\n",
            " epoch:12 auc: 0.6690\n",
            "Epoch 14/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.5953 - accuracy: 0.6484 - my_auc: 0.7431 - val_loss: 0.6943 - val_accuracy: 0.6394 - val_my_auc: 0.6683\n",
            " epoch:13 auc: 0.6686\n",
            "Epoch 15/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.5899 - accuracy: 0.6281 - my_auc: 0.7552 - val_loss: 0.7013 - val_accuracy: 0.6473 - val_my_auc: 0.6718\n",
            " epoch:14 auc: 0.6717\n",
            "Epoch 16/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.6380 - accuracy: 0.6213 - my_auc: 0.7472 - val_loss: 0.7065 - val_accuracy: 0.6483 - val_my_auc: 0.6722\n",
            " epoch:15 auc: 0.6729\n",
            "Epoch 17/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.5969 - accuracy: 0.6318 - my_auc: 0.7350 - val_loss: 0.7025 - val_accuracy: 0.6355 - val_my_auc: 0.6709\n",
            " epoch:16 auc: 0.6710\n",
            "Epoch 18/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.6260 - accuracy: 0.6144 - my_auc: 0.7311 - val_loss: 0.7049 - val_accuracy: 0.6322 - val_my_auc: 0.6724\n",
            " epoch:17 auc: 0.6723\n",
            "Epoch 19/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.5811 - accuracy: 0.6201 - my_auc: 0.7500 - val_loss: 0.6994 - val_accuracy: 0.6297 - val_my_auc: 0.6725\n",
            " epoch:18 auc: 0.6728\n",
            "Epoch 20/30\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 0.6054 - accuracy: 0.6134 - my_auc: 0.7214 - val_loss: 0.6983 - val_accuracy: 0.6485 - val_my_auc: 0.6746\n",
            " epoch:19 auc: 0.6750\n",
            "Epoch 21/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.6764 - accuracy: 0.6205 - my_auc: 0.7238 - val_loss: 0.7051 - val_accuracy: 0.6544 - val_my_auc: 0.6735\n",
            " epoch:20 auc: 0.6734\n",
            "Epoch 22/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.6370 - accuracy: 0.6360 - my_auc: 0.7547 - val_loss: 0.6996 - val_accuracy: 0.6542 - val_my_auc: 0.6748\n",
            " epoch:21 auc: 0.6748\n",
            "Epoch 23/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.5681 - accuracy: 0.6388 - my_auc: 0.7514 - val_loss: 0.7171 - val_accuracy: 0.6453 - val_my_auc: 0.6719\n",
            " epoch:22 auc: 0.6719\n",
            "Epoch 24/30\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 0.6213 - accuracy: 0.6220 - my_auc: 0.7229 - val_loss: 0.7094 - val_accuracy: 0.6391 - val_my_auc: 0.6709\n",
            " epoch:23 auc: 0.6712\n",
            "Epoch 25/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.5743 - accuracy: 0.6244 - my_auc: 0.7159 - val_loss: 0.7067 - val_accuracy: 0.6288 - val_my_auc: 0.6695\n",
            " epoch:24 auc: 0.6696\n",
            "AUC:  0.6748\n",
            "11303\n",
            "Model: \"model_lstm\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 1, 15)]           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 1, 15)             60        \n",
            "_________________________________________________________________\n",
            "bidirectional_14 (Bidirectio (None, 1, 62)             11656     \n",
            "_________________________________________________________________\n",
            "layer_lstm_2 (LSTM)          (None, 31)                11656     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                1024      \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 24,429\n",
            "Trainable params: 24,399\n",
            "Non-trainable params: 30\n",
            "_________________________________________________________________\n",
            "{0.0: 0.5019836570345808, 1.0: 126.52985074626865}\n",
            "Epoch 1/30\n",
            "67/67 [==============================] - 14s 50ms/step - loss: 0.6964 - accuracy: 0.3086 - my_auc: 0.5536 - val_loss: 0.6924 - val_accuracy: 0.3804 - val_my_auc: 0.5152\n",
            " epoch:0 auc: 0.6563\n",
            "Epoch 2/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.6825 - accuracy: 0.6676 - my_auc: 0.6152 - val_loss: 0.6895 - val_accuracy: 0.5736 - val_my_auc: 0.6684\n",
            " epoch:1 auc: 0.6975\n",
            "Epoch 3/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.6848 - accuracy: 0.7221 - my_auc: 0.6856 - val_loss: 0.6828 - val_accuracy: 0.6035 - val_my_auc: 0.6998\n",
            " epoch:2 auc: 0.7034\n",
            "Epoch 4/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.7346 - accuracy: 0.6562 - my_auc: 0.6755 - val_loss: 0.6707 - val_accuracy: 0.5684 - val_my_auc: 0.7057\n",
            " epoch:3 auc: 0.7063\n",
            "Epoch 5/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.6691 - accuracy: 0.6646 - my_auc: 0.7351 - val_loss: 0.6558 - val_accuracy: 0.5991 - val_my_auc: 0.7039\n",
            " epoch:4 auc: 0.7051\n",
            "Epoch 6/30\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 0.6217 - accuracy: 0.6523 - my_auc: 0.6486 - val_loss: 0.6405 - val_accuracy: 0.6113 - val_my_auc: 0.7080\n",
            " epoch:5 auc: 0.7067\n",
            "Epoch 7/30\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 0.6703 - accuracy: 0.6276 - my_auc: 0.6642 - val_loss: 0.6281 - val_accuracy: 0.6339 - val_my_auc: 0.7079\n",
            " epoch:6 auc: 0.7082\n",
            "Epoch 8/30\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 0.6317 - accuracy: 0.6413 - my_auc: 0.7539 - val_loss: 0.6225 - val_accuracy: 0.6316 - val_my_auc: 0.7078\n",
            " epoch:7 auc: 0.7080\n",
            "Epoch 9/30\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 0.5777 - accuracy: 0.6315 - my_auc: 0.7278 - val_loss: 0.6195 - val_accuracy: 0.6023 - val_my_auc: 0.7079\n",
            " epoch:8 auc: 0.7079\n",
            "AUC:  0.7067\n",
            "11303\n",
            "avg_AUC :  0.7169638629727217\n",
            "avg_AUC_2 :  0.716860524436282\n",
            "         0         1         2   ...       22        23        24\n",
            "0  0.569882  0.664605  0.720557  ...      NaN       NaN       NaN\n",
            "1  0.545789  0.657488  0.689421  ...      NaN       NaN       NaN\n",
            "2  0.570061  0.640722  0.648698  ...  0.67195  0.670926  0.669467\n",
            "3  0.515215  0.668380  0.699792  ...      NaN       NaN       NaN\n",
            "\n",
            "[4 rows x 25 columns]\n",
            "0     0.550237\n",
            "1     0.657799\n",
            "2     0.689617\n",
            "3     0.693385\n",
            "4     0.695859\n",
            "5     0.701464\n",
            "6     0.704318\n",
            "7     0.706455\n",
            "8     0.708352\n",
            "9     0.711477\n",
            "10    0.712464\n",
            "11    0.715107\n",
            "12    0.717016\n",
            "13    0.717782\n",
            "14    0.719053\n",
            "15    0.718391\n",
            "16    0.717163\n",
            "17    0.699433\n",
            "18    0.699416\n",
            "19    0.700085\n",
            "20    0.699774\n",
            "21    0.674833\n",
            "22    0.671950\n",
            "23    0.670926\n",
            "24    0.669467\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7169638629727217,\n",
              " array([0.        , 0.03901515, 0.06136364, 0.09482323, 0.1114899 ,\n",
              "        0.15050505, 0.17840909, 0.19520202, 0.21755051, 0.22891414,\n",
              "        0.26237374, 0.30164141, 0.31856061, 0.33522727, 0.34633838,\n",
              "        0.37436869, 0.38560606, 0.41919192, 0.43598485, 0.46931818,\n",
              "        0.47487374, 0.48611111, 0.5084596 , 0.52525253, 0.55340909,\n",
              "        0.55909091, 0.57588384, 0.59255051, 0.59255051, 0.59823232,\n",
              "        0.61489899, 0.61489899, 0.62045455, 0.64823232, 0.64823232,\n",
              "        0.66515152, 0.68181818, 0.69292929, 0.69292929, 0.70959596,\n",
              "        0.71515152, 0.71515152, 0.72070707, 0.73737374, 0.76565657,\n",
              "        0.78813131, 0.8104798 , 0.81603535, 0.83270202, 0.84381313,\n",
              "        0.85492424, 0.8604798 , 0.8604798 , 0.87171717, 0.87171717,\n",
              "        0.87171717, 0.88282828, 0.88282828, 0.88282828, 0.89393939,\n",
              "        0.89393939, 0.89393939, 0.89949495, 0.90505051, 0.90505051,\n",
              "        0.91060606, 0.91060606, 0.91616162, 0.91616162, 0.91616162,\n",
              "        0.91616162, 0.92727273, 0.92727273, 0.92727273, 0.92727273,\n",
              "        0.93838384, 0.94393939, 0.94962121, 0.94962121, 0.96073232,\n",
              "        0.96073232, 0.96073232, 0.96641414, 0.96641414, 0.96641414,\n",
              "        0.96641414, 0.96641414, 0.96641414, 0.96641414, 0.9719697 ,\n",
              "        0.9719697 , 0.98320707, 0.98320707, 0.98320707, 0.99444444,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ]),\n",
              " [[[array([0., 0., 0., ..., 0., 0., 0.]),\n",
              "    array([0.6264442 , 0.664051  , 0.7086361 , ..., 0.48290715, 0.42009723,\n",
              "           0.15464133], dtype=float32)],\n",
              "   array([   16,    19,    21, ..., 45200, 45207, 45211])],\n",
              "  [[array([0., 0., 0., ..., 0., 0., 0.]),\n",
              "    array([0.19602531, 0.24577013, 0.44316822, ..., 0.17657053, 0.40605646,\n",
              "           0.384885  ], dtype=float32)],\n",
              "   array([    0,     1,     4, ..., 45206, 45208, 45212])],\n",
              "  [[array([0., 0., 0., ..., 0., 0., 0.]),\n",
              "    array([0.4435309 , 0.21916452, 0.7315581 , ..., 0.5061263 , 0.6776343 ,\n",
              "           0.34730312], dtype=float32)],\n",
              "   array([    3,     5,     7, ..., 45188, 45190, 45192])],\n",
              "  [[array([0., 0., 0., ..., 0., 0., 0.]),\n",
              "    array([0.5593718 , 0.53679574, 0.36145127, ..., 0.23735821, 0.43740547,\n",
              "           0.30408615], dtype=float32)],\n",
              "   array([    2,     8,    13, ..., 45205, 45209, 45210])]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PvFXlAFtHc-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ab909FEtHgB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_u0lKc8tHjl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkzIKyXuCtyq"
      },
      "source": [
        "# LSTM+CNN+TCN\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWiCYABO24qC"
      },
      "source": [
        "#TCN for timestep = 1\r\n",
        "def model_tcn(n1,n2,n3,T, perf, words, channel, filters = 24, dropout = 0):\r\n",
        "    model = None\r\n",
        "    \r\n",
        "    input_perf = Input(shape=(T,perf), \\\r\n",
        "                      dtype='float32', name='input_perf')\r\n",
        "    \r\n",
        "    input_words = Input(shape=(T,words,channel), \\\r\n",
        "                      dtype='float32', name='input_words') \r\n",
        "    \r\n",
        "    word_norm = BatchNormalization()(input_words)\r\n",
        "    padding = ZeroPadding2D(padding=((0,0),(words-1,0)))(word_norm)\r\n",
        "    \r\n",
        "    print(\"shape after padding:\", K.int_shape(padding))\r\n",
        "    \r\n",
        "    conv = Conv2D(filters = filters,\\\r\n",
        "                  kernel_size = (1,words),\\\r\n",
        "                  use_bias = False,\\\r\n",
        "                  activation = None)(padding)  # Shape None x T x words x filters\r\n",
        "    print(\"conv shape:\", K.int_shape(conv))\r\n",
        "    conv = BatchNormalization()(conv)\r\n",
        "    conv = Activation(\"relu\") (conv)\r\n",
        "    \r\n",
        "    pool = MaxPooling2D(pool_size=(1, words), \\\r\n",
        "                        strides=(1,1))(conv) # None x T x filters\r\n",
        "    \r\n",
        "    pool = Reshape((T, filters))(pool)\r\n",
        "    print(\"pool shape:\", K.int_shape(pool))\r\n",
        "    pool = Dropout(0.3)(pool)\r\n",
        "\r\n",
        "    #drop = Dropout(0.3)(input_all)\r\n",
        "    # Now concatenate\r\n",
        "    perf_norm = BatchNormalization()(input_perf)\r\n",
        "    all_input = Concatenate(axis = -1)([perf_norm, pool])\r\n",
        "    all_rsp = Reshape((filters+ input_perf.shape[2],))(all_input)\r\n",
        "    #nor = BatchNormalization()(all_rsp)\r\n",
        "    \r\n",
        "    # LSTM_w_1 =Bidirectional(LSTM(n1,  recurrent_dropout = 0.2,\r\n",
        "    #                 name = 'layer_lstm_1', return_sequences=True,\r\n",
        "    #                 # kernel_regularizer = regularizers.l2(0.01),\r\n",
        "    #                 # activity_regularizer = regularizers.l2(0.01),\r\n",
        "    #                 # bias_regularizer = regularizers.l2(0.01)\r\n",
        "    #                 ))(all_input)\r\n",
        "    # LSTM_w_2 = LSTM(n2, dropout= 0.3, recurrent_dropout = 0.3,\r\n",
        "    #                name = 'layer_lstm_2', return_sequences=False)(LSTM_w_1)\r\n",
        "    \r\n",
        "    dense = Dense(60, activation='relu', name='dense0')(all_rsp)\r\n",
        "    drop = Dropout(0.3)(dense)\r\n",
        "    dense = Dense(32, activation='relu', name='dense')(drop)\r\n",
        "    #nor = BatchNormalization()(dense)\r\n",
        "    #dense = Dense(24, activation='relu', name='dense2')(drop)\r\n",
        "    preds = Dense(1, activation='sigmoid', name='output')(dense)\r\n",
        "    model = Model(inputs=[input_perf, input_words], outputs=preds)\r\n",
        "    model._name = \"model_tcn\"\r\n",
        "    model.summary()\r\n",
        "    \r\n",
        "    return model\r\n",
        "    "
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOOTtJYFbmXi"
      },
      "source": [
        "#TCN for timestep > 1\r\n",
        "def model_tcn_1(n1,n2,n3,T, perf, words, channel, filters = 24, dropout = 0):\r\n",
        "    model = None\r\n",
        "    \r\n",
        "    input_perf = Input(shape=(T,perf), \\\r\n",
        "                      dtype='float32', name='input_perf')\r\n",
        "    \r\n",
        "    input_words = Input(shape=(T,words,channel), \\\r\n",
        "                      dtype='float32', name='input_words') \r\n",
        "    \r\n",
        "    word_norm = BatchNormalization()(input_words)\r\n",
        "    padding = ZeroPadding2D(padding=((0,0),(words-1,0)))(word_norm)\r\n",
        "    \r\n",
        "    print(\"shape after padding:\", K.int_shape(padding))\r\n",
        "    \r\n",
        "    conv = Conv2D(filters = filters,\\\r\n",
        "                  kernel_size = (1,words),\\\r\n",
        "                  use_bias = False,\\\r\n",
        "                  activation = None)(padding)  # Shape None x T x words x filters\r\n",
        "    print(\"conv shape:\", K.int_shape(conv))\r\n",
        "    conv = BatchNormalization()(conv)\r\n",
        "    conv = Activation(\"relu\") (conv)\r\n",
        "    \r\n",
        "    pool = MaxPooling2D(pool_size=(1, words), \\\r\n",
        "                        strides=(1,1))(conv) # None x T x filters\r\n",
        "    pool = Reshape((T, filters))(pool)\r\n",
        "    print(\"pool shape:\", K.int_shape(pool))\r\n",
        "\r\n",
        "    #drop = Dropout(0.3)(input_all)\r\n",
        "    # Now concatenate\r\n",
        "    perf_norm = BatchNormalization()(input_perf)\r\n",
        "    all_input = Concatenate(axis = -1)([perf_norm, pool])\r\n",
        "    #all_rsp = Reshape((filters+15,))(all_input)\r\n",
        "    #nor = BatchNormalization()(all_input)\r\n",
        "    \r\n",
        "    LSTM_w_1 =Bidirectional(LSTM(n1,  recurrent_dropout = 0.2,\r\n",
        "                    name = 'layer_lstm_1', return_sequences=True,\r\n",
        "                    # kernel_regularizer = regularizers.l2(0.01),\r\n",
        "                    # activity_regularizer = regularizers.l2(0.01),\r\n",
        "                    # bias_regularizer = regularizers.l2(0.01)\r\n",
        "                    ))(all_input)\r\n",
        "    LSTM_w_2 = LSTM(n2, dropout= 0.3, recurrent_dropout = 0.3,\r\n",
        "                   name = 'layer_lstm_2', return_sequences=False)(LSTM_w_1)\r\n",
        "    \r\n",
        "    dense = Dense(n3, activation='relu', name='dense')(LSTM_w_2)\r\n",
        "    drop = Dropout(0.3)(dense)\r\n",
        "    \r\n",
        "    preds = Dense(1, activation='sigmoid', name='output')(drop)\r\n",
        "    model = Model(inputs=[input_perf, input_words], outputs=preds)\r\n",
        "    model._name = \"model_tcn\"\r\n",
        "    model.summary()\r\n",
        "    \r\n",
        "    return model"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "744Oq8vYvbsF"
      },
      "source": [
        "def performance_measure(pred_yp, y):\r\n",
        "    '''\r\n",
        "    Given lists of predicted y probability and x, y, return a dataframe of AR, AUC, Brier, Decile Table\r\n",
        "    '''\r\n",
        "    \r\n",
        "    tenc_dat = pd.DataFrame({'y_true':y,'probability':pred_yp.flatten()})\r\n",
        "    tenc_dat.sort_values('probability',axis = 0,ascending=False, inplace = True)\r\n",
        "    tenc_dat.index = range(0,len(tenc_dat))\r\n",
        "    y = tenc_dat['y_true']\r\n",
        "    point = float(len(tenc_dat))/10\r\n",
        "    point = int(round(point))\r\n",
        "    tenc = []\r\n",
        "    for i in range(0,10):\r\n",
        "        tenc.append(y[(i*point):((i+1)*point)])\r\n",
        "    tenc[9]=tenc[9].append(y[10*point:])\r\n",
        "    total = sum(y)\r\n",
        "    num_of_bkr = []\r\n",
        "    for j in range(0,10):\r\n",
        "        num_of_bkr.append(sum(tenc[j]))\r\n",
        "    tencile_bkr = np.array(num_of_bkr)\r\n",
        "    rate = tencile_bkr.astype(float)/total\r\n",
        "\r\n",
        "    return rate"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1oy1Jcrvd1Y"
      },
      "source": [
        "class AUCEvaluation(Callback):\r\n",
        "    \"\"\" Show AUC after interval number of epoches \"\"\"\r\n",
        "    def __init__(self, validation_data=(), interval=1):\r\n",
        "        super(Callback, self).__init__()\r\n",
        "        self.interval = interval\r\n",
        "        self.X_val, self.y_val = validation_data\r\n",
        "\r\n",
        "    def on_epoch_end(self, epoch, logs={}):\r\n",
        "        if epoch % self.interval == 0:\r\n",
        "            y_pred = self.model.predict(self.X_val, verbose=0)\r\n",
        "            score = roc_auc_score(self.y_val, y_pred)\r\n",
        "            logs['auc'] = score\r\n",
        "            tencile=performance_measure(y_pred, self.y_val)\r\n",
        "            logs['tencile'] = tencile\r\n",
        "            print(\" epoch:{:d} auc: {:.4f}\".format(epoch, score))\r\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gmZEw24vv9R"
      },
      "source": [
        "def fit_model( model,x_train, y_train, x_val, y_val, x_test, y_test, model_name, verbose = 0):\r\n",
        "    \r\n",
        "    history = None\r\n",
        "    result = None\r\n",
        "    \r\n",
        "    model_df = model\r\n",
        "    print('in fit, val_y: ', sum(y_val), 'test_y',sum(y_test), 'train_y',sum(y_train))\r\n",
        "\r\n",
        "    #class weight for test \r\n",
        "    class_weights = class_weight.compute_class_weight('balanced',\r\n",
        "                              np.unique(y_train),\r\n",
        "                              y_train)\r\n",
        "    class_weights = {l:c for l,c in zip(np.unique(y_train), class_weights)}\r\n",
        "    # class weight for val\r\n",
        "    val_class_weights = class_weight.compute_class_weight('balanced',\r\n",
        "                                np.unique(y_val),\r\n",
        "                                y_val)\r\n",
        "    val_class_weights = {l:c for l,c in zip(np.unique(y_val), val_class_weights)}\r\n",
        "    val_sample_weights = []\r\n",
        "    for y in y_val:\r\n",
        "        if y == 1:\r\n",
        "          val_sample_weights.append(val_class_weights[1])\r\n",
        "        else: val_sample_weights.append(val_class_weights[0])\r\n",
        "    val_sample_weights = np.asarray(val_sample_weights)\r\n",
        "    #print('in fit val weights', val_sample_weights.shape)\r\n",
        "    \r\n",
        "    auc_eval = AUCEvaluation(validation_data=(x_val, y_val), interval=1)\r\n",
        "    # earlyStopping = EarlyStopping(monitor='val_my_auc',patience = 3, \r\n",
        "    #                   verbose =verbose, mode ='max')\r\n",
        "    # checkpoint = ModelCheckpoint(model_name,monitor='val_my_auc',verbose=verbose,\r\n",
        "    #           save_best_only=True, save_weights_only=True, mode ='max')\r\n",
        "\r\n",
        "    opt = optimizers.RMSprop(lr=0.0005)\r\n",
        "    model_df.compile(optimizer= opt,\r\n",
        "              loss='binary_crossentropy',\r\n",
        "              metrics=['accuracy', metrics.AUC(name='my_auc')])\r\n",
        "\r\n",
        "    history = model_df.fit(x_train,\r\n",
        "                y_train,\r\n",
        "                epochs=15,\r\n",
        "                batch_size=128,\r\n",
        "                verbose =verbose,\r\n",
        "                callbacks=[auc_eval],\\\r\n",
        "                #callbacks=[auc_eval, earlyStopping, checkpoint], #checkpoint\r\n",
        "                class_weight = class_weights, \\\r\n",
        "                validation_data=(x_val, y_val, val_sample_weights)) \r\n",
        "    \r\n",
        "    #model_df.load_weights(model_name)\r\n",
        "    y_pred = model_df.predict(x_test)\r\n",
        "    y_pred_1=np.reshape(y_pred, -1)\r\n",
        "    auc_score = roc_auc_score(y_test, y_pred_1)\r\n",
        "    #auc_score = roc_auc_score(y_test, y_pred_1)\r\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_1)\r\n",
        "    print(\"AUC: \" ,round(auc_score,4))\r\n",
        "    print([ round(h,4) for h in history.history['val_loss']])    \r\n",
        "    plt.plot(history.history['loss'])\r\n",
        "    plt.plot(history.history['val_loss'])\r\n",
        "    plt.title('loss')\r\n",
        "    plt.ylabel('loss')\r\n",
        "    plt.xlabel('epoch')\r\n",
        "    plt.legend(['train', 'val'], loc='upper left')\r\n",
        "    plt.show()\r\n",
        "\r\n",
        "        \r\n",
        "    return history, auc_score, fpr, tpr, thresholds, [y_test, y_pred_1]"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bo3ShzQyoSci"
      },
      "source": [
        "def cross_val(data, label, perf_cols, words_cols, name, w, filters = 24):\r\n",
        "    tprs = []\r\n",
        "    auc_list = []\r\n",
        "    mean_fpr = np.linspace(0,1,100)\r\n",
        "    predicted_res =[]\r\n",
        "    his_auc = []\r\n",
        "    \r\n",
        "    kf = StratifiedKFold(n_splits = 4, shuffle = True, random_state = 42)\r\n",
        "    c = 0\r\n",
        "\r\n",
        "    X_perf, X_word, Y = shift_data(df_fl, w, \\\r\n",
        "                    perf_cols, \\\r\n",
        "                    words_cols, \\\r\n",
        "                    'label')\r\n",
        "    \r\n",
        "    for train_index, test_index in kf.split(range(len(X_perf)),Y):\r\n",
        "        \r\n",
        "        c += 1\r\n",
        "        \r\n",
        "        l1 = X_perf.shape[-1]+ filters + 16\r\n",
        "        \r\n",
        "        model = model_tcn(l1,l1,32,\\\r\n",
        "                    X_perf.shape[1],\\\r\n",
        "                    X_perf.shape[2],\r\n",
        "                    X_word.shape[2], \\\r\n",
        "                    X_word.shape[3], \\\r\n",
        "                    filters = filters)\r\n",
        "    \r\n",
        "        #model = model_lstm(n1,n2,n,w)\r\n",
        "        # train_x, train_val = train_test_split(train_index,test_size=0.2, \\\r\n",
        "        #             random_state=42, stratify = Y[train_index])\r\n",
        "        train_perf_data = X_perf[train_index]\r\n",
        "        train_word_data = X_word[train_index]\r\n",
        "        # train_perf_val = X_perf[train_val]\r\n",
        "        # train_word_val = X_word[train_val]\r\n",
        "\r\n",
        "        train_label = Y[train_index]\r\n",
        "        #val_label = Y[train_val]\r\n",
        "\r\n",
        "        test_perf_x = X_perf[test_index]\r\n",
        "        test_word_x = X_word[test_index]\r\n",
        "        test_y = Y[test_index] \r\n",
        "        \r\n",
        "        train_data = [train_perf_data, train_word_data]\r\n",
        "        # val_data = [train_perf_val,train_word_val]\r\n",
        "        test_x = [test_perf_x, test_word_x]\r\n",
        "\r\n",
        "        mod_res = fit_model(model, train_data, train_label, test_x, test_y, test_x, test_y,\\\r\n",
        "                  name+'_'+str(c))\r\n",
        "        his_auc.append(mod_res[0].history['val_my_auc'])\r\n",
        "        \r\n",
        "        \r\n",
        "        \r\n",
        "        \r\n",
        "        auc_list.append(mod_res[1])\r\n",
        "        tprs.append(np.interp(mean_fpr, mod_res[2], mod_res[3]))\r\n",
        "        temp_pred_res = [mod_res[-1],test_index]\r\n",
        "        print(len(test_index))\r\n",
        "        predicted_res.append(temp_pred_res)\r\n",
        "        \r\n",
        "        \r\n",
        "    mean_tpr = np.mean(tprs, axis=0)\r\n",
        "    print('avg_AUC : ', np.mean(auc_list))\r\n",
        "    print('avg_AUC_2 : ', auc(mean_fpr, mean_tpr))\r\n",
        "    print(pd.DataFrame(his_auc))\r\n",
        "    print(pd.DataFrame(his_auc).mean())\r\n",
        "    \r\n",
        "    return np.average(auc_list), mean_tpr, predicted_res"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rfF_t6WWVcu"
      },
      "source": [
        "#a = np.arange(16).reshape((2,8#))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4FwTZ8JWZcJ"
      },
      "source": [
        "#a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooJMEa21WZem"
      },
      "source": [
        "#a.reshape((2,8), order = '')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3ub73u2WZhz"
      },
      "source": [
        "#a.reshape((2,4,2), order = 'C')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fSPkGEAWZjk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDLCeoltzOn6"
      },
      "source": [
        "def shift_data(data, step, perf_cols, words_cols, label):\r\n",
        "    A = []\r\n",
        "    \r\n",
        "    cols = perf_cols + words_cols\r\n",
        "    A.append(data[cols].values)\r\n",
        "    \r\n",
        "    for t in range(1, step):\r\n",
        "        d = data.groupby(\"cik\")[cols].shift(t)\r\n",
        "        A.append(d.values)\r\n",
        "    A = A[::-1]\r\n",
        "    A = np.concatenate(A, axis = 1)  # flatten shifted columns\r\n",
        "    A = np.concatenate([data[label].values[:,None], A], axis = 1)  # add target\r\n",
        "    #np.random.shuffle(A)\r\n",
        "    #print(A[3])\r\n",
        "    print('init A shape: ',A.shape)\r\n",
        "    #print(A[3,:])\r\n",
        "    #print(data[cols].iloc[4,:])\r\n",
        "\r\n",
        "\r\n",
        "    \r\n",
        "    A = A[~np.isnan(A).any(axis=1)]  # drop nan\r\n",
        "    \r\n",
        "\r\n",
        "    Y = A[:,0]  # get target\r\n",
        "    #A = np.reshape(A[:,1:], (len(A), step, len(cols))) # reshape\r\n",
        "\r\n",
        "    A = np.reshape(A[:,1:], (len(A), step, len(perf_cols) + len(words_cols)))\r\n",
        "    \r\n",
        "    A_perf = A[:, :, 0:len(perf_cols)]\r\n",
        "    # CNN_LSTM must be None x T x words x 4\r\n",
        "    A_words = A[:, :, len(perf_cols):]\r\n",
        "    #convert the shape to [[_p,_new][_dis,_n]]\r\n",
        "    A_words = A_words.reshape((len(A), step, int(len(words_cols)/4), 4), order = 'C')\r\n",
        "    \r\n",
        "    print(A_perf.shape, A_words.shape, Y.sum())\r\n",
        "    return A_perf, A_words, Y\r\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDR1cndI_xJF"
      },
      "source": [
        "#shift_perf,shit_wrd, _y = shift_data(df_fl, 3, v_perf + v_1+ v_2, selected_new_all_sorted, label='label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B42iqO2dZWQU"
      },
      "source": [
        "#shit_wrd[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJJvwrMuANlK"
      },
      "source": [
        "# for k , fr in df_fl.groupby(\"cik\"):\r\n",
        "#   print(fr[selected_new_all_sorted])\r\n",
        "#   break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaVhYNFbZJgE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fREeiK36ZJi7"
      },
      "source": [
        "import os, random\r\n",
        "\r\n",
        "seed_value = 43\r\n",
        "os.environ['PYTHONASHSEED'] = str(seed_value)\r\n",
        "\r\n",
        "random.seed(seed_value)\r\n",
        "\r\n",
        "from numpy.random import seed\r\n",
        "seed(seed_value)\r\n",
        "\r\n",
        "import tensorflow\r\n",
        "tensorflow.random.set_seed(seed_value)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tygu3EpmnZl7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0844a689-10d7-453d-ea23-e2ce02df721e"
      },
      "source": [
        "#filter = [24,28,32,36,46,56]\r\n",
        "#for f in filter:\r\n",
        "w = 1\r\n",
        "perf_cols =  v_1 #+ v_perf\r\n",
        "words_cols = selected_new_all_sorted\r\n",
        "label = 'label'\r\n",
        "h = cross_val( df_fl, 'label', \\\r\n",
        "          perf_cols,\\\r\n",
        "          words_cols, \\\r\n",
        "          'model_tcn_w1',w, \\\r\n",
        "          filters = 56)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "init A shape:  (52402, 42)\n",
            "(52402, 1, 1) (52402, 1, 10, 4) 210.0\n",
            "shape after padding: (None, 1, 19, 4)\n",
            "conv shape: (None, 1, 10, 56)\n",
            "pool shape: (None, 1, 56)\n",
            "Model: \"model_tcn\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_words (InputLayer)        [(None, 1, 10, 4)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 1, 10, 4)     16          input_words[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_4 (ZeroPadding2D (None, 1, 19, 4)     0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 1, 10, 56)    2240        zero_padding2d_4[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 1, 10, 56)    224         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 1, 10, 56)    0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 1, 1, 56)     0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "input_perf (InputLayer)         [(None, 1, 1)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reshape_4 (Reshape)             (None, 1, 56)        0           max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 1, 1)         4           input_perf[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 1, 56)        0           reshape_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 1, 57)        0           batch_normalization_14[0][0]     \n",
            "                                                                 dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_5 (Reshape)             (None, 57)           0           concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense0 (Dense)                  (None, 60)           3480        reshape_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 60)           0           dense0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 32)           1952        dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "output (Dense)                  (None, 1)            33          dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 7,949\n",
            "Trainable params: 7,827\n",
            "Non-trainable params: 122\n",
            "__________________________________________________________________________________________________\n",
            "in fit, val_y:  53.0 test_y 53.0 train_y 157.0\n",
            " epoch:0 auc: 0.5688\n",
            " epoch:1 auc: 0.5985\n",
            " epoch:2 auc: 0.5972\n",
            " epoch:3 auc: 0.5765\n",
            " epoch:4 auc: 0.5388\n",
            " epoch:5 auc: 0.5561\n",
            " epoch:6 auc: 0.5713\n",
            " epoch:7 auc: 0.5588\n",
            " epoch:8 auc: 0.5771\n",
            " epoch:9 auc: 0.5413\n",
            " epoch:10 auc: 0.5534\n",
            " epoch:11 auc: 0.5453\n",
            " epoch:12 auc: 0.5697\n",
            " epoch:13 auc: 0.5409\n",
            " epoch:14 auc: 0.5726\n",
            "AUC:  0.5726\n",
            "[0.6876, 0.7012, 0.6851, 0.682, 0.7085, 0.69, 0.6843, 0.6852, 0.6902, 0.7154, 0.7082, 0.7274, 0.7112, 0.9384, 0.7035]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "13101\n",
            "shape after padding: (None, 1, 19, 4)\n",
            "conv shape: (None, 1, 10, 56)\n",
            "pool shape: (None, 1, 56)\n",
            "Model: \"model_tcn\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_words (InputLayer)        [(None, 1, 10, 4)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 1, 10, 4)     16          input_words[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_5 (ZeroPadding2D (None, 1, 19, 4)     0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 1, 10, 56)    2240        zero_padding2d_5[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 1, 10, 56)    224         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 1, 10, 56)    0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 1, 1, 56)     0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "input_perf (InputLayer)         [(None, 1, 1)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reshape_6 (Reshape)             (None, 1, 56)        0           max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 1, 1)         4           input_perf[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 1, 56)        0           reshape_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 1, 57)        0           batch_normalization_17[0][0]     \n",
            "                                                                 dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_7 (Reshape)             (None, 57)           0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense0 (Dense)                  (None, 60)           3480        reshape_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 60)           0           dense0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 32)           1952        dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "output (Dense)                  (None, 1)            33          dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 7,949\n",
            "Trainable params: 7,827\n",
            "Non-trainable params: 122\n",
            "__________________________________________________________________________________________________\n",
            "in fit, val_y:  53.0 test_y 53.0 train_y 157.0\n",
            " epoch:0 auc: 0.5185\n",
            " epoch:1 auc: 0.5355\n",
            " epoch:2 auc: 0.5582\n",
            " epoch:3 auc: 0.5600\n",
            " epoch:4 auc: 0.5591\n",
            " epoch:5 auc: 0.5901\n",
            " epoch:6 auc: 0.5817\n",
            " epoch:7 auc: 0.5813\n",
            " epoch:8 auc: 0.5766\n",
            " epoch:9 auc: 0.6064\n",
            " epoch:10 auc: 0.6101\n",
            " epoch:11 auc: 0.6026\n",
            " epoch:12 auc: 0.5985\n",
            " epoch:13 auc: 0.5929\n",
            " epoch:14 auc: 0.6033\n",
            "AUC:  0.6033\n",
            "[0.6935, 0.7184, 0.6966, 0.6935, 0.6858, 0.6779, 0.6883, 0.6902, 0.6841, 0.6752, 0.6723, 0.6884, 0.6745, 0.6931, 0.6985]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "13101\n",
            "shape after padding: (None, 1, 19, 4)\n",
            "conv shape: (None, 1, 10, 56)\n",
            "pool shape: (None, 1, 56)\n",
            "Model: \"model_tcn\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_words (InputLayer)        [(None, 1, 10, 4)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 1, 10, 4)     16          input_words[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_6 (ZeroPadding2D (None, 1, 19, 4)     0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 1, 10, 56)    2240        zero_padding2d_6[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 1, 10, 56)    224         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 1, 10, 56)    0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 1, 1, 56)     0           activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "input_perf (InputLayer)         [(None, 1, 1)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reshape_8 (Reshape)             (None, 1, 56)        0           max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 1, 1)         4           input_perf[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 1, 56)        0           reshape_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 1, 57)        0           batch_normalization_20[0][0]     \n",
            "                                                                 dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_9 (Reshape)             (None, 57)           0           concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense0 (Dense)                  (None, 60)           3480        reshape_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 60)           0           dense0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 32)           1952        dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "output (Dense)                  (None, 1)            33          dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 7,949\n",
            "Trainable params: 7,827\n",
            "Non-trainable params: 122\n",
            "__________________________________________________________________________________________________\n",
            "in fit, val_y:  52.0 test_y 52.0 train_y 158.0\n",
            " epoch:0 auc: 0.5847\n",
            " epoch:1 auc: 0.5612\n",
            " epoch:2 auc: 0.5432\n",
            " epoch:3 auc: 0.5618\n",
            " epoch:4 auc: 0.5527\n",
            " epoch:5 auc: 0.5565\n",
            " epoch:6 auc: 0.5585\n",
            " epoch:7 auc: 0.5482\n",
            " epoch:8 auc: 0.5729\n",
            " epoch:9 auc: 0.5376\n",
            " epoch:10 auc: 0.5662\n",
            " epoch:11 auc: 0.5689\n",
            " epoch:12 auc: 0.5531\n",
            " epoch:13 auc: 0.5545\n",
            " epoch:14 auc: 0.5523\n",
            "AUC:  0.5523\n",
            "[0.6897, 0.6915, 0.6871, 0.6975, 0.7534, 0.7707, 0.6983, 0.7013, 0.718, 0.7315, 0.6729, 0.685, 0.7097, 0.7216, 0.7228]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "13100\n",
            "shape after padding: (None, 1, 19, 4)\n",
            "conv shape: (None, 1, 10, 56)\n",
            "pool shape: (None, 1, 56)\n",
            "Model: \"model_tcn\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_words (InputLayer)        [(None, 1, 10, 4)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 1, 10, 4)     16          input_words[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_7 (ZeroPadding2D (None, 1, 19, 4)     0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 1, 10, 56)    2240        zero_padding2d_7[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 1, 10, 56)    224         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 1, 10, 56)    0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 1, 1, 56)     0           activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "input_perf (InputLayer)         [(None, 1, 1)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reshape_10 (Reshape)            (None, 1, 56)        0           max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 1, 1)         4           input_perf[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 1, 56)        0           reshape_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 1, 57)        0           batch_normalization_23[0][0]     \n",
            "                                                                 dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_11 (Reshape)            (None, 57)           0           concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense0 (Dense)                  (None, 60)           3480        reshape_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 60)           0           dense0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 32)           1952        dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "output (Dense)                  (None, 1)            33          dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 7,949\n",
            "Trainable params: 7,827\n",
            "Non-trainable params: 122\n",
            "__________________________________________________________________________________________________\n",
            "in fit, val_y:  52.0 test_y 52.0 train_y 158.0\n",
            " epoch:0 auc: 0.4926\n",
            " epoch:1 auc: 0.5429\n",
            " epoch:2 auc: 0.5356\n",
            " epoch:3 auc: 0.6055\n",
            " epoch:4 auc: 0.6011\n",
            " epoch:5 auc: 0.5944\n",
            " epoch:6 auc: 0.5776\n",
            " epoch:7 auc: 0.5650\n",
            " epoch:8 auc: 0.6004\n",
            " epoch:9 auc: 0.5951\n",
            " epoch:10 auc: 0.5698\n",
            " epoch:11 auc: 0.5621\n",
            " epoch:12 auc: 0.5320\n",
            " epoch:13 auc: 0.5167\n",
            " epoch:14 auc: 0.5330\n",
            "AUC:  0.533\n",
            "[0.6943, 0.6978, 0.7226, 0.6842, 0.6829, 0.6909, 0.6775, 0.6809, 0.6868, 0.6795, 0.6898, 0.6853, 0.7006, 0.7173, 0.7711]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "13100\n",
            "avg_AUC :  0.5652788431505331\n",
            "avg_AUC_2 :  0.5651544472299189\n",
            "         0         1         2   ...        12        13        14\n",
            "0  0.564642  0.599001  0.597144  ...  0.569382  0.540976  0.573512\n",
            "1  0.519436  0.535996  0.558290  ...  0.599031  0.592649  0.603576\n",
            "2  0.583692  0.561020  0.544092  ...  0.552808  0.553406  0.552554\n",
            "3  0.489045  0.541927  0.535602  ...  0.530992  0.516936  0.532897\n",
            "\n",
            "[4 rows x 15 columns]\n",
            "0     0.539204\n",
            "1     0.559486\n",
            "2     0.558782\n",
            "3     0.575683\n",
            "4     0.562803\n",
            "5     0.574401\n",
            "6     0.572292\n",
            "7     0.563029\n",
            "8     0.581044\n",
            "9     0.570879\n",
            "10    0.574955\n",
            "11    0.570337\n",
            "12    0.563053\n",
            "13    0.550992\n",
            "14    0.565635\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWWUxAIHflk9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}